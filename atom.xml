<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CSRJTAN</title>
  <subtitle>Keep Moving</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://csrjtan.github.io/"/>
  <updated>2016-06-21T12:47:49.000Z</updated>
  <id>https://csrjtan.github.io/</id>
  
  <author>
    <name>CsrjTan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CS231n_8_9</title>
    <link href="https://csrjtan.github.io/2016/06/21/CS231n-8/"/>
    <id>https://csrjtan.github.io/2016/06/21/CS231n-8/</id>
    <published>2016-06-21T11:16:47.000Z</published>
    <updated>2016-06-21T12:47:49.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Lec8&quot;&gt;&lt;a href=&quot;#Lec8&quot; class=&quot;headerlink&quot; title=&quot;Lec8&quot;&gt;&lt;/a&gt;Lec8&lt;/h3&gt;&lt;p&gt;Spatial Localization and Detection&lt;/p&gt;
&lt;h4 id=&quot;Tasks&quot;&gt;&lt;a href=&quot;#Tasks&quot; class=&quot;headerlink&quot; title=&quot;Tasks&quot;&gt;&lt;/a&gt;Tasks&lt;/h4&gt;&lt;p&gt;Classification, Classificatin+Localization, Object Detection, Instance Segmentation.&lt;/p&gt;
&lt;p&gt;Localization, I:Image O:Box in the image(x,y,w,h) E:Intersection over Union.(IoU)&lt;/p&gt;
&lt;h4 id=&quot;Claissification-Localization&quot;&gt;&lt;a href=&quot;#Claissification-Localization&quot; class=&quot;headerlink&quot; title=&quot;Claissification+Localization&quot;&gt;&lt;/a&gt;Claissification+Localization&lt;/h4&gt;&lt;p&gt;Output: Single Label and Bounding Box&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Idea one&lt;/strong&gt;: Two task head&lt;br&gt;1.Train a CNN&lt;br&gt;2.Attach new fully-connected “regression head” to the network(FC)&lt;br&gt;  2.1 Classification Head&lt;br&gt;  2.2 Regression Head&lt;br&gt;3.Train the regression head only with SGD and L2 loss&lt;br&gt;&lt;a href=&quot;http://4.At&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;4.At&lt;/a&gt; test time use both heads&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Idea two&lt;/strong&gt;: Sliding Window&lt;br&gt;Input: Bounding Box&lt;br&gt;Iteratively refine the BB into a optimal size and place.&lt;/p&gt;
&lt;h4 id=&quot;Objects-Detection&quot;&gt;&lt;a href=&quot;#Objects-Detection&quot; class=&quot;headerlink&quot; title=&quot;Objects Detection&quot;&gt;&lt;/a&gt;Objects Detection&lt;/h4&gt;&lt;p&gt;Output: all the exist labels and BBs&lt;/p&gt;
&lt;p&gt;Problem: Need to test many positions and scales, use computationally demanding classifier&lt;/p&gt;
&lt;p&gt;Solution: Only look at a tiny subset of possible positions&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Region Proposal&lt;/strong&gt;:Bottom-up segmentation.&lt;/p&gt;
&lt;p&gt;RCNN: 1. Train a classification model on ImageNet&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fine-tune model for detection(Throw finaly FC rathter than 20 Objects and one background, that is 4096*21 for the last layer.)&lt;/li&gt;
&lt;li&gt;Extract Features: Extract region proposals for all images, save the pool5 features to disk.&lt;/li&gt;
&lt;li&gt;Train one binary SVM per class to claissify region features.&lt;/li&gt;
&lt;li&gt;Bbox regression: Train a linear model to fine-grain the bbox&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Fast-RCNN: Build an end-to-end framework, much faster than RCNN.&lt;/p&gt;
&lt;h4 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0621classification.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Lec9-Understanding-and-Visualizing&quot;&gt;&lt;a href=&quot;#Lec9-Understanding-and-Visualizing&quot; class=&quot;headerlink&quot; title=&quot;Lec9 Understanding and Visualizing&quot;&gt;&lt;/a&gt;Lec9 Understanding and Visualizing&lt;/h3&gt;&lt;p&gt;Visualizing the weights, t-SNE visualization&lt;/p&gt;
&lt;p&gt;Deconv Approaches:&lt;br&gt;1.Feed image into net&lt;br&gt;2.pick a layer, set gradients of the score vector to [0 0 1 .. 0], then bp to image&lt;br&gt;&lt;a href=&quot;http://3.Do&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;3.Do&lt;/a&gt; a small “Image Update”&lt;br&gt;4.Forward the Image&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to step 2&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0621deconv.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;Deconv&quot;&gt;&lt;a href=&quot;#Deconv&quot; class=&quot;headerlink&quot; title=&quot;Deconv&quot;&gt;&lt;/a&gt;Deconv&lt;/h4&gt;&lt;p&gt;Learn to visualize the weights, also deconv to reconstruct an larger size output.&lt;/p&gt;
&lt;p&gt;Deconv: reverse the convolution filter&lt;br&gt;DePool: record the position and set other be zero.&lt;br&gt;DeReLU: The same as the ReLU.&lt;/p&gt;
&lt;h4 id=&quot;Neural-Style&quot;&gt;&lt;a href=&quot;#Neural-Style&quot; class=&quot;headerlink&quot; title=&quot;Neural Style&quot;&gt;&lt;/a&gt;Neural Style&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;extract content targets&lt;/li&gt;
&lt;li&gt;extract style targets&lt;/li&gt;
&lt;li&gt;Optimize over image &lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;BackPropping-is-powerful&quot;&gt;&lt;a href=&quot;#BackPropping-is-powerful&quot; class=&quot;headerlink&quot; title=&quot;BackPropping is powerful&quot;&gt;&lt;/a&gt;BackPropping is powerful&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Understanding&lt;/li&gt;
&lt;li&gt;Segmenting Objects in the Image&lt;/li&gt;
&lt;li&gt;Inverting codes and introducing privacy concerns&lt;/li&gt;
&lt;li&gt;Fun(NeuralStyle/DeepDream)&lt;/li&gt;
&lt;li&gt;Confusion and chaos(Adversarial Examples)&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Lec8&quot;&gt;&lt;a href=&quot;#Lec8&quot; class=&quot;headerlink&quot; title=&quot;Lec8&quot;&gt;&lt;/a&gt;Lec8&lt;/h3&gt;&lt;p&gt;Spatial Localization and Detection&lt;/p&gt;
&lt;h4 id=&quot;Tasks&quot;&gt;&lt;a href=
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="CNN 公开课" scheme="https://csrjtan.github.io/tags/CNN-%E5%85%AC%E5%BC%80%E8%AF%BE/"/>
    
  </entry>
  
  <entry>
    <title>Bilateral_Guided_Filter</title>
    <link href="https://csrjtan.github.io/2016/06/13/Bilateral-Guided-Filter/"/>
    <id>https://csrjtan.github.io/2016/06/13/Bilateral-Guided-Filter/</id>
    <published>2016-06-13T02:24:43.000Z</published>
    <updated>2016-06-13T04:09:51.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;Bilateral-Filter&quot;&gt;&lt;a href=&quot;#Bilateral-Filter&quot; class=&quot;headerlink&quot; title=&quot;Bilateral Filter&quot;&gt;&lt;/a&gt;Bilateral Filter&lt;/h4&gt;&lt;p&gt;双边滤波主要考虑了邻域里的像素加权，权重受几何距离和色彩距离相关。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613bilateral.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;双边滤波具有Non-linear, edge-preseving and noise-reducing smoothing的特性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613bi1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;Guided-Filter&quot;&gt;&lt;a href=&quot;#Guided-Filter&quot; class=&quot;headerlink&quot; title=&quot;Guided Filter&quot;&gt;&lt;/a&gt;Guided Filter&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613guided.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;加入了引导图像的抽象，可以不一定沿着自身而做bilateral filter的。但这里guided filter还是用自身的保持边缘滤波来先理解。&lt;/p&gt;
&lt;p&gt;与bilateral的区别在于不是简单地利用spatial和range,而是建立一个局部的线性关系，在当前更新pixel的局部窗口k中，建立一个局部线性关系。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613linear.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后根据线性回归，对每个像素求解出其对应的参数$a_k,b_k$,再分“High variance”和”Flat patch”进行处理。&lt;br&gt;如果a-&amp;gt;1,b-&amp;gt;0:High Variance,保持值不变&lt;br&gt;如果a-&amp;gt;0,b-&amp;gt;$\mu_k$:Flat patch,使用临近像素平均&lt;/p&gt;
&lt;h4 id=&quot;具体数学分析&quot;&gt;&lt;a href=&quot;#具体数学分析&quot; class=&quot;headerlink&quot; title=&quot;具体数学分析&quot;&gt;&lt;/a&gt;具体数学分析&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613gui1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613gui2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;保留了Bilateral filter的优点，同时克服了缺点，使得平滑之余达到边沿保留。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Bilateral-Filter&quot;&gt;&lt;a href=&quot;#Bilateral-Filter&quot; class=&quot;headerlink&quot; title=&quot;Bilateral Filter&quot;&gt;&lt;/a&gt;Bilateral Filter&lt;/h4&gt;&lt;p&gt;双边滤波主要考虑了邻域里的像
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
  </entry>
  
  <entry>
    <title>时间简史</title>
    <link href="https://csrjtan.github.io/2016/06/12/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2/"/>
    <id>https://csrjtan.github.io/2016/06/12/时间简史/</id>
    <published>2016-06-12T03:23:17.000Z</published>
    <updated>2016-06-12T03:45:43.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h4&gt;&lt;p&gt;这是霍金在2010出版的书，讲述近代纯物理学的一些研究成果以及围绕宇宙学来展开的一系列科普理论。&lt;br&gt;这个评价很高也让我了解到物理学是怎么去做research的，然而无奈自己太多理论没有接触过，也没有上过《大学物理》这个课程，中间太多断层的知识唯有靠瞎蒙，无奈第一次十分不理解地看完了。想做点笔记，也只能围绕书本的结构顺序展开基本的描述，也参考了一下豆瓣上的笔记之类的，在这里总结一下，毕竟这个书前前后后读了2周，依然云里雾里。庆幸的是我对为何宇宙膨胀，黑洞、虫洞、空间曲率等有了更深的理解。因为我很喜欢关于宇宙题材的电影，包括《火星救援》、《星际穿越》、《星际迷航》等等。还是很值得一看，这是个重要的科学问题，也是一个哲学问题。&lt;/p&gt;
&lt;p&gt;最后，大部分的朋友也是认为此书看不懂是正常的，甚至连物理系的学生也可能不能完全读通，主要是一来物理学未成大体系，二来目前研究还很粗糙，霍金用个人的理解和总结来描述，总不免有未能顾及大众科普，三来对基本理论的掌握要求比较高，不然无法延伸出来这些观点。&lt;/p&gt;
&lt;h4 id=&quot;文章结构&quot;&gt;&lt;a href=&quot;#文章结构&quot; class=&quot;headerlink&quot; title=&quot;文章结构&quot;&gt;&lt;/a&gt;文章结构&lt;/h4&gt;&lt;p&gt;这里把看书的笔记列一下，比较杂乱:&lt;br&gt;人类发展以来的宇宙观和世界观：地方说-&amp;gt;地圆说（上帝说）-&amp;gt;日心说（哥白尼）-&amp;gt;椭圆轨道-&amp;gt;万有引力（牛顿）-&amp;gt;狭义相对论-&amp;gt;广义相对论-&amp;gt;宇宙大爆炸&lt;/p&gt;
&lt;p&gt;组成成分的认识： 四元素（亚里士多德）-&amp;gt;原子论（道尔）-&amp;gt;布朗运动-&amp;gt;电子（卢瑟福）-&amp;gt;中子（查德威克）-&amp;gt;夸克（加州理工1969）&lt;/p&gt;
&lt;p&gt;四种力：万有引力、电磁力、弱核力、强作用力&lt;/p&gt;
&lt;p&gt;量子物理（微观）：量子假设、不确定性原理、薛定谔的猫&lt;br&gt;热力学熵增（有序到无序）：热力学箭头，心理学箭头，宇宙学箭头&lt;br&gt;黑洞的“无毛定力”，称为“不能逃逸远处的时间集合”、弱人择原理、不完备定理、虫洞（空间扭曲）、宇宙弦（张力大的橡筋），光速C为常量且最快，粒子无法提速到99.99%*c,无论功率如何加大。还有光锥、高维空间、PST对称原理等。&lt;/p&gt;
&lt;h4 id=&quot;借鉴总结&quot;&gt;&lt;a href=&quot;#借鉴总结&quot; class=&quot;headerlink&quot; title=&quot;借鉴总结&quot;&gt;&lt;/a&gt;借鉴总结&lt;/h4&gt;&lt;p&gt;【引用自豆瓣 川贝】&lt;/p&gt;
&lt;p&gt;一、物质（Substance）&lt;br&gt;物质即一种存在。物质由一些基本粒子（自旋为1/2）构成。物质的绝对静止是不存在的，物质的绝对状态是不停运动变化的。质量和能量是描述物质状态的两个重要属性，两者皆满足广泛意义上的守恒定律，且可以互相转化。力（自旋为0，1，2的虚粒子）和波（自旋为0，1，2的实粒子）描述了物质间的相互作用及效果，自然界归纳出四种基本的力：引力、电磁力、强核力、弱核力。&lt;/p&gt;
&lt;p&gt;二、时空（Time&amp;amp;Space）&lt;br&gt;当我们跳出低维度的视角去思考这个世界，时间和空间是一个混合的概念，时空的本质是物质的散漫态，而时间只是物质状态变迁的一种度量。时间箭头是基于热力学方向（闭合系统中的熵总是随时间增加）、心理学方向（取决于热力学方向）、宇宙学方向（方向不定，但根据人择原理，现在它与前两个方向一致）的。关于广义相对论和时空曲率的一些论证及推论让我们看到通过旋转黑洞、虫洞进行时空旅行的可能性。&lt;/p&gt;
&lt;p&gt;三、科学（Science）&lt;br&gt;从最初亚里士多德的权威说法到牛顿的经典理论再到爱因斯坦的相对论和近代物理学的量子论，科学理论的提出、完善、应用乃至推翻，每每令人惊叹随即错愕。让我来回想一下部分基本理论及关键字：&lt;br&gt;1、电磁场理论：四个方程，似乎没什么好说的。做大一统工作的人总能博得满堂彩，向麦克斯韦致敬。也正是这个理论方程关于伽利略变换的不谐洽导致了洛伦兹变换和相对论的提出。&lt;br&gt;2、相对论：狭义相对论凭借两条简洁的假设，开拓了一个崭新的时空观，重新探讨了惯性系中物体的运动规律，由此衍生出来的一系列推论和预言近乎完美的解释并验证了诸多难题，继而广义相对论又对非惯性系中的物体运动规律做了进一步研究，赋予了引力场和惯性等物理概念以新的科学内涵，有力地推动了天文宇宙物理学的快速发展。&lt;br&gt;3、量子理论：光电效应、波谱研究、康普顿效应、德布罗意波-&amp;gt;量子化（从普朗克到波尔）！海森堡不确定性原理（俗称测不准原理）放弃了量子状态的精确测量、泡利不相容原理－&amp;gt;概率波、薛定谔方程，还有一大堆基本粒子及其量子状态描述（复杂从略），量子物理学作为研究物质微观机理的近代理论还在不断的完善中……&lt;br&gt;4、近代宇宙学：宇宙的起源及演化（热大爆炸学说，弗里德曼闭合宇宙，宇宙无边界设想）、黑洞理论（坍塌，高密度，大引力）、虫洞(时空负曲率)、人择原理（最莫名其妙的原理：“不要问为什么，因为这就是答案”）、暗物质（反粒子）、弦理论、……关于宇宙的理论与设想自古以来就没少过。&lt;br&gt;5、理论的统一：广义相对论用以描述宇宙的大尺度结构（几公里到1亿亿亿英里），量子力学用以处理极小尺度现象（百万亿分之一米），然而，可惜的是这两个理论不是互相协调的——它们不可能都对！现在科学家们正在思索并探寻一种被称为“量子引力论”的统一理论。自然界中的四种基本力中除引力外的其他三种力的统一已经在GUT（大统一理论）中初见端倪，然而离最终得到包含包括引力在内的所有力和普适物理规律的统一理论还有相当长的一段路要走。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h4&gt;&lt;p&gt;这是霍金在2010出版的书，讲述近代纯物理学的一些研究成果以及围绕宇宙学来展开的一系列科普理论。&lt;br&gt;这个评价很高也让我了解到物理学是怎么
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="Read" scheme="https://csrjtan.github.io/tags/Read/"/>
    
  </entry>
  
  <entry>
    <title>CS231n-7</title>
    <link href="https://csrjtan.github.io/2016/06/09/CS231n-7/"/>
    <id>https://csrjtan.github.io/2016/06/09/CS231n-7/</id>
    <published>2016-06-09T06:33:36.000Z</published>
    <updated>2016-06-09T13:33:20.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;CNN&quot;&gt;&lt;a href=&quot;#CNN&quot; class=&quot;headerlink&quot; title=&quot;CNN&quot;&gt;&lt;/a&gt;CNN&lt;/h4&gt;&lt;p&gt;终于进入CNN的话题了，介绍一下CONV,POOL,FC层的做法，具体的结构、参数、运算量等。&lt;/p&gt;
&lt;p&gt;回顾一下，Mini-batch SGD&lt;br&gt;Loop: 1. &lt;strong&gt;Sample&lt;/strong&gt; a batch of data&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Forward&lt;/strong&gt; prop it through the graph, get loss&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Backprop&lt;/strong&gt; to calculate the gradients&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update&lt;/strong&gt; the parameters using the gradient&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609CNN.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;卷积操作过程的参数计算公式图，趋向于用数量更多的小Filter,更深的网络。&lt;br&gt;ConV的卷积核深度总是和输入的立方Feature Map的深度一致，而Kernel的个数就是新的FeatureMap的Depth.&lt;/p&gt;
&lt;p&gt;一般来说：Max Pool with 2*2 filters and stride 2&lt;/p&gt;
&lt;p&gt;FC： Containes Neurons connect to the entire input volume&lt;/p&gt;
&lt;p&gt;ConV的参数取决于Filter,例如227&lt;em&gt;227&lt;/em&gt;3通道的Feature Map,用Stride为4的96个Kernel 11&lt;em&gt;11 Filters,则有(11&lt;/em&gt;11&lt;em&gt;3)&lt;/em&gt;96=35K， Output Volum [((227-11)/4+1)&lt;em&gt;55&lt;/em&gt;96]&lt;/p&gt;
&lt;p&gt;Pool的参数为0，FC的参数最多.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609ALEX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2012的ALEXNET的网络架构&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609VGG.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2014的VGGNET网络架构和参数，主要占显存的是头几层的FeatureMap,而主要占用参数是FC层，VGG是初始化效果最佳的网络之一。&lt;br&gt;TOTAL MEMORY: 24M&lt;em&gt;4bytes ~= 93MB/image (Only forward!~&lt;/em&gt;2 for bwd)&lt;br&gt;TOTAL params: 138M parameters&lt;/p&gt;
&lt;p&gt;之后是GoogleNET(2014),6.7% for top5 error,12X less params than ALEXNET&lt;br&gt;然后是MSRA的RESNET（2015）， 3.6% top5 error, at runtime: faster than VGGNet&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609RES.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;特点：BN after every CONV, Xavier/2 for initialization, SGD+Momentum(0.9), Learning rate,0.1 and dived by 10 when validation error plateaus. Mini-batch size 256, Weight decay of 1e-5, No dropout&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;CNN&quot;&gt;&lt;a href=&quot;#CNN&quot; class=&quot;headerlink&quot; title=&quot;CNN&quot;&gt;&lt;/a&gt;CNN&lt;/h4&gt;&lt;p&gt;终于进入CNN的话题了，介绍一下CONV,POOL,FC层的做法，具体的结构、参数、运算量等。&lt;/p&gt;
&lt;p&gt;回顾一下，Mini-b
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_6</title>
    <link href="https://csrjtan.github.io/2016/06/09/CS231n-6/"/>
    <id>https://csrjtan.github.io/2016/06/09/CS231n-6/</id>
    <published>2016-06-09T04:34:02.000Z</published>
    <updated>2016-06-09T06:33:55.000Z</updated>
    
    <content type="html">&lt;p&gt;开始新一课之前，先来把上一节的相关阅读材料的知识补充上来。&lt;/p&gt;
&lt;h3 id=&quot;Lecture-5-Notes2-amp-3&quot;&gt;&lt;a href=&quot;#Lecture-5-Notes2-amp-3&quot; class=&quot;headerlink&quot; title=&quot;Lecture 5 Notes2&amp;amp;3&quot;&gt;&lt;/a&gt;Lecture 5 Notes2&amp;amp;3&lt;/h3&gt;&lt;h4 id=&quot;Regularization&quot;&gt;&lt;a href=&quot;#Regularization&quot; class=&quot;headerlink&quot; title=&quot;Regularization&quot;&gt;&lt;/a&gt;Regularization&lt;/h4&gt;&lt;p&gt;L1,L2的Loss function 还有Max Norm constraints: 对于系数向量w,有$w^2 &amp;lt; c$ ，C一般为3或4.&lt;br&gt;Dropout的技术：一般采用P=0.5,每个神经元的激活概率为0.5，然后每个样本对应一个新的Mask之后的子网络进行训练，最后测试的时候开启全部神经元但得到的结果需要乘上P=0.5这个系数。这种技术直观的好处是：1.迫使网络学习冗余的表达能力  2.实现了大型的学习模型，具有共享参数特性 &lt;/p&gt;
&lt;p&gt;Practice: 使用single,global L2 Regularization(cross-validated)+ Dropout(p=0.5)&lt;/p&gt;
&lt;h4 id=&quot;Loss-Functions&quot;&gt;&lt;a href=&quot;#Loss-Functions&quot; class=&quot;headerlink&quot; title=&quot;Loss Functions&quot;&gt;&lt;/a&gt;Loss Functions&lt;/h4&gt;&lt;p&gt;针对classification的任务，使用Softmax或者SVM Loss. 针对类别多的情况，可以使用Hierarchical Softmax. &lt;/p&gt;
&lt;p&gt;Attribute Classification可以用Logistic regression classifier with two classes(0,1)&lt;/p&gt;
&lt;p&gt;Regression任务，一般使用L2或者L1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;br&gt;When faced with a regression task, first consider if it is absolutely necessary. Instead, have a strong preference to discretizing your outputs to bins and perform classification over them whenever possible.
&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;Gradient-Checks&quot;&gt;&lt;a href=&quot;#Gradient-Checks&quot; class=&quot;headerlink&quot; title=&quot;Gradient Checks&quot;&gt;&lt;/a&gt;Gradient Checks&lt;/h4&gt;&lt;p&gt;Use centered formula,求梯度用左右方向的平均。$$\frac{df(x)}{dx} = \frac{f(x+h)-f(x-h)}{2h}$$&lt;/p&gt;
&lt;p&gt;Use relative error for the comparison, relative error&lt;br&gt;$$ \frac{ |f_a - f_n | }{max(f_a,f_n)} $$  . $f_a$ 为analytic gradient  , $f_n$ 为numberic gradient &lt;/p&gt;
&lt;p&gt;In practice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;relative error &amp;gt; 1e-2 usually means the gradient is probably wrong&lt;/li&gt;
&lt;li&gt;1e-2&amp;gt;relative error&amp;gt;1e-4 should make you feel uncomfortable&lt;/li&gt;
&lt;li&gt;1e-4&amp;gt;relative error is usually okay for objectives with kinks, but if there are no kinks(such tanh nonlinearities and softmax) , then 1e-4 is too high.&lt;/li&gt;
&lt;li&gt;1e-7 and less you should be happy&lt;/li&gt;
&lt;li&gt;if too small like or than 1e-10, absolute value is worrying&lt;br&gt;越深的网络，relative errors越大，如果10层，则1e-2是可以接受的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Summary: Careful with step size h, Gradcheck important, Don’t let regularization overwhelm the data, turn off the dropout/augmentations when gradient check, check only few dimensions.&lt;/p&gt;
&lt;h3 id=&quot;Lecture-6&quot;&gt;&lt;a href=&quot;#Lecture-6&quot; class=&quot;headerlink&quot; title=&quot;Lecture 6&quot;&gt;&lt;/a&gt;Lecture 6&lt;/h3&gt;&lt;h4 id=&quot;How-to-do-parameter-Updates&quot;&gt;&lt;a href=&quot;#How-to-do-parameter-Updates&quot; class=&quot;headerlink&quot; title=&quot;How to do parameter Updates&quot;&gt;&lt;/a&gt;How to do parameter Updates&lt;/h4&gt;&lt;p&gt;1.SGD: $x+= -learning rate *dx$&lt;br&gt;2.Momentum:  allow velocity build up, velocity damped in steep due to changing sign&lt;/p&gt;
&lt;p&gt;v = mu &lt;em&gt; v - learning_rate &lt;/em&gt; dx&lt;br&gt;x += v&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Nestreov Momentum:&lt;br&gt;$v_t = \mu v_{t-1} - \epsilon \Delta f(\theta_{t-1} + \mu V_{t-1})$&lt;br&gt;$\theta_t = \theta_{t-1} + V_t$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.Adagrad: Equalization the steep and shallow direction&lt;br&gt;cache + = dx &lt;em&gt;*2&lt;br&gt;x += - learn_rate &lt;/em&gt; dx / (sqrt(cache)+1e-7)&lt;/p&gt;
&lt;p&gt;5.Adam: Great enough with bias correct&lt;br&gt;m = beta1 &lt;em&gt; m + (1-beta1)&lt;/em&gt;dx&lt;br&gt;v = beta2 &lt;em&gt; v + (1-beta2)&lt;/em&gt;(dx &lt;em&gt;*2)&lt;br&gt;x += -learn_rate &lt;/em&gt; m/(sqrt(v)+1e-7)&lt;br&gt;一般beta1和beta2可以设置为0.9和0.995&lt;/p&gt;
&lt;h4 id=&quot;Second-Order-Optimization&quot;&gt;&lt;a href=&quot;#Second-Order-Optimization&quot; class=&quot;headerlink&quot; title=&quot;Second Order Optimization&quot;&gt;&lt;/a&gt;Second Order Optimization&lt;/h4&gt;&lt;p&gt;1.泰勒展开&lt;br&gt;2.Newton Gradient: Jacobian H is too large with O(n^3),n is million&lt;br&gt;3.Quasi-Newton O(n^2)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;L-BFGS(Limited Memory BFGS):work well in full patch,but can not transfoer well to mini-batch search.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Practice: 1.Train Multiple Indeoendent model&lt;br&gt;&lt;a href=&quot;http://2.At&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;2.At&lt;/a&gt; test time average the results &lt;/p&gt;
&lt;p&gt;Fun tricks: get small boost from average multiple initilization model, keep track running average parametre vector.&lt;/p&gt;
&lt;h4 id=&quot;Annealing-learning-rate&quot;&gt;&lt;a href=&quot;#Annealing-learning-rate&quot; class=&quot;headerlink&quot; title=&quot;Annealing learning rate&quot;&gt;&lt;/a&gt;Annealing learning rate&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;step dcay: learning rate by half every t epochs&lt;/li&gt;
&lt;li&gt;Exponential decay $\alpha = \alpha_0 e^{-kt}$&lt;/li&gt;
&lt;li&gt;1/t decay: $\alpha = \alpha_0 /(1+kt)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Hyperparameter-optimzation&quot;&gt;&lt;a href=&quot;#Hyperparameter-optimzation&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter optimzation&quot;&gt;&lt;/a&gt;Hyperparameter optimzation&lt;/h4&gt;&lt;p&gt;stage search from coarse to fine&lt;br&gt;bayesian hyperparameter optimization&lt;br&gt;Model ensemble, improve the performance of NN a few percent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Same Model, Different Initializations&lt;/li&gt;
&lt;li&gt;Top models discovered during cross-validation&lt;/li&gt;
&lt;li&gt;Different Checkpoints of a single model: Training is very expensive, taking the different checkpoints of single network and using those to form an ensemble.(Cheap and practice，选取一些好的epoch模型)&lt;/li&gt;
&lt;li&gt;Running averatge of parameters during training(用训练过程模型中的均值，直观来看在碗状徘徊，均值更有利于接近底部)&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h4&gt;&lt;p&gt;1.针对少量的样本，gradient check很重要，并注意正确的初始化&lt;br&gt;2.the magnitude of updates should be ~1e-3 in first-layer&lt;br&gt;3.推荐用SGD+Nesterov Momentum or Adam&lt;br&gt;4.Decay learning rate over the period of training&lt;br&gt;5.Search good hyperparameters with random search(not grid), stage coarse to fine&lt;br&gt;6.Form model ensembles for extra performance&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;开始新一课之前，先来把上一节的相关阅读材料的知识补充上来。&lt;/p&gt;
&lt;h3 id=&quot;Lecture-5-Notes2-amp-3&quot;&gt;&lt;a href=&quot;#Lecture-5-Notes2-amp-3&quot; class=&quot;headerlink&quot; title=&quot;Lecture 5 N
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>LDI-NAT《Color Demosaicking by Local Directional Interpolation and Nonlocal Adaptive Thresholding》</title>
    <link href="https://csrjtan.github.io/2016/06/07/paper-reading-20160607/"/>
    <id>https://csrjtan.github.io/2016/06/07/paper-reading-20160607/</id>
    <published>2016-06-07T07:51:31.000Z</published>
    <updated>2016-06-07T08:29:38.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;IDEA&quot;&gt;&lt;a href=&quot;#IDEA&quot; class=&quot;headerlink&quot; title=&quot;IDEA&quot;&gt;&lt;/a&gt;IDEA&lt;/h4&gt;&lt;p&gt;这是张老师11年的文章，效果也是很好的，至今依然不断拿来对比实验。Demosaick的做法还是初始化，然后建立CDM噪声模型，然后根据样本统计拟合出符合样本的实际值。（这个建模思路很耐用，其实还是为了更好的挖掘空域和频域信息的相关性）&lt;/p&gt;
&lt;p&gt;这里用Local Directional Interpolation(LDI)的方法进行复杂的梯度插值初始化，然后比较Non-local Minimize(NLM)的方法和Non-local Adaptive Thresholding（NAT）的方法。这里NLM是指扫描附近满足相似度的Patch，对这些patch进行distance weighted的使用；而NAT基于找到Non-local Similar Patch之后，用这些作为观测样本，在噪声模型里结合SVD、PCA的方法（假定满足Sparse），来进行分解，由于噪声v与x较少相关性，通过设定Adaptive Threshold来提取v的主成分，从而保证拟合的值更准确。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;LDI&quot;&gt;&lt;a href=&quot;#LDI&quot; class=&quot;headerlink&quot; title=&quot;LDI&quot;&gt;&lt;/a&gt;LDI&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI3.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI1.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI2.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;中间还有个$d_gr$的梯度影响因子，这种梯度的插值方法还是比较常见的。如上图，假设插值$R_0$，我们可以利用整块的CFA信息，通过和其它频段的信息如G的差来求出变化的梯度，如$\Delta_n$为$R_0$在北方向的梯度，距离远的影响少的原则，然后得到各个方向的梯度；根据梯度的大小作为权值来加权四方的color difference插值。&lt;/p&gt;
&lt;p&gt;这种方法在Color Demosaicking很常见，早期简单的方法是同一频段下的线性、双线性插值，然后利用其它频段的color difference或者color ratio来有效利用局部空间的信息，一般平滑的区域这个假设更有效，而对于变换剧烈的地方往往处理不好出现artifacts或者超过了采样原理。出现梯度变化最小的插值方法、多方向加权的插值方法等，复杂的空域插值方法、sparse adaptive的抑制噪声的插值方法等等&lt;/p&gt;
&lt;h4 id=&quot;NLM-Non-local-Minimum&quot;&gt;&lt;a href=&quot;#NLM-Non-local-Minimum&quot; class=&quot;headerlink&quot; title=&quot;NLM(Non-local Minimum)&quot;&gt;&lt;/a&gt;NLM(Non-local Minimum)&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607NLM.png&quot; alt=&quot;NLM&quot;&gt;&lt;br&gt;这个方法是要挖掘更多的Non-local信息，所以去寻找一些局部相似的Patch，因为CDM和DNS、SR等图像研究具有相似性，denoise BM3D的成功说明了图像上的Patch往往会具有相似性或者重复出现的，所以用简单的Minimum比较获得Similar Patch,再利用这些信息恢复当前Patch的信息。如这个方法里的distance weighted；也有看过一篇是直接correlated比当前patch高，且梯度更平滑，则直接用Non-local Patch恢复的pixel代替当前pixel等；&lt;/p&gt;
&lt;p&gt;上图就是用L1的patch distance确定similar patch,然后将这些恢复的值进行distance weighted加权。&lt;/p&gt;
&lt;h4 id=&quot;NAT&quot;&gt;&lt;a href=&quot;#NAT&quot; class=&quot;headerlink&quot; title=&quot;NAT&quot;&gt;&lt;/a&gt;NAT&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607NAT.png&quot; alt=&quot;NLM&quot;&gt;&lt;br&gt;这个在获得Non-local Similar patch之后，利用这些patch作为可靠的观测样本，进行CDM噪声模型的建立，从而采用PCA的方法获得optimal solution。&lt;/p&gt;
&lt;p&gt;这里的矩阵F范数是指矩阵的值绝对值相加再开平方，也就是观测和PCA值的误差尽可能少，而且主成分的个数也尽可能小；（满足sparse的假设）&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;IDEA&quot;&gt;&lt;a href=&quot;#IDEA&quot; class=&quot;headerlink&quot; title=&quot;IDEA&quot;&gt;&lt;/a&gt;IDEA&lt;/h4&gt;&lt;p&gt;这是张老师11年的文章，效果也是很好的，至今依然不断拿来对比实验。Demosaick的做法还是初始化，然后建立CDM噪声模型，然后根据样本统计拟合出符合样本的实际值。（这个建模思路很耐用，其实还是为了更好的挖掘空域和频域信息的相关性）&lt;/p&gt;
&lt;p&gt;这里用Local Directional Interpolation(LDI)的方法进行复杂的梯度插值初始化，然后比较Non-local Minimize(NLM)的方法和Non-local Adaptive Thresholding（NAT）的方法。这里NLM是指扫描附近满足相似度的Patch，对这些patch进行distance weighted的使用；而NAT基于找到Non-local Similar Patch之后，用这些作为观测样本，在噪声模型里结合SVD、PCA的方法（假定满足Sparse），来进行分解，由于噪声v与x较少相关性，通过设定Adaptive Threshold来提取v的主成分，从而保证拟合的值更准确。&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="Paper Demosaick" scheme="https://csrjtan.github.io/tags/Paper-Demosaick/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读《Residual Interpolation for color image demosaicking》</title>
    <link href="https://csrjtan.github.io/2016/06/06/paper-reading-20160606/"/>
    <id>https://csrjtan.github.io/2016/06/06/paper-reading-20160606/</id>
    <published>2016-06-06T12:19:45.000Z</published>
    <updated>2016-06-07T08:29:40.000Z</updated>
    
    <content type="html">&lt;p&gt;首先将东京工业大学新提出的基于Residual difference interpolation的几篇文章扫一遍，这是第一篇，提出residual difference rather than color difference&lt;br&gt;&lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;网站&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;idea&quot;&gt;&lt;a href=&quot;#idea&quot; class=&quot;headerlink&quot; title=&quot;idea&quot;&gt;&lt;/a&gt;idea&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606ri.png&quot; alt=&quot;主要流程&quot;&gt;&lt;br&gt;左边为正常的Demosaicking流程是：先fine-grained地对G通道插值，然后对R通道插值的时候，是根据R-G的谱间具有相似差异性的原理进行，得到delta,在插值过程中得到R图再把delta加上的过程。&lt;br&gt;现在RI提出直接使用G图做差值插值由于变换太过剧烈的地方会造成Artifact,如今用一些处理使得这个G变成G尖，这个G尖的图像满足平滑和准确的特性。如此利用这个谱间相关性的时候误差会更小，出来的效果更好。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;具体内容&quot;&gt;&lt;a href=&quot;#具体内容&quot; class=&quot;headerlink&quot; title=&quot;具体内容&quot;&gt;&lt;/a&gt;具体内容&lt;/h3&gt;&lt;p&gt;提出了Residual Interpolation基于GBTF的Demosaick初始化,这里用的是GBTF做G通道的初始化插值，然后Guided Filter得到G尖。我们来看看这两个论文。&lt;/p&gt;
&lt;h4 id=&quot;GBTF&quot;&gt;&lt;a href=&quot;#GBTF&quot; class=&quot;headerlink&quot; title=&quot;GBTF&quot;&gt;&lt;/a&gt;GBTF&lt;/h4&gt;&lt;p&gt;喔，这篇文章是基于我老板的DLMMSE文章优化，简要说一下老板的思路：先求出G-R和G-B图像在横竖方向上的differences，然后建立一个噪声估计模型，结合了optimal LMMSE的方法，直接将performance比以前提高了5个dp。（我老板就说那些人全都是瞎搞的。）这里GBTF提了DLMMSE两点缺陷：1.只利用了4-Neighbor的像素 2.将原来的两个方向解耦成四个方向 3.利用了较好的sparse adaptive初始化方法&lt;br&gt;实验的结论比LPA好0.14dB，比DLMMSE好0.64dB（基本上小打小闹的trick）.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606sp.png&quot; alt=&quot;Sparse Adaptive&quot;&gt;&lt;br&gt;在DLMMSE基础上，对G的插值使用了Gradient Weighted Based的方法，对R和B的通道使用了[3]的sparse adaptive interpolation(一定程度可以通道稀疏来抑制噪声，有空看看这篇什么鬼)。&lt;/p&gt;
&lt;h4 id=&quot;MMSE&quot;&gt;&lt;a href=&quot;#MMSE&quot; class=&quot;headerlink&quot; title=&quot;MMSE&quot;&gt;&lt;/a&gt;MMSE&lt;/h4&gt;&lt;p&gt;首先说一下这个优化方法，MMSE指Minimum Mean Square Error。问了一下师兄，懂了不少。&lt;br&gt;这个是一个知道函数形式，拟合参数的模型，y为Ground Truth,$\hat x(y)$ of x is any function of y. Model一个$MSE=tr{E{(\hat x-x)(\hat x=x)^T}}$ 则有$$\hat x_{MMSE}(y) = arg min_{\hat x}MSE$$&lt;br&gt;这个模型假定你知道了x与y的函数形式，用最小化MSE的方法求解函数的具体参数。&lt;/p&gt;
&lt;p&gt;传统的做法是假设函数形式，然后用Monte Carlo或者Gradient Descent去寻找最优解，但这样仍然需要评价指标。所以简单来说，一般用线性的模型可以变成Optimal LMMSE的问题。 $$min_{W,b}MSE \ \  s.t. \hat x = Wy+b$$&lt;br&gt;Optimal b and W is given by: $b = \overline x - W \overline y, W = C_{XY}C_Y^{-1}$ 然后用样本集的统计值来求解。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Minimum_mean_square_error&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;具体查看Wiki&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;DLMMSE&quot;&gt;&lt;a href=&quot;#DLMMSE&quot; class=&quot;headerlink&quot; title=&quot;DLMMSE&quot;&gt;&lt;/a&gt;DLMMSE&lt;/h4&gt;&lt;p&gt;这里老板借鉴了LMMSE即Linear MMSE的方法，来拟合PSD(pirmer signal difference)和LCC1初始化后的Vertical和Horizontal的噪声。这里有点复杂：首先理解了Demosaicking里面的Color Difference原理是利用了局部区域谱间差值为常量，这个协同性原理。然而这个差值为常量的假设并不准确，所以很多人在这个问题上面做文章。我们发现，有时候出现Artifact是因为变化过于剧烈，这里面已经超过了信号的采样原理，所以信息是丢失无法恢复的。我们只能加入一些约束和先验知识来弥补（后面扩展的工作）。所以这个PSD就是Color Difference并不准确，我们来拟合它。这里直接使用一个LCC1作为G通道插值的初始化，然后简单计算V和H方向上的梯度，与PSD相减得到误差$\epsilon$ 。&lt;br&gt;到这里，我们可以建模了，n代表位置，将x代表PSD,y代表我们拟合真正的结果，$\epsilon$就是初始化方法的误差。$$y(n) = x(n) + v(n)$$&lt;/p&gt;
&lt;p&gt;引入MMSE模型来求解拟合真正的x，y为数据观测值，传统MMSE未定形式不好求解，所以使用LMMSE,得到$\hat x = E[x] + \frac{Conv(x,y)}{Var(y)(y-E[y])}$,自然地假设x和v是为locally Gaussian processes,而且经验性地发现demosaicking noise $\epsilon_{g,r}^h$ 和 $\epsilon_{g,r}^v$为zero-mean random process,且uncorrelated with $\Delta_{g,r}$ (经过实验测出的，数值在0~0.08之间)所以可以简化式子为$$\hat x = \mu_x + \frac{\sigma_x^2}{(\sigma_x^2+\sigma_v^2)}(y-\mu_x)$$ 这里不用计算x的后验和真正样本的均值，因为基于上述假设，可以用x的期望代替了。Cov(x,y)用Cov(x)替代了。这样，我们就拟合预测出优化的PSD $\hat x$，用这个来拟合通道之间的信息更有效！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结:&lt;/strong&gt; LMMSE就是提出y和x的线性关系，然后根据最小MSE去根据观测样本的分布来拟合出符合分布的观测值$\hat x$，关键是用数据样本拟合出线性模型的参数，然后新来的样本经过模型得到拟合的值，会比原来观测的值更符合样本分布。（假设观测样本和预测样本是同分布的）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;看了源码&lt;/strong&gt;：可以看到在实现里面，先对图像做了横向和纵向的滤波，然后在8*8的patch里面进行LMMSE的求解拟合的。&lt;/p&gt;
&lt;h4 id=&quot;RI&quot;&gt;&lt;a href=&quot;#RI&quot; class=&quot;headerlink&quot; title=&quot;RI&quot;&gt;&lt;/a&gt;RI&lt;/h4&gt;&lt;p&gt;回到RI，想法也是拟合一个better PSD，只是这里的做法是用一个比较好的初始化方法，GBTF，在这个之上用了何大神的Guided Filter做平滑上采样（文中这么说），然后得到一个比较好的tentative estimate,用这个来拟合channel difference,取得了更好的效果，接下来就看一下这个guided filter和RI延伸出来的Improvement工作。&lt;/p&gt;
&lt;p&gt;RI在IMAX和Kodak的30张Images取得CPSNR 37.92dB&lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;[1]I. Pekkucuksen and Y. Altunbasak, “Gradient based threshold free color filter array interpolation,” Proc. of IEEE Int. Conf. on Image Processing (ICIP), pp. 137– 140, 2010.&lt;/p&gt;
&lt;p&gt;[2]Zhang, L. and X. Wu (2005). “Color demosaicking via directional linear minimum mean square-error estimation.” Image Processing, IEEE Transactions on 14(12): 2167-2178.&lt;/p&gt;
&lt;p&gt;[3] D. Paliy, V. Katkovnik, R. Bilcu, S. Alenius, and K. Egiazarian, “Spatially adaptive color filter array interpo- lation for noiseless and noisy data,” International Journal of Imaging Systems and Technology, vol. 17, no. 3, pp. 105-122, 2007.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;首先将东京工业大学新提出的基于Residual difference interpolation的几篇文章扫一遍，这是第一篇，提出residual difference rather than color difference&lt;br&gt;&lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot;&gt;网站&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;idea&quot;&gt;&lt;a href=&quot;#idea&quot; class=&quot;headerlink&quot; title=&quot;idea&quot;&gt;&lt;/a&gt;idea&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606ri.png&quot; alt=&quot;主要流程&quot;&gt;&lt;br&gt;左边为正常的Demosaicking流程是：先fine-grained地对G通道插值，然后对R通道插值的时候，是根据R-G的谱间具有相似差异性的原理进行，得到delta,在插值过程中得到R图再把delta加上的过程。&lt;br&gt;现在RI提出直接使用G图做差值插值由于变换太过剧烈的地方会造成Artifact,如今用一些处理使得这个G变成G尖，这个G尖的图像满足平滑和准确的特性。如此利用这个谱间相关性的时候误差会更小，出来的效果更好。&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="paper demosaick" scheme="https://csrjtan.github.io/tags/paper-demosaick/"/>
    
  </entry>
  
  <entry>
    <title>CS231n-4 &amp; 5</title>
    <link href="https://csrjtan.github.io/2016/06/06/CS231n-4/"/>
    <id>https://csrjtan.github.io/2016/06/06/CS231n-4/</id>
    <published>2016-06-06T06:05:56.000Z</published>
    <updated>2016-06-09T04:46:38.000Z</updated>
    
    <content type="html">&lt;p&gt;这节课主要讲述一下BP怎么做的&lt;/p&gt;
&lt;h3 id=&quot;BackProbagation&quot;&gt;&lt;a href=&quot;#BackProbagation&quot; class=&quot;headerlink&quot; title=&quot;BackProbagation&quot;&gt;&lt;/a&gt;BackProbagation&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606bp.png&quot; alt=&quot;简单BP&quot;&gt;&lt;br&gt;这里根据Chain Rule:$\frac{df}{dx} = \frac{df}{dq} \frac{dq}{dx}$&lt;br&gt;所以推算$\frac{df}{df} =1$, $\frac{df}{dz} = \frac{df}{df} \frac{df}{dz} = 1 &lt;em&gt; q = 3$, 同理得后面的梯度（求导中函数的x为当前neuron的值）&lt;br&gt;Add gate: Gradient Distributor&lt;br&gt;Max gate: Gradient Router(只有max的值获得梯度传递)&lt;br&gt;Mul gate: Gradient “Switcher”(Neuron交换了梯度)&lt;br&gt;BP Gradient = [Last Gradient] &lt;/em&gt; [Local Gradient]&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606bp1.png&quot; alt=&quot;Sigmoid BP&quot;&gt;&lt;br&gt;这里是用了Sigmoid作为Activation Function,可以看到梯度按照一层一层递推和直接对sigmoid function求导得到的值是一致的。$d\sigma (x)=\frac{1}{1+e^(-x)}$&lt;br&gt;$$\frac{d\sigma (x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = (1-\sigma (x))\sigma(x)$$&lt;/p&gt;
&lt;p&gt;[hints: 每个循环包括：更新BP和更新FP，因为每次BP是受当前FP的结果影响的]&lt;/p&gt;
&lt;p&gt;(Before) Linear: $ f= Wx $&lt;br&gt;(Now) 2-Layer NN: $f = W_2 max(0,W_1x) $&lt;/p&gt;
&lt;p&gt;Vectorized: 向量化后，W是一层高维的参数可能4096，若果输出层也为4096。Jacobian矩阵的大小将为4096 &lt;em&gt; 4096,而且一般按批量处理图片，如果Batch为100，则为100&lt;/em&gt; Size of Jacobian。&lt;/p&gt;
&lt;p&gt;参考阅读 &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Efficient BP by Lecun&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Lecture-5&quot;&gt;&lt;a href=&quot;#Lecture-5&quot; class=&quot;headerlink&quot; title=&quot;Lecture 5&quot;&gt;&lt;/a&gt;Lecture 5&lt;/h3&gt;&lt;h4 id=&quot;A-bit-History&quot;&gt;&lt;a href=&quot;#A-bit-History&quot; class=&quot;headerlink&quot; title=&quot;A bit History&quot;&gt;&lt;/a&gt;A bit History&lt;/h4&gt;&lt;p&gt;86年提出的BP算法如今大热，以往DEEP LEARNING主要网络复杂，无法收敛等问题，运算速度和数据也是考量的重要因素，导致停滞不前。如今随着实验对CNN等的认识，提出了很多有效训练和防止过拟合的方法。&lt;/p&gt;
&lt;p&gt;06年Hinton提出了RBM，先逐层做一个预训练，然后再整合成网络BP Fine-tuning，结果效果不错。&lt;/p&gt;
&lt;p&gt;10年的微软组增加了HMM在网络结构中，12年ALEX NET在IMAGE NET的成功引爆了潮流。&lt;/p&gt;
&lt;p&gt;如何做CNN：&lt;br&gt;&lt;a href=&quot;http://1.One&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;1.One&lt;/a&gt; time setup: activation functions, preprocessing, weight initialization, regularization, gradient checking&lt;br&gt;2.Traning Dynamics: babysitting the learning process, parameter updates, hyperparameter optimization&lt;br&gt;3.Evaluation: model ensembles&lt;/p&gt;
&lt;h4 id=&quot;Activation-Function&quot;&gt;&lt;a href=&quot;#Activation-Function&quot; class=&quot;headerlink&quot; title=&quot;Activation Function&quot;&gt;&lt;/a&gt;Activation Function&lt;/h4&gt;&lt;p&gt;研究对比激活函数：&lt;br&gt;Sigmoid: 1.Squashes range [0,1] 2.nice interpretation “firing rate”&lt;br&gt;三个重大问题：1.Saturated Neurons “Kill” the gradient&lt;br&gt;2.Sigmoid ouputs are not zero-centered(使得生成下层的输入x全部同号，这会导致Optimization的过程锯齿状)&lt;br&gt;3.exp computation is high&lt;/p&gt;
&lt;p&gt;tanh: 1.sqash among[-1,1]&lt;br&gt;      &lt;a href=&quot;http://2.zero&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;2.zero&lt;/a&gt; centered (nice)&lt;br&gt;      3.kills the gradient when saturated&lt;/p&gt;
&lt;p&gt;ReLU: 1.Does not saturate(in +region)&lt;br&gt;      2.computationally efficient&lt;br&gt;      3.converges mush faster&lt;br&gt;     but 1. Not zero-centered&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2. An annoyance: the gradient of &amp;lt;0 is killed
3. Some time will &amp;quot;dead&amp;quot;(大概为负值后，无法继续更新，注意学习步长不能过大)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Leaky ReLU:  $f(x) = max(\alpha x,x)$ some times $\alpha $ is 0.01&lt;br&gt;      will not die&lt;/p&gt;
&lt;p&gt;Exponential Linear Units(ELU):&lt;br&gt;      当 x &amp;lt; 0时, $f(x) = \alpha (exp(x)-1)$&lt;br&gt;     All benefit of ReLU, Closer to zero mean outputs, but requires exp()&lt;/p&gt;
&lt;p&gt;Maxout “Neuron”:&lt;br&gt;   $$max(w_1^Tx+b_1,w_2^Tx+b_2)$$&lt;br&gt;   Linear Regime, Generalizes ReLU and Leaky ReLU,但参数变成原来的两倍了&lt;/p&gt;
&lt;p&gt;总结： 一般用ReLU,可以尝试Leaky ReLU/Maxout/ELU,不要用sigmoid；tanh的性能也不行&lt;/p&gt;
&lt;h4 id=&quot;Data-Preprocessing&quot;&gt;&lt;a href=&quot;#Data-Preprocessing&quot; class=&quot;headerlink&quot; title=&quot;Data Preprocessing&quot;&gt;&lt;/a&gt;Data Preprocessing&lt;/h4&gt;&lt;p&gt;归一： Subtract Mean and Normalization, 一般图片会subtract mean 或subtract channel mean&lt;br&gt;降为： 用PCA和Whitening或者Leveraging的方法对高维数据做降为处理，但对于图像不常用&lt;/p&gt;
&lt;h4 id=&quot;Weight-Initalization-Important&quot;&gt;&lt;a href=&quot;#Weight-Initalization-Important&quot; class=&quot;headerlink&quot; title=&quot;Weight Initalization(Important)&quot;&gt;&lt;/a&gt;Weight Initalization(Important)&lt;/h4&gt;&lt;p&gt;这是过去被忽视，但十分重要的部分。&lt;br&gt;1.All zero: Neuron的结果、误差和更新是一致的，失败&lt;br&gt;2.Small Random Numbers(以0为mean,0.01variance的高斯分布)：Work okay but lead to non-homogeneous distributions of activations across the layers of network.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Variance=1, all the neurons completely saturated, either -1 or 1,Gradients will be all zero.&lt;/li&gt;
&lt;li&gt;Xavier Initialization(suitable so far): Variance = 1/sqrt(in_layer),Reasonable initialization assumes the linear activations.&lt;/li&gt;
&lt;li&gt;Note additional /2: Variance = 1/sqrt(in_layer/2)&lt;br&gt;这里的in_layer是指上层输入的个数，通过这样可以使得上层的分布和当层的分布趋同，经验性地提高收敛的比率&lt;br&gt;soon… Propoer Initialization is an active area of research&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Batch-Normalization&quot;&gt;&lt;a href=&quot;#Batch-Normalization&quot; class=&quot;headerlink&quot; title=&quot;Batch Normalization&quot;&gt;&lt;/a&gt;Batch Normalization&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606BN.png&quot; alt=&quot;BN&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improves gradient flow through the network&lt;/li&gt;
&lt;li&gt;Allows higher learning rates&lt;/li&gt;
&lt;li&gt;Reduces the strong dependence on initialization&lt;/li&gt;
&lt;li&gt;Acts as a form of regularization and slightly reduces the need for dropout(Maybe)&lt;br&gt;里面的scale和shift参数是通过Network自己学习的，归一化后重新根据学习需求调整数据分布的scale和shift.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;: At test time the BN layer differently: the mean/std are not computed based on the batch. Instead, a single fixed empirical mean of activations during training is used.&lt;/p&gt;
&lt;h4 id=&quot;Babysitting-the-Learning-Process&quot;&gt;&lt;a href=&quot;#Babysitting-the-Learning-Process&quot; class=&quot;headerlink&quot; title=&quot;Babysitting the Learning Process&quot;&gt;&lt;/a&gt;Babysitting the Learning Process&lt;/h4&gt;&lt;p&gt;一个课堂模拟的小CNN，做完预处理后，选择了50个hidden neurons，10个output neurons.用CIFAR-10,使用SGD梯度下降。关键是拟合小的数据集，举了实际遇到情况的判断和处理：1.small loss train accuracy 1.00（nice) 2.Loss barely changing(Learning Rating too small) 3.loss exploding to NaN or Inf(Learning Rating too high)&lt;/p&gt;
&lt;h4 id=&quot;Hyperparameter-Optimization&quot;&gt;&lt;a href=&quot;#Hyperparameter-Optimization&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter Optimization&quot;&gt;&lt;/a&gt;Hyperparameter Optimization&lt;/h4&gt;&lt;p&gt;1.Cross-Validation: Coarse-&amp;gt;fine&lt;br&gt;First Stage: only few epochs get a rough idea of what params work&lt;br&gt;Second Stage: Longer running time , finer search(Repeat as Necessary)&lt;br&gt;(Cost ever &amp;gt; 3*original cost, break out early)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is best to optimize in log space&lt;br&gt;Grid Search Vs Random Search: (random is better 2012)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;3.Hyperparameter play with: network architecture, learning rate, its decay schedule, update type, regularization(L2/Dropout strength)&lt;/p&gt;
&lt;p&gt;4.Monitor and Visualize the Loss curve(Big gap= Overfitting)&lt;/p&gt;
&lt;p&gt;5.Track the ratio of weight updates/weight magnitudes(Ratio 0.01 is okay)&lt;/p&gt;
&lt;h4 id=&quot;Side-Talks&quot;&gt;&lt;a href=&quot;#Side-Talks&quot; class=&quot;headerlink&quot; title=&quot;Side Talks&quot;&gt;&lt;/a&gt;Side Talks&lt;/h4&gt;&lt;p&gt;如何计算网络：神经元个数=逐层个数相加；W个数=累加（当层神经元个数*下层神经元个数），B个数=神经元个数&lt;/p&gt;
&lt;h4 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h4&gt;&lt;p&gt;推荐一个网络走的流程：&lt;br&gt;1.Activation Functions(Use ReLU)&lt;br&gt;2.Data Preprocessing(Subtract Mean)&lt;br&gt;3.Weight Initialization(Xavier (/2) init)&lt;br&gt;4.Batch Normalization(Use)&lt;br&gt;5.Hyperparameter Optimization(random sample hyperparams, In log space when proper)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将数据预处理为[-1,1],mean 0, val 1&lt;/li&gt;
&lt;li&gt;高斯初始化参数w, standaard deviation 为 $\sqrt{2/n}$, n为上层输入的神经元&lt;/li&gt;
&lt;li&gt;用L2和Dropout作正则化（记得用p调整回test output）&lt;/li&gt;
&lt;li&gt;使用Batch Normalization&lt;/li&gt;
&lt;li&gt;参考任务使用loss function&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;疑问点：&lt;br&gt;1.初始化方差为1/(sqrt(in)/2): 详细看何大神的&lt;a href=&quot;https://arxiv.org/abs/1502.01852&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文章&lt;/a&gt;&lt;br&gt;2.&lt;a href=&quot;http://arxiv.org/abs/1502.03167&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;BN&lt;/a&gt;和&lt;a href=&quot;http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Dropout&lt;/a&gt;都是近两年的工作，可以看看.Alex和Lecun还是CNN的先锋者，记得大师兄说，要多看Alex的文章。&lt;br&gt;3.&lt;a href=&quot;http://arxiv.org/pdf/1310.4546.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hiearachical Softmax&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考阅读:&lt;br&gt;&lt;a href=&quot;http://cs231n.github.io/neural-networks-2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NN notes2&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cs231n.github.io/neural-networks-3/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NN notes3&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这节课主要讲述一下BP怎么做的&lt;/p&gt;
&lt;h3 id=&quot;BackProbagation&quot;&gt;&lt;a href=&quot;#BackProbagation&quot; class=&quot;headerlink&quot; title=&quot;BackProbagation&quot;&gt;&lt;/a&gt;BackProbagation&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606bp.png&quot; alt=&quot;简单BP&quot;&gt;&lt;br&gt;这里根据Chain Rule:$\frac{df}{dx} = \frac{df}{dq} \frac{dq}{dx}$&lt;br&gt;所以推算$\frac{df}{df} =1$, $\frac{df}{dz} = \frac{df}{df} \frac{df}{dz} = 1 &lt;em&gt; q = 3$, 同理得后面的梯度（求导中函数的x为当前neuron的值）&lt;br&gt;Add gate: Gradient Distributor&lt;br&gt;Max gate: Gradient Router(只有max的值获得梯度传递)&lt;br&gt;Mul gate: Gradient “Switcher”(Neuron交换了梯度)&lt;br&gt;BP Gradient = [Last Gradient] &lt;/em&gt; [Local Gradient]&lt;br&gt;
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_3</title>
    <link href="https://csrjtan.github.io/2016/06/04/CS231n-3/"/>
    <id>https://csrjtan.github.io/2016/06/04/CS231n-3/</id>
    <published>2016-06-04T10:36:58.000Z</published>
    <updated>2016-06-07T03:13:56.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;一-Loss-Function&quot;&gt;&lt;a href=&quot;#一-Loss-Function&quot; class=&quot;headerlink&quot; title=&quot;一.Loss Function&quot;&gt;&lt;/a&gt;一.Loss Function&lt;/h4&gt;&lt;p&gt;定义Multiclass SVM loss: $L_i = \sum_{j\neq y_i} max(0,s_j-s_{y_i}+1)$&lt;br&gt;这里，$L_i$为针对类别i的Loss值，$s_j$是除了i的其他类别得分,$y_i$为当前目标类别，$s_{y_i}$ 为当前目标类别得分&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060401.png&quot; alt=&quot;SVM loss&quot;&gt;&lt;br&gt;Full Training Loss为取平均,$L=\frac{1}{N}\sum_{i=1}^N L_i$ ,则L=（2.9+0+10.9）/3= 4.6&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;SoftMax function: $\frac{e^{s_k}}{\sum_j e^{s_j}}$&lt;br&gt;这里的SVM loss存在一个问题，w可能不是唯一存在满足L最小的，比如w=w*2,L依然为0，但w已经放大了两倍，如图；这里我们加入正则项$\alpha R(w)$,其中$\alpha$为训练误差和模型复杂度的调整系数&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060402.png&quot; alt=&quot;SVM loss Bug&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里提到了loss function的选择：对于loss function的值全体做shift和scale是不会影响梯度的，而max/min则导致最后收敛时候梯度无限小。&lt;/p&gt;
&lt;p&gt;关于正则项的使用，如SVM Loss： $L = \frac{1}{N}\sum_{i=1}^N\sum_{j\neq y_i}max(0,f(x_i;W)_j-f(x_i;W)_{y_i}+1)+\lambda R(W)$ ,called &lt;strong&gt;hinge loss&lt;/strong&gt;,而L2-SVM则$max(0,-)^2$则放大惩罚误差。这里的1是$\Delta$，指正确样本到非正确样本的Margin&lt;br&gt;常用的正则向&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2: $R(W) = \sum_k\sum_l W_{k,l}^2$&lt;/li&gt;
&lt;li&gt;L1: $R(W) = \sum_k\sum_l |W_{k,l}|$&lt;/li&gt;
&lt;li&gt;Elastic Net (L1+L2): $R(W)=\sum_k\sum_l \beta W_{k,l}^2 + |W_{k,l}|$&lt;/li&gt;
&lt;li&gt;Max Norm Regularization&lt;/li&gt;
&lt;li&gt;Dropout&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Softmax Classifier(Multinomial Logistic Regression)&lt;/strong&gt;: $$ L_i = -log(\frac{e^{s_{y_i}}}{\sum_j e^{s_j}})$$ ,这里Softmax是满足Minimizing the cross-entropy between estimated class probabilities and “true” distribution,从信息学的角度来说，是一个好的loss function.&lt;a href=&quot;http://cs231n.github.io/linear-classify/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Loss Function Noetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Practical Tips: $\delta$和$\lambda$ 的trade off是相关的，所以可以fix one and only tuned another one&lt;/p&gt;
&lt;h4 id=&quot;二-Optimization&quot;&gt;&lt;a href=&quot;#二-Optimization&quot; class=&quot;headerlink&quot; title=&quot;二.Optimization&quot;&gt;&lt;/a&gt;二.Optimization&lt;/h4&gt;&lt;p&gt;得到合适的Loss Function后，如何最小化呢？使用到Optimization的方法了.&lt;br&gt;1.Random Search(Stupid)：瞎走&lt;br&gt;2.Random Local Search(这里还有很多AI的Search算法)&lt;br&gt;3.Gradient Descent（都在用的）: 沿着梯度下降，如果Loss是Convex Function,有Global Minimize;否则可能只能到达Local Minimize；如何走，也有很多学问，下一节课说。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;: 1.逐点weights,添加步长更新，Numerical Gradient: Approximate,Slow but easy  2.矩阵求导更新，Analytic Gradient: Exact, Fast but error-prone. （有时候陷入病态，无法求导或者导数太小）&lt;br&gt;[Practical Tips：用Analytic gradient but check the implementation compared with numerical gradient, called “&lt;strong&gt;Gradient Check&lt;/strong&gt;“&lt;/p&gt;
&lt;p&gt;Mini-Batch Gradient Descent: 对样本批量做，求平均更新；一般size为32/64/126，ALEX NET用了256；这里Batch过小，导致收敛漂移，陷入病态；Batch过大，则权值更新缓慢，优化过程长。&lt;/p&gt;
&lt;p&gt;调参：Suitable Learning Rate, BatchSize, Regularization&lt;/p&gt;
&lt;p&gt;题外话：回顾了一下CV上的Image Feature, Hue Histogram: 区块直方图统计，缺乏结构信息； HoG/Sift: Artifact Feature; BoW:对Feature学一个字典重新有效表示Image.&lt;/p&gt;
&lt;p&gt;SVM是一个凸优化问题，但CNN不是，所以注意凸优化里面的方法不一定适用于CNN。&lt;/p&gt;
&lt;p&gt;关于Gradient Descent的Practical considerations: 1.使用左右两端的导数值会更优,$[f(x+h)-f(x-h)]/2h$; 2.注意是往梯度的反方向更新，因为是下降 3.有效的更新步长（重要的学习参数）&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一-Loss-Function&quot;&gt;&lt;a href=&quot;#一-Loss-Function&quot; class=&quot;headerlink&quot; title=&quot;一.Loss Function&quot;&gt;&lt;/a&gt;一.Loss Function&lt;/h4&gt;&lt;p&gt;定义Multiclass SVM loss: $L_i = \sum_{j\neq y_i} max(0,s_j-s_{y_i}+1)$&lt;br&gt;这里，$L_i$为针对类别i的Loss值，$s_j$是除了i的其他类别得分,$y_i$为当前目标类别，$s_{y_i}$ 为当前目标类别得分&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060401.png&quot; alt=&quot;SVM loss&quot;&gt;&lt;br&gt;Full Training Loss为取平均,$L=\frac{1}{N}\sum_{i=1}^N L_i$ ,则L=（2.9+0+10.9）/3= 4.6&lt;br&gt;
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_1 &amp; 2</title>
    <link href="https://csrjtan.github.io/2016/06/03/CS231n-1/"/>
    <id>https://csrjtan.github.io/2016/06/03/CS231n-1/</id>
    <published>2016-06-03T04:53:24.000Z</published>
    <updated>2016-06-07T03:14:03.000Z</updated>
    
    <content type="html">&lt;p&gt;回来积极投身CNN的学习和研究中，受到博后哥哥宪标的推荐，毅然决然去学习standford CS231n关于CNN的公开课CNN for Visual Recognition，主要由飞飞姐和Karpathy、Johnson主讲，&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ngXbD21b4qk&amp;amp;index=2&amp;amp;list=PLrZmhn8sSgye6ijhLzIIXiU9GNaIwbF8B&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Youtube视频&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cs231n.stanford.edu/syllabus.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;课程主页&lt;/a&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;第一课-Introduction&quot;&gt;&lt;a href=&quot;#第一课-Introduction&quot; class=&quot;headerlink&quot; title=&quot;第一课 Introduction&quot;&gt;&lt;/a&gt;第一课 Introduction&lt;/h3&gt;&lt;p&gt;首先不出意外地第一节课是Introduction,飞飞对CV的研究发展历史给出了一个比较中肯的conclusion,从生物视觉的起源到Da Vinci的摄影技术以及第一篇CV phd Thesis. 主要提到了计算机视觉围绕主要的问题，有一个宏观意义上的认识。物体是识别、分类、切割、定位等，还能延伸出许多的子问题。&lt;/p&gt;
&lt;h4 id=&quot;经典工作&quot;&gt;&lt;a href=&quot;#经典工作&quot; class=&quot;headerlink&quot; title=&quot;经典工作&quot;&gt;&lt;/a&gt;经典工作&lt;/h4&gt;&lt;p&gt;这里关键读一下CV历史上影响巨大的几篇文章：&lt;br&gt;一.AdaBoost Face Detection:使得人脸的识别可以实时应用，主要Contribution:1.Harr特征的边缘提取 2.积分图的快速计算 3.AdaBoost的学习分类器&lt;br&gt;二.SIFT：Lowe大神经典之作，每个CV人都知道的图片经典特征点,具有shift、rotate、scale不变性：1.构建高斯图像金字塔 2.提取特征点 3.特征描述子的建立&lt;br&gt;三.金字塔匹配：CVPR06工作，将图片分块成多个空间金字塔，从而结合BoW等技术进行有效的匹配和分类&lt;/p&gt;
&lt;p&gt;ImageNet主要关注在CV核心问题，图像识别和分类定位等问题。起初使用的模型一般是提取特征点-&amp;gt;建立字典和模型-&amp;gt;学习分类算法(SVM)-&amp;gt;预测结果；如今DL的火热，使得CNN成为研究CV的主工具。&lt;/p&gt;
&lt;h4 id=&quot;关于CNN的工作&quot;&gt;&lt;a href=&quot;#关于CNN的工作&quot; class=&quot;headerlink&quot; title=&quot;关于CNN的工作&quot;&gt;&lt;/a&gt;关于CNN的工作&lt;/h4&gt;&lt;p&gt;1.LeCun大神的MNIST文字识别库，文章比较了多种ML方法在库上的表现，当年使用的CNN达到了非常好的效果，但具有训练速度慢、收敛难等问题&lt;br&gt;2.ImageNet12上，AlexNet这篇经典的CNN文章引爆了潮流，主要使用ReLU、GPU加速、LRN、Data Augument等技术使得CNN避免Overfitting，方便梯度传递，加速训练、解决DL收敛困难的主要问题，在比赛上获得惊人的效果。&lt;/p&gt;
&lt;h4 id=&quot;课程的Pre-Requisite&quot;&gt;&lt;a href=&quot;#课程的Pre-Requisite&quot; class=&quot;headerlink&quot; title=&quot;课程的Pre-Requisite&quot;&gt;&lt;/a&gt;课程的Pre-Requisite&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;high proficiency in python和c++&lt;/li&gt;
&lt;li&gt;Linear Algebra&lt;/li&gt;
&lt;li&gt;Machine Learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;第二课-Classification&quot;&gt;&lt;a href=&quot;#第二课-Classification&quot; class=&quot;headerlink&quot; title=&quot;第二课 Classification&quot;&gt;&lt;/a&gt;第二课 Classification&lt;/h3&gt;&lt;h4 id=&quot;Image-Classification&quot;&gt;&lt;a href=&quot;#Image-Classification&quot; class=&quot;headerlink&quot; title=&quot;Image Classification&quot;&gt;&lt;/a&gt;Image Classification&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;http://cs231n.github.io/classification/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ImageClassification Tutorial&lt;/a&gt;&lt;br&gt;Challenges:Viewpoint Variation, Scale Variation, Deformation, Occlusion, Iluumnation conditions, Background Clutter, Intra-class Variation.（图像识别的经典难点）&lt;/p&gt;
&lt;p&gt;Data-Driven Approach: Input-&amp;gt;Learning-&amp;gt;Evaluation&lt;br&gt;根据训练样本的学习出来模型，从而对新来的样本进行分类识别的方法&lt;/p&gt;
&lt;p&gt;Nearest Neighbor Classifier,具体为KNN: 1.Distance Metric的选择 2.k值的选择（根据Cross Validation,e.g. 5-fold cross-validation）,从训练集中切成5份，轮着用一份训练，剩余四份Evaluate,从而调整hyperParameters&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060301.png&quot; alt=&quot;k-fold分析图&quot;&gt;，对于一般性的数据集，K在4-7取得更加的效果，K越大越smooth,expensive也越大&lt;/p&gt;
&lt;p&gt;[tips:Evaluate on the test set only a single time, at the very end.确保最后才使用testSets,避免overfit for testSets,保证了模型的generlzation]&lt;/p&gt;
&lt;p&gt;Ads: Easy to understand and implement&lt;br&gt;Draws: Pay computational cost at test time(因此提出了ANN的近似加速，还有FLANN的库)&lt;br&gt;Pixel-based distances on high-dimensional data can be very unintuitive.(不适用，就像图片平移或者出现Artifacts等情况，但pixel-based distance是不适应人眼的;这里karpathy用了t-SNE对CIFAR-10的图片作了一个分布排列，相似的放在一起，可以看到背景相似但内容不一的东西反而靠在一起了)&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060303.jpg&quot; alt=&quot;t-SNE对CIFAR-10的分布&quot;&gt;&lt;br&gt;cons: suit for the low-dimensional data&lt;/p&gt;
&lt;p&gt;Summary: 1.Introduce the problem of image classification, image mapping label&lt;br&gt;2.introduce the NN classifier&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using validation set for tuning the hyperparameters, split training data into two: a training set and a fake test set. Try different hyperparameter values&lt;/li&gt;
&lt;li&gt;Once the parameter found, we fixed and use actual test set to evaluation&lt;/li&gt;
&lt;li&gt;the NN only get about 40% accuracy on CIFAR-10, while human achieve 94% and CNN achieve already 95%!&lt;/li&gt;
&lt;li&gt;the L1 or L2 distances on raw pixel is not adequate since more strongly relative with backgrounds and color distributions rather than semantic content&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Practice-with-kNN&quot;&gt;&lt;a href=&quot;#Practice-with-kNN&quot; class=&quot;headerlink&quot; title=&quot;Practice with kNN:&quot;&gt;&lt;/a&gt;Practice with kNN:&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;Preprocessing: Normalize the data in zero mean and unit variance&lt;/li&gt;
&lt;li&gt;If the data is high dimensional, using dimensionality reduction technique such as PCA or even Random Projections&lt;/li&gt;
&lt;li&gt;Split your traiing data randomly into train/val splits. About 70%~90% of data usually goes to the train split. It depens on how many hyperparameters you have and how much influence you expect them to have. (Cross-validation with the more folds the better, but more expensive)&lt;/li&gt;
&lt;li&gt;Train and evaluate kNN on validation data for many choices of k and across different distance types(暴力人为去尝试，加上自己实验的理解)&lt;/li&gt;
&lt;li&gt;If kNN running too long, consider using ANN library(FLANN, cost of some accuracy)&lt;/li&gt;
&lt;li&gt;Normaly do not use the validation set into the training data, we burned it for unestimated influence. Then evaluate with the test set and report the result as the performance of the kNN models.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Linear-Claissification&quot;&gt;&lt;a href=&quot;#Linear-Claissification&quot; class=&quot;headerlink&quot; title=&quot;Linear Claissification&quot;&gt;&lt;/a&gt;Linear Claissification&lt;/h4&gt;&lt;p&gt;kNN disadvantages: 1.需要存储training data for comparison&lt;br&gt;                   2.与数据库comparison十分耗时&lt;/p&gt;
&lt;p&gt;Using a score function and loss function to build a powerful model rather than the kNN&lt;br&gt;$f(x_i,W,b) = Wx_i+b$&lt;/p&gt;
&lt;p&gt;这里主要把W,b的参数学习，x为图片输入，将像素和通道展开成一维超长向量，假设有10类，则b为【10*1】为，得到一个10维的向量，分别表示对应类别的得分。如此一来，新来样本分类只要计算一个矩阵乘法和向量加法就得到结果了，比原先kNN不知道快到哪里去。&lt;/p&gt;
&lt;p&gt;思考：这里Linear Classification相当于做了什么，怎么去理解？1.学习了对应类别的一个模板匹配 2.在高维度空间对数据样本做线性分类学习（有点像SVM)&lt;br&gt;这里将学习得到的Linear Classification再重新可视化之后，得到以下的结果&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060302.png&quot; alt=&quot;类别模板可视化&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;回来积极投身CNN的学习和研究中，受到博后哥哥宪标的推荐，毅然决然去学习standford CS231n关于CNN的公开课CNN for Visual Recognition，主要由飞飞姐和Karpathy、Johnson主讲，&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ngXbD21b4qk&amp;amp;index=2&amp;amp;list=PLrZmhn8sSgye6ijhLzIIXiU9GNaIwbF8B&quot;&gt;Youtube视频&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cs231n.stanford.edu/syllabus.html&quot;&gt;课程主页&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
</feed>
