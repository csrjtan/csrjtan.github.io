<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CSRJTAN</title>
  <subtitle>Keep Moving</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://csrjtan.github.io/"/>
  <updated>2016-06-07T08:29:38.000Z</updated>
  <id>https://csrjtan.github.io/</id>
  
  <author>
    <name>CsrjTan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LDI-NAT《Color Demosaicking by Local Directional Interpolation and Nonlocal Adaptive Thresholding》</title>
    <link href="https://csrjtan.github.io/2016/06/07/paper-reading-20160607/"/>
    <id>https://csrjtan.github.io/2016/06/07/paper-reading-20160607/</id>
    <published>2016-06-07T07:51:31.000Z</published>
    <updated>2016-06-07T08:29:38.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;IDEA&quot;&gt;&lt;a href=&quot;#IDEA&quot; class=&quot;headerlink&quot; title=&quot;IDEA&quot;&gt;&lt;/a&gt;IDEA&lt;/h4&gt;&lt;p&gt;这是张老师11年的文章，效果也是很好的，至今依然不断拿来对比实验。Demosaick的做法还是初始化，然后建立CDM噪声模型，然后根据样本统计拟合出符合样本的实际值。（这个建模思路很耐用，其实还是为了更好的挖掘空域和频域信息的相关性）&lt;/p&gt;
&lt;p&gt;这里用Local Directional Interpolation(LDI)的方法进行复杂的梯度插值初始化，然后比较Non-local Minimize(NLM)的方法和Non-local Adaptive Thresholding（NAT）的方法。这里NLM是指扫描附近满足相似度的Patch，对这些patch进行distance weighted的使用；而NAT基于找到Non-local Similar Patch之后，用这些作为观测样本，在噪声模型里结合SVD、PCA的方法（假定满足Sparse），来进行分解，由于噪声v与x较少相关性，通过设定Adaptive Threshold来提取v的主成分，从而保证拟合的值更准确。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;LDI&quot;&gt;&lt;a href=&quot;#LDI&quot; class=&quot;headerlink&quot; title=&quot;LDI&quot;&gt;&lt;/a&gt;LDI&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI3.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI1.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI2.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;中间还有个$d_gr$的梯度影响因子，这种梯度的插值方法还是比较常见的。如上图，假设插值$R_0$，我们可以利用整块的CFA信息，通过和其它频段的信息如G的差来求出变化的梯度，如$\Delta_n$为$R_0$在北方向的梯度，距离远的影响少的原则，然后得到各个方向的梯度；根据梯度的大小作为权值来加权四方的color difference插值。&lt;/p&gt;
&lt;p&gt;这种方法在Color Demosaicking很常见，早期简单的方法是同一频段下的线性、双线性插值，然后利用其它频段的color difference或者color ratio来有效利用局部空间的信息，一般平滑的区域这个假设更有效，而对于变换剧烈的地方往往处理不好出现artifacts或者超过了采样原理。出现梯度变化最小的插值方法、多方向加权的插值方法等，复杂的空域插值方法、sparse adaptive的抑制噪声的插值方法等等&lt;/p&gt;
&lt;h4 id=&quot;NLM-Non-local-Minimum&quot;&gt;&lt;a href=&quot;#NLM-Non-local-Minimum&quot; class=&quot;headerlink&quot; title=&quot;NLM(Non-local Minimum)&quot;&gt;&lt;/a&gt;NLM(Non-local Minimum)&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607NLM.png&quot; alt=&quot;NLM&quot;&gt;&lt;br&gt;这个方法是要挖掘更多的Non-local信息，所以去寻找一些局部相似的Patch，因为CDM和DNS、SR等图像研究具有相似性，denoise BM3D的成功说明了图像上的Patch往往会具有相似性或者重复出现的，所以用简单的Minimum比较获得Similar Patch,再利用这些信息恢复当前Patch的信息。如这个方法里的distance weighted；也有看过一篇是直接correlated比当前patch高，且梯度更平滑，则直接用Non-local Patch恢复的pixel代替当前pixel等；&lt;/p&gt;
&lt;p&gt;上图就是用L1的patch distance确定similar patch,然后将这些恢复的值进行distance weighted加权。&lt;/p&gt;
&lt;h4 id=&quot;NAT&quot;&gt;&lt;a href=&quot;#NAT&quot; class=&quot;headerlink&quot; title=&quot;NAT&quot;&gt;&lt;/a&gt;NAT&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607NAT.png&quot; alt=&quot;NLM&quot;&gt;&lt;br&gt;这个在获得Non-local Similar patch之后，利用这些patch作为可靠的观测样本，进行CDM噪声模型的建立，从而采用PCA的方法获得optimal solution。&lt;/p&gt;
&lt;p&gt;这里的矩阵F范数是指矩阵的值绝对值相加再开平方，也就是观测和PCA值的误差尽可能少，而且主成分的个数也尽可能小；（满足sparse的假设）&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;IDEA&quot;&gt;&lt;a href=&quot;#IDEA&quot; class=&quot;headerlink&quot; title=&quot;IDEA&quot;&gt;&lt;/a&gt;IDEA&lt;/h4&gt;&lt;p&gt;这是张老师11年的文章，效果也是很好的，至今依然不断拿来对比实验。Demosaick的做法还是初始化，然后建立CDM噪声模型，然后根据样本统计拟合出符合样本的实际值。（这个建模思路很耐用，其实还是为了更好的挖掘空域和频域信息的相关性）&lt;/p&gt;
&lt;p&gt;这里用Local Directional Interpolation(LDI)的方法进行复杂的梯度插值初始化，然后比较Non-local Minimize(NLM)的方法和Non-local Adaptive Thresholding（NAT）的方法。这里NLM是指扫描附近满足相似度的Patch，对这些patch进行distance weighted的使用；而NAT基于找到Non-local Similar Patch之后，用这些作为观测样本，在噪声模型里结合SVD、PCA的方法（假定满足Sparse），来进行分解，由于噪声v与x较少相关性，通过设定Adaptive Threshold来提取v的主成分，从而保证拟合的值更准确。&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="Paper Demosaick" scheme="https://csrjtan.github.io/tags/Paper-Demosaick/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读《Residual Interpolation for color image demosaicking》</title>
    <link href="https://csrjtan.github.io/2016/06/06/paper-reading-20160606/"/>
    <id>https://csrjtan.github.io/2016/06/06/paper-reading-20160606/</id>
    <published>2016-06-06T12:19:45.000Z</published>
    <updated>2016-06-07T08:29:40.000Z</updated>
    
    <content type="html">&lt;p&gt;首先将东京工业大学新提出的基于Residual difference interpolation的几篇文章扫一遍，这是第一篇，提出residual difference rather than color difference&lt;br&gt;&lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;网站&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;idea&quot;&gt;&lt;a href=&quot;#idea&quot; class=&quot;headerlink&quot; title=&quot;idea&quot;&gt;&lt;/a&gt;idea&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606ri.png&quot; alt=&quot;主要流程&quot;&gt;&lt;br&gt;左边为正常的Demosaicking流程是：先fine-grained地对G通道插值，然后对R通道插值的时候，是根据R-G的谱间具有相似差异性的原理进行，得到delta,在插值过程中得到R图再把delta加上的过程。&lt;br&gt;现在RI提出直接使用G图做差值插值由于变换太过剧烈的地方会造成Artifact,如今用一些处理使得这个G变成G尖，这个G尖的图像满足平滑和准确的特性。如此利用这个谱间相关性的时候误差会更小，出来的效果更好。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;具体内容&quot;&gt;&lt;a href=&quot;#具体内容&quot; class=&quot;headerlink&quot; title=&quot;具体内容&quot;&gt;&lt;/a&gt;具体内容&lt;/h3&gt;&lt;p&gt;提出了Residual Interpolation基于GBTF的Demosaick初始化,这里用的是GBTF做G通道的初始化插值，然后Guided Filter得到G尖。我们来看看这两个论文。&lt;/p&gt;
&lt;h4 id=&quot;GBTF&quot;&gt;&lt;a href=&quot;#GBTF&quot; class=&quot;headerlink&quot; title=&quot;GBTF&quot;&gt;&lt;/a&gt;GBTF&lt;/h4&gt;&lt;p&gt;喔，这篇文章是基于我老板的DLMMSE文章优化，简要说一下老板的思路：先求出G-R和G-B图像在横竖方向上的differences，然后建立一个噪声估计模型，结合了optimal LMMSE的方法，直接将performance比以前提高了5个dp。（我老板就说那些人全都是瞎搞的。）这里GBTF提了DLMMSE两点缺陷：1.只利用了4-Neighbor的像素 2.将原来的两个方向解耦成四个方向 3.利用了较好的sparse adaptive初始化方法&lt;br&gt;实验的结论比LPA好0.14dB，比DLMMSE好0.64dB（基本上小打小闹的trick）.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606sp.png&quot; alt=&quot;Sparse Adaptive&quot;&gt;&lt;br&gt;在DLMMSE基础上，对G的插值使用了Gradient Weighted Based的方法，对R和B的通道使用了[3]的sparse adaptive interpolation(一定程度可以通道稀疏来抑制噪声，有空看看这篇什么鬼)。&lt;/p&gt;
&lt;h4 id=&quot;MMSE&quot;&gt;&lt;a href=&quot;#MMSE&quot; class=&quot;headerlink&quot; title=&quot;MMSE&quot;&gt;&lt;/a&gt;MMSE&lt;/h4&gt;&lt;p&gt;首先说一下这个优化方法，MMSE指Minimum Mean Square Error。问了一下师兄，懂了不少。&lt;br&gt;这个是一个知道函数形式，拟合参数的模型，y为Ground Truth,$\hat x(y)$ of x is any function of y. Model一个$MSE=tr{E{(\hat x-x)(\hat x=x)^T}}$ 则有$$\hat x_{MMSE}(y) = arg min_{\hat x}MSE$$&lt;br&gt;这个模型假定你知道了x与y的函数形式，用最小化MSE的方法求解函数的具体参数。&lt;/p&gt;
&lt;p&gt;传统的做法是假设函数形式，然后用Monte Carlo或者Gradient Descent去寻找最优解，但这样仍然需要评价指标。所以简单来说，一般用线性的模型可以变成Optimal LMMSE的问题。 $$min_{W,b}MSE \ \  s.t. \hat x = Wy+b$$&lt;br&gt;Optimal b and W is given by: $b = \overline x - W \overline y, W = C_{XY}C_Y^{-1}$ 然后用样本集的统计值来求解。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Minimum_mean_square_error&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;具体查看Wiki&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;DLMMSE&quot;&gt;&lt;a href=&quot;#DLMMSE&quot; class=&quot;headerlink&quot; title=&quot;DLMMSE&quot;&gt;&lt;/a&gt;DLMMSE&lt;/h4&gt;&lt;p&gt;这里老板借鉴了LMMSE即Linear MMSE的方法，来拟合PSD(pirmer signal difference)和LCC1初始化后的Vertical和Horizontal的噪声。这里有点复杂：首先理解了Demosaicking里面的Color Difference原理是利用了局部区域谱间差值为常量，这个协同性原理。然而这个差值为常量的假设并不准确，所以很多人在这个问题上面做文章。我们发现，有时候出现Artifact是因为变化过于剧烈，这里面已经超过了信号的采样原理，所以信息是丢失无法恢复的。我们只能加入一些约束和先验知识来弥补（后面扩展的工作）。所以这个PSD就是Color Difference并不准确，我们来拟合它。这里直接使用一个LCC1作为G通道插值的初始化，然后简单计算V和H方向上的梯度，与PSD相减得到误差$\epsilon$ 。&lt;br&gt;到这里，我们可以建模了，n代表位置，将x代表PSD,y代表我们拟合真正的结果，$\epsilon$就是初始化方法的误差。$$y(n) = x(n) + v(n)$$&lt;/p&gt;
&lt;p&gt;引入MMSE模型来求解拟合真正的x，y为数据观测值，传统MMSE未定形式不好求解，所以使用LMMSE,得到$\hat x = E[x] + \frac{Conv(x,y)}{Var(y)(y-E[y])}$,自然地假设x和v是为locally Gaussian processes,而且经验性地发现demosaicking noise $\epsilon_{g,r}^h$ 和 $\epsilon_{g,r}^v$为zero-mean random process,且uncorrelated with $\Delta_{g,r}$ (经过实验测出的，数值在0~0.08之间)所以可以简化式子为$$\hat x = \mu_x + \frac{\sigma_x^2}{(\sigma_x^2+\sigma_v^2)}(y-\mu_x)$$ 这里不用计算x的后验和真正样本的均值，因为基于上述假设，可以用x的期望代替了。Cov(x,y)用Cov(x)替代了。这样，我们就拟合预测出优化的PSD $\hat x$，用这个来拟合通道之间的信息更有效！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结:&lt;/strong&gt; LMMSE就是提出y和x的线性关系，然后根据最小MSE去根据观测样本的分布来拟合出符合分布的观测值$\hat x$，关键是用数据样本拟合出线性模型的参数，然后新来的样本经过模型得到拟合的值，会比原来观测的值更符合样本分布。（假设观测样本和预测样本是同分布的）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;看了源码&lt;/strong&gt;：可以看到在实现里面，先对图像做了横向和纵向的滤波，然后在8*8的patch里面进行LMMSE的求解拟合的。&lt;/p&gt;
&lt;h4 id=&quot;RI&quot;&gt;&lt;a href=&quot;#RI&quot; class=&quot;headerlink&quot; title=&quot;RI&quot;&gt;&lt;/a&gt;RI&lt;/h4&gt;&lt;p&gt;回到RI，想法也是拟合一个better PSD，只是这里的做法是用一个比较好的初始化方法，GBTF，在这个之上用了何大神的Guided Filter做平滑上采样（文中这么说），然后得到一个比较好的tentative estimate,用这个来拟合channel difference,取得了更好的效果，接下来就看一下这个guided filter和RI延伸出来的Improvement工作。&lt;/p&gt;
&lt;p&gt;RI在IMAX和Kodak的30张Images取得CPSNR 37.92dB&lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;[1]I. Pekkucuksen and Y. Altunbasak, “Gradient based threshold free color filter array interpolation,” Proc. of IEEE Int. Conf. on Image Processing (ICIP), pp. 137– 140, 2010.&lt;/p&gt;
&lt;p&gt;[2]Zhang, L. and X. Wu (2005). “Color demosaicking via directional linear minimum mean square-error estimation.” Image Processing, IEEE Transactions on 14(12): 2167-2178.&lt;/p&gt;
&lt;p&gt;[3] D. Paliy, V. Katkovnik, R. Bilcu, S. Alenius, and K. Egiazarian, “Spatially adaptive color filter array interpo- lation for noiseless and noisy data,” International Journal of Imaging Systems and Technology, vol. 17, no. 3, pp. 105-122, 2007.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;首先将东京工业大学新提出的基于Residual difference interpolation的几篇文章扫一遍，这是第一篇，提出residual difference rather than color difference&lt;br&gt;&lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot;&gt;网站&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;idea&quot;&gt;&lt;a href=&quot;#idea&quot; class=&quot;headerlink&quot; title=&quot;idea&quot;&gt;&lt;/a&gt;idea&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606ri.png&quot; alt=&quot;主要流程&quot;&gt;&lt;br&gt;左边为正常的Demosaicking流程是：先fine-grained地对G通道插值，然后对R通道插值的时候，是根据R-G的谱间具有相似差异性的原理进行，得到delta,在插值过程中得到R图再把delta加上的过程。&lt;br&gt;现在RI提出直接使用G图做差值插值由于变换太过剧烈的地方会造成Artifact,如今用一些处理使得这个G变成G尖，这个G尖的图像满足平滑和准确的特性。如此利用这个谱间相关性的时候误差会更小，出来的效果更好。&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="paper demosaick" scheme="https://csrjtan.github.io/tags/paper-demosaick/"/>
    
  </entry>
  
  <entry>
    <title>CS231n-4 &amp; 5</title>
    <link href="https://csrjtan.github.io/2016/06/06/CS231n-4/"/>
    <id>https://csrjtan.github.io/2016/06/06/CS231n-4/</id>
    <published>2016-06-06T06:05:56.000Z</published>
    <updated>2016-06-07T03:13:47.000Z</updated>
    
    <content type="html">&lt;p&gt;这节课主要讲述一下BP怎么做的&lt;/p&gt;
&lt;h3 id=&quot;BackProbagation&quot;&gt;&lt;a href=&quot;#BackProbagation&quot; class=&quot;headerlink&quot; title=&quot;BackProbagation&quot;&gt;&lt;/a&gt;BackProbagation&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606bp.png&quot; alt=&quot;简单BP&quot;&gt;&lt;br&gt;这里根据Chain Rule:$\frac{df}{dx} = \frac{df}{dq} \frac{dq}{dx}$&lt;br&gt;所以推算$\frac{df}{df} =1$, $\frac{df}{dz} = \frac{df}{df} \frac{df}{dz} = 1 &lt;em&gt; q = 3$, 同理得后面的梯度（求导中函数的x为当前neuron的值）&lt;br&gt;Add gate: Gradient Distributor&lt;br&gt;Max gate: Gradient Router(只有max的值获得梯度传递)&lt;br&gt;Mul gate: Gradient “Switcher”(Neuron交换了梯度)&lt;br&gt;BP Gradient = [Last Gradient] &lt;/em&gt; [Local Gradient]&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606bp1.png&quot; alt=&quot;Sigmoid BP&quot;&gt;&lt;br&gt;这里是用了Sigmoid作为Activation Function,可以看到梯度按照一层一层递推和直接对sigmoid function求导得到的值是一致的。$d\sigma (x)=\frac{1}{1+e^(-x)}$&lt;br&gt;$$\frac{d\sigma (x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = (1-\sigma (x))\sigma(x)$$&lt;/p&gt;
&lt;p&gt;[hints: 每个循环包括：更新BP和更新FP，因为每次BP是受当前FP的结果影响的]&lt;/p&gt;
&lt;p&gt;(Before) Linear: $ f= Wx $&lt;br&gt;(Now) 2-Layer NN: $f = W_2 max(0,W_1x) $&lt;/p&gt;
&lt;p&gt;Vectorized: 向量化后，W是一层高维的参数可能4096，若果输出层也为4096。Jacobian矩阵的大小将为4096 &lt;em&gt; 4096,而且一般按批量处理图片，如果Batch为100，则为100&lt;/em&gt; Size of Jacobian。&lt;/p&gt;
&lt;p&gt;参考阅读 &lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Efficient BP by Lecun&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;Lecture-5&quot;&gt;&lt;a href=&quot;#Lecture-5&quot; class=&quot;headerlink&quot; title=&quot;Lecture 5&quot;&gt;&lt;/a&gt;Lecture 5&lt;/h3&gt;&lt;h4 id=&quot;A-bit-History&quot;&gt;&lt;a href=&quot;#A-bit-History&quot; class=&quot;headerlink&quot; title=&quot;A bit History&quot;&gt;&lt;/a&gt;A bit History&lt;/h4&gt;&lt;p&gt;86年提出的BP算法如今大热，以往DEEP LEARNING主要网络复杂，无法收敛等问题，运算速度和数据也是考量的重要因素，导致停滞不前。如今随着实验对CNN等的认识，提出了很多有效训练和防止过拟合的方法。&lt;/p&gt;
&lt;p&gt;06年Hinton提出了RBM，先逐层做一个预训练，然后再整合成网络BP Fine-tuning，结果效果不错。&lt;/p&gt;
&lt;p&gt;10年的微软组增加了HMM在网络结构中，12年ALEX NET在IMAGE NET的成功引爆了潮流。&lt;/p&gt;
&lt;p&gt;如何做CNN：&lt;br&gt;&lt;a href=&quot;http://1.One&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;1.One&lt;/a&gt; time setup: activation functions, preprocessing, weight initialization, regularization, gradient checking&lt;br&gt;2.Traning Dynamics: babysitting the learning process, parameter updates, hyperparameter optimization&lt;br&gt;3.Evaluation: model ensembles&lt;/p&gt;
&lt;h4 id=&quot;Activation-Function&quot;&gt;&lt;a href=&quot;#Activation-Function&quot; class=&quot;headerlink&quot; title=&quot;Activation Function&quot;&gt;&lt;/a&gt;Activation Function&lt;/h4&gt;&lt;p&gt;研究对比激活函数：&lt;br&gt;Sigmoid: 1.Squashes range [0,1] 2.nice interpretation “firing rate”&lt;br&gt;三个重大问题：1.Saturated Neurons “Kill” the gradient&lt;br&gt;2.Sigmoid ouputs are not zero-centered(使得生成下层的输入x全部同号，这会导致Optimization的过程锯齿状)&lt;br&gt;3.exp computation is high&lt;/p&gt;
&lt;p&gt;tanh: 1.sqash among[-1,1]&lt;br&gt;      &lt;a href=&quot;http://2.zero&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;2.zero&lt;/a&gt; centered (nice)&lt;br&gt;      3.kills the gradient when saturated&lt;/p&gt;
&lt;p&gt;ReLU: 1.Does not saturate(in +region)&lt;br&gt;      2.computationally efficient&lt;br&gt;      3.converges mush faster&lt;br&gt;     but 1. Not zero-centered&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;2. An annoyance: the gradient of &amp;lt;0 is killed
3. Some time will &amp;quot;dead&amp;quot;(大概为负值后，无法继续更新，注意学习步长不能过大)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Leaky ReLU:  $f(x) = max(\alpha x,x)$ some times $\alpha $ is 0.01&lt;br&gt;      will not die&lt;/p&gt;
&lt;p&gt;Exponential Linear Units(ELU):&lt;br&gt;      当 x &amp;lt; 0时, $f(x) = \alpha (exp(x)-1)$&lt;br&gt;     All benefit of ReLU, Closer to zero mean outputs, but requires exp()&lt;/p&gt;
&lt;p&gt;Maxout “Neuron”:&lt;br&gt;   $$max(w_1^Tx+b_1,w_2^Tx+b_2)$$&lt;br&gt;   Linear Regime, Generalizes ReLU and Leaky ReLU,但参数变成原来的两倍了&lt;/p&gt;
&lt;p&gt;总结： 一般用ReLU,可以尝试Leaky ReLU/Maxout/ELU,不要用sigmoid；tanh的性能也不行&lt;/p&gt;
&lt;h4 id=&quot;Data-Preprocessing&quot;&gt;&lt;a href=&quot;#Data-Preprocessing&quot; class=&quot;headerlink&quot; title=&quot;Data Preprocessing&quot;&gt;&lt;/a&gt;Data Preprocessing&lt;/h4&gt;&lt;p&gt;归一： Subtract Mean and Normalization, 一般图片会subtract mean 或subtract channel mean&lt;br&gt;降为： 用PCA和Whitening或者Leveraging的方法对高维数据做降为处理，但对于图像不常用&lt;/p&gt;
&lt;h4 id=&quot;Weight-Initalization-Important&quot;&gt;&lt;a href=&quot;#Weight-Initalization-Important&quot; class=&quot;headerlink&quot; title=&quot;Weight Initalization(Important)&quot;&gt;&lt;/a&gt;Weight Initalization(Important)&lt;/h4&gt;&lt;p&gt;这是过去被忽视，但十分重要的部分。&lt;br&gt;1.All zero: Neuron的结果、误差和更新是一致的，失败&lt;br&gt;2.Small Random Numbers(以0为mean,0.01variance的高斯分布)：Work okay but lead to non-homogeneous distributions of activations across the layers of network.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Variance=1, all the neurons completely saturated, either -1 or 1,Gradients will be all zero.&lt;/li&gt;
&lt;li&gt;Xavier Initialization(suitable so far): Variance = 1/sqrt(in_layer),Reasonable initialization assumes the linear activations.&lt;/li&gt;
&lt;li&gt;Note additional /2: Variance = 1/sqrt(in_layer/2)&lt;br&gt;这里的in_layer是指上层输入的个数，通过这样可以使得上层的分布和当层的分布趋同，经验性地提高收敛的比率&lt;br&gt;soon… Propoer Initialization is an active area of research&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Batch-Normalization&quot;&gt;&lt;a href=&quot;#Batch-Normalization&quot; class=&quot;headerlink&quot; title=&quot;Batch Normalization&quot;&gt;&lt;/a&gt;Batch Normalization&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606BN.png&quot; alt=&quot;BN&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improves gradient flow through the network&lt;/li&gt;
&lt;li&gt;Allows higher learning rates&lt;/li&gt;
&lt;li&gt;Reduces the strong dependence on initialization&lt;/li&gt;
&lt;li&gt;Acts as a form of regularization and slightly reduces the need for dropout(Maybe)&lt;br&gt;里面的scale和shift参数是通过Network自己学习的，归一化后重新根据学习需求调整数据分布的scale和shift.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Notice&lt;/strong&gt;: At test time the BN layer differently: the mean/std are not computed based on the batch. Instead, a single fixed empirical mean of activations during training is used.&lt;/p&gt;
&lt;h4 id=&quot;Babysitting-the-Learning-Process&quot;&gt;&lt;a href=&quot;#Babysitting-the-Learning-Process&quot; class=&quot;headerlink&quot; title=&quot;Babysitting the Learning Process&quot;&gt;&lt;/a&gt;Babysitting the Learning Process&lt;/h4&gt;&lt;p&gt;一个课堂模拟的小CNN，做完预处理后，选择了50个hidden neurons，10个output neurons.用CIFAR-10,使用SGD梯度下降。关键是拟合小的数据集，举了实际遇到情况的判断和处理：1.small loss train accuracy 1.00（nice) 2.Loss barely changing(Learning Rating too small) 3.loss exploding to NaN or Inf(Learning Rating too high)&lt;/p&gt;
&lt;h4 id=&quot;Hyperparameter-Optimization&quot;&gt;&lt;a href=&quot;#Hyperparameter-Optimization&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter Optimization&quot;&gt;&lt;/a&gt;Hyperparameter Optimization&lt;/h4&gt;&lt;p&gt;1.Cross-Validation: Coarse-&amp;gt;fine&lt;br&gt;First Stage: only few epochs get a rough idea of what params work&lt;br&gt;Second Stage: Longer running time , finer search(Repeat as Necessary)&lt;br&gt;(Cost ever &amp;gt; 3*original cost, break out early)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It is best to optimize in log space&lt;br&gt;Grid Search Vs Random Search: (random is better 2012)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;3.Hyperparameter play with: network architecture, learning rate, its decay schedule, update type, regularization(L2/Dropout strength)&lt;/p&gt;
&lt;p&gt;4.Monitor and Visualize the Loss curve(Big gap= Overfitting)&lt;/p&gt;
&lt;p&gt;5.Track the ratio of weight updates/weight magnitudes(Ratio 0.01 is okay)&lt;/p&gt;
&lt;h4 id=&quot;Side-Talks&quot;&gt;&lt;a href=&quot;#Side-Talks&quot; class=&quot;headerlink&quot; title=&quot;Side Talks&quot;&gt;&lt;/a&gt;Side Talks&lt;/h4&gt;&lt;p&gt;如何计算网络：神经元个数=逐层个数相加；W个数=累加（当层神经元个数*下层神经元个数），B个数=神经元个数&lt;/p&gt;
&lt;h4 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h4&gt;&lt;p&gt;推荐一个网络走的流程：&lt;br&gt;1.Activation Functions(Use ReLU)&lt;br&gt;2.Data Preprocessing(Subtract Mean)&lt;br&gt;3.Weight Initialization(Xavier (/2) init)&lt;br&gt;4.Batch Normalization(Use)&lt;br&gt;5.Hyperparameter Optimization(random sample hyperparams, In log space when proper)&lt;/p&gt;
&lt;p&gt;疑问点：&lt;br&gt;1.初始化方差为1/(sqrt(in)/2): 详细看何大神的&lt;a href=&quot;https://arxiv.org/abs/1502.01852&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;文章&lt;/a&gt;&lt;br&gt;2.&lt;a href=&quot;http://arxiv.org/abs/1502.03167&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;BN&lt;/a&gt;和&lt;a href=&quot;http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Dropout&lt;/a&gt;都是近两年的工作，可以看看.Alex和Lecun还是CNN的先锋者，记得大师兄说，要多看Alex的文章。&lt;br&gt;3.&lt;a href=&quot;http://arxiv.org/pdf/1310.4546.pdf&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hiearachical Softmax&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;参考阅读:&lt;br&gt;&lt;a href=&quot;http://cs231n.github.io/neural-networks-2/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NN notes2&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cs231n.github.io/neural-networks-3/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;NN notes3&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这节课主要讲述一下BP怎么做的&lt;/p&gt;
&lt;h3 id=&quot;BackProbagation&quot;&gt;&lt;a href=&quot;#BackProbagation&quot; class=&quot;headerlink&quot; title=&quot;BackProbagation&quot;&gt;&lt;/a&gt;BackProbagation&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606bp.png&quot; alt=&quot;简单BP&quot;&gt;&lt;br&gt;这里根据Chain Rule:$\frac{df}{dx} = \frac{df}{dq} \frac{dq}{dx}$&lt;br&gt;所以推算$\frac{df}{df} =1$, $\frac{df}{dz} = \frac{df}{df} \frac{df}{dz} = 1 &lt;em&gt; q = 3$, 同理得后面的梯度（求导中函数的x为当前neuron的值）&lt;br&gt;Add gate: Gradient Distributor&lt;br&gt;Max gate: Gradient Router(只有max的值获得梯度传递)&lt;br&gt;Mul gate: Gradient “Switcher”(Neuron交换了梯度)&lt;br&gt;BP Gradient = [Last Gradient] &lt;/em&gt; [Local Gradient]&lt;br&gt;
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_3</title>
    <link href="https://csrjtan.github.io/2016/06/04/CS231n-3/"/>
    <id>https://csrjtan.github.io/2016/06/04/CS231n-3/</id>
    <published>2016-06-04T10:36:58.000Z</published>
    <updated>2016-06-07T03:13:56.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;一-Loss-Function&quot;&gt;&lt;a href=&quot;#一-Loss-Function&quot; class=&quot;headerlink&quot; title=&quot;一.Loss Function&quot;&gt;&lt;/a&gt;一.Loss Function&lt;/h4&gt;&lt;p&gt;定义Multiclass SVM loss: $L_i = \sum_{j\neq y_i} max(0,s_j-s_{y_i}+1)$&lt;br&gt;这里，$L_i$为针对类别i的Loss值，$s_j$是除了i的其他类别得分,$y_i$为当前目标类别，$s_{y_i}$ 为当前目标类别得分&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060401.png&quot; alt=&quot;SVM loss&quot;&gt;&lt;br&gt;Full Training Loss为取平均,$L=\frac{1}{N}\sum_{i=1}^N L_i$ ,则L=（2.9+0+10.9）/3= 4.6&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;SoftMax function: $\frac{e^{s_k}}{\sum_j e^{s_j}}$&lt;br&gt;这里的SVM loss存在一个问题，w可能不是唯一存在满足L最小的，比如w=w*2,L依然为0，但w已经放大了两倍，如图；这里我们加入正则项$\alpha R(w)$,其中$\alpha$为训练误差和模型复杂度的调整系数&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060402.png&quot; alt=&quot;SVM loss Bug&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里提到了loss function的选择：对于loss function的值全体做shift和scale是不会影响梯度的，而max/min则导致最后收敛时候梯度无限小。&lt;/p&gt;
&lt;p&gt;关于正则项的使用，如SVM Loss： $L = \frac{1}{N}\sum_{i=1}^N\sum_{j\neq y_i}max(0,f(x_i;W)_j-f(x_i;W)_{y_i}+1)+\lambda R(W)$ ,called &lt;strong&gt;hinge loss&lt;/strong&gt;,而L2-SVM则$max(0,-)^2$则放大惩罚误差。这里的1是$\Delta$，指正确样本到非正确样本的Margin&lt;br&gt;常用的正则向&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L2: $R(W) = \sum_k\sum_l W_{k,l}^2$&lt;/li&gt;
&lt;li&gt;L1: $R(W) = \sum_k\sum_l |W_{k,l}|$&lt;/li&gt;
&lt;li&gt;Elastic Net (L1+L2): $R(W)=\sum_k\sum_l \beta W_{k,l}^2 + |W_{k,l}|$&lt;/li&gt;
&lt;li&gt;Max Norm Regularization&lt;/li&gt;
&lt;li&gt;Dropout&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Softmax Classifier(Multinomial Logistic Regression)&lt;/strong&gt;: $$ L_i = -log(\frac{e^{s_{y_i}}}{\sum_j e^{s_j}})$$ ,这里Softmax是满足Minimizing the cross-entropy between estimated class probabilities and “true” distribution,从信息学的角度来说，是一个好的loss function.&lt;a href=&quot;http://cs231n.github.io/linear-classify/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Loss Function Noetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Practical Tips: $\delta$和$\lambda$ 的trade off是相关的，所以可以fix one and only tuned another one&lt;/p&gt;
&lt;h4 id=&quot;二-Optimization&quot;&gt;&lt;a href=&quot;#二-Optimization&quot; class=&quot;headerlink&quot; title=&quot;二.Optimization&quot;&gt;&lt;/a&gt;二.Optimization&lt;/h4&gt;&lt;p&gt;得到合适的Loss Function后，如何最小化呢？使用到Optimization的方法了.&lt;br&gt;1.Random Search(Stupid)：瞎走&lt;br&gt;2.Random Local Search(这里还有很多AI的Search算法)&lt;br&gt;3.Gradient Descent（都在用的）: 沿着梯度下降，如果Loss是Convex Function,有Global Minimize;否则可能只能到达Local Minimize；如何走，也有很多学问，下一节课说。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;: 1.逐点weights,添加步长更新，Numerical Gradient: Approximate,Slow but easy  2.矩阵求导更新，Analytic Gradient: Exact, Fast but error-prone. （有时候陷入病态，无法求导或者导数太小）&lt;br&gt;[Practical Tips：用Analytic gradient but check the implementation compared with numerical gradient, called “&lt;strong&gt;Gradient Check&lt;/strong&gt;“&lt;/p&gt;
&lt;p&gt;Mini-Batch Gradient Descent: 对样本批量做，求平均更新；一般size为32/64/126，ALEX NET用了256；这里Batch过小，导致收敛漂移，陷入病态；Batch过大，则权值更新缓慢，优化过程长。&lt;/p&gt;
&lt;p&gt;调参：Suitable Learning Rate, BatchSize, Regularization&lt;/p&gt;
&lt;p&gt;题外话：回顾了一下CV上的Image Feature, Hue Histogram: 区块直方图统计，缺乏结构信息； HoG/Sift: Artifact Feature; BoW:对Feature学一个字典重新有效表示Image.&lt;/p&gt;
&lt;p&gt;SVM是一个凸优化问题，但CNN不是，所以注意凸优化里面的方法不一定适用于CNN。&lt;/p&gt;
&lt;p&gt;关于Gradient Descent的Practical considerations: 1.使用左右两端的导数值会更优,$[f(x+h)-f(x-h)]/2h$; 2.注意是往梯度的反方向更新，因为是下降 3.有效的更新步长（重要的学习参数）&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;一-Loss-Function&quot;&gt;&lt;a href=&quot;#一-Loss-Function&quot; class=&quot;headerlink&quot; title=&quot;一.Loss Function&quot;&gt;&lt;/a&gt;一.Loss Function&lt;/h4&gt;&lt;p&gt;定义Multiclass SVM loss: $L_i = \sum_{j\neq y_i} max(0,s_j-s_{y_i}+1)$&lt;br&gt;这里，$L_i$为针对类别i的Loss值，$s_j$是除了i的其他类别得分,$y_i$为当前目标类别，$s_{y_i}$ 为当前目标类别得分&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060401.png&quot; alt=&quot;SVM loss&quot;&gt;&lt;br&gt;Full Training Loss为取平均,$L=\frac{1}{N}\sum_{i=1}^N L_i$ ,则L=（2.9+0+10.9）/3= 4.6&lt;br&gt;
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_1 &amp; 2</title>
    <link href="https://csrjtan.github.io/2016/06/03/CS231n-1/"/>
    <id>https://csrjtan.github.io/2016/06/03/CS231n-1/</id>
    <published>2016-06-03T04:53:24.000Z</published>
    <updated>2016-06-07T03:14:03.000Z</updated>
    
    <content type="html">&lt;p&gt;回来积极投身CNN的学习和研究中，受到博后哥哥宪标的推荐，毅然决然去学习standford CS231n关于CNN的公开课CNN for Visual Recognition，主要由飞飞姐和Karpathy、Johnson主讲，&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ngXbD21b4qk&amp;amp;index=2&amp;amp;list=PLrZmhn8sSgye6ijhLzIIXiU9GNaIwbF8B&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Youtube视频&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cs231n.stanford.edu/syllabus.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;课程主页&lt;/a&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;第一课-Introduction&quot;&gt;&lt;a href=&quot;#第一课-Introduction&quot; class=&quot;headerlink&quot; title=&quot;第一课 Introduction&quot;&gt;&lt;/a&gt;第一课 Introduction&lt;/h3&gt;&lt;p&gt;首先不出意外地第一节课是Introduction,飞飞对CV的研究发展历史给出了一个比较中肯的conclusion,从生物视觉的起源到Da Vinci的摄影技术以及第一篇CV phd Thesis. 主要提到了计算机视觉围绕主要的问题，有一个宏观意义上的认识。物体是识别、分类、切割、定位等，还能延伸出许多的子问题。&lt;/p&gt;
&lt;h4 id=&quot;经典工作&quot;&gt;&lt;a href=&quot;#经典工作&quot; class=&quot;headerlink&quot; title=&quot;经典工作&quot;&gt;&lt;/a&gt;经典工作&lt;/h4&gt;&lt;p&gt;这里关键读一下CV历史上影响巨大的几篇文章：&lt;br&gt;一.AdaBoost Face Detection:使得人脸的识别可以实时应用，主要Contribution:1.Harr特征的边缘提取 2.积分图的快速计算 3.AdaBoost的学习分类器&lt;br&gt;二.SIFT：Lowe大神经典之作，每个CV人都知道的图片经典特征点,具有shift、rotate、scale不变性：1.构建高斯图像金字塔 2.提取特征点 3.特征描述子的建立&lt;br&gt;三.金字塔匹配：CVPR06工作，将图片分块成多个空间金字塔，从而结合BoW等技术进行有效的匹配和分类&lt;/p&gt;
&lt;p&gt;ImageNet主要关注在CV核心问题，图像识别和分类定位等问题。起初使用的模型一般是提取特征点-&amp;gt;建立字典和模型-&amp;gt;学习分类算法(SVM)-&amp;gt;预测结果；如今DL的火热，使得CNN成为研究CV的主工具。&lt;/p&gt;
&lt;h4 id=&quot;关于CNN的工作&quot;&gt;&lt;a href=&quot;#关于CNN的工作&quot; class=&quot;headerlink&quot; title=&quot;关于CNN的工作&quot;&gt;&lt;/a&gt;关于CNN的工作&lt;/h4&gt;&lt;p&gt;1.LeCun大神的MNIST文字识别库，文章比较了多种ML方法在库上的表现，当年使用的CNN达到了非常好的效果，但具有训练速度慢、收敛难等问题&lt;br&gt;2.ImageNet12上，AlexNet这篇经典的CNN文章引爆了潮流，主要使用ReLU、GPU加速、LRN、Data Augument等技术使得CNN避免Overfitting，方便梯度传递，加速训练、解决DL收敛困难的主要问题，在比赛上获得惊人的效果。&lt;/p&gt;
&lt;h4 id=&quot;课程的Pre-Requisite&quot;&gt;&lt;a href=&quot;#课程的Pre-Requisite&quot; class=&quot;headerlink&quot; title=&quot;课程的Pre-Requisite&quot;&gt;&lt;/a&gt;课程的Pre-Requisite&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;high proficiency in python和c++&lt;/li&gt;
&lt;li&gt;Linear Algebra&lt;/li&gt;
&lt;li&gt;Machine Learning&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;第二课-Classification&quot;&gt;&lt;a href=&quot;#第二课-Classification&quot; class=&quot;headerlink&quot; title=&quot;第二课 Classification&quot;&gt;&lt;/a&gt;第二课 Classification&lt;/h3&gt;&lt;h4 id=&quot;Image-Classification&quot;&gt;&lt;a href=&quot;#Image-Classification&quot; class=&quot;headerlink&quot; title=&quot;Image Classification&quot;&gt;&lt;/a&gt;Image Classification&lt;/h4&gt;&lt;p&gt;&lt;a href=&quot;http://cs231n.github.io/classification/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ImageClassification Tutorial&lt;/a&gt;&lt;br&gt;Challenges:Viewpoint Variation, Scale Variation, Deformation, Occlusion, Iluumnation conditions, Background Clutter, Intra-class Variation.（图像识别的经典难点）&lt;/p&gt;
&lt;p&gt;Data-Driven Approach: Input-&amp;gt;Learning-&amp;gt;Evaluation&lt;br&gt;根据训练样本的学习出来模型，从而对新来的样本进行分类识别的方法&lt;/p&gt;
&lt;p&gt;Nearest Neighbor Classifier,具体为KNN: 1.Distance Metric的选择 2.k值的选择（根据Cross Validation,e.g. 5-fold cross-validation）,从训练集中切成5份，轮着用一份训练，剩余四份Evaluate,从而调整hyperParameters&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060301.png&quot; alt=&quot;k-fold分析图&quot;&gt;，对于一般性的数据集，K在4-7取得更加的效果，K越大越smooth,expensive也越大&lt;/p&gt;
&lt;p&gt;[tips:Evaluate on the test set only a single time, at the very end.确保最后才使用testSets,避免overfit for testSets,保证了模型的generlzation]&lt;/p&gt;
&lt;p&gt;Ads: Easy to understand and implement&lt;br&gt;Draws: Pay computational cost at test time(因此提出了ANN的近似加速，还有FLANN的库)&lt;br&gt;Pixel-based distances on high-dimensional data can be very unintuitive.(不适用，就像图片平移或者出现Artifacts等情况，但pixel-based distance是不适应人眼的;这里karpathy用了t-SNE对CIFAR-10的图片作了一个分布排列，相似的放在一起，可以看到背景相似但内容不一的东西反而靠在一起了)&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060303.jpg&quot; alt=&quot;t-SNE对CIFAR-10的分布&quot;&gt;&lt;br&gt;cons: suit for the low-dimensional data&lt;/p&gt;
&lt;p&gt;Summary: 1.Introduce the problem of image classification, image mapping label&lt;br&gt;2.introduce the NN classifier&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Using validation set for tuning the hyperparameters, split training data into two: a training set and a fake test set. Try different hyperparameter values&lt;/li&gt;
&lt;li&gt;Once the parameter found, we fixed and use actual test set to evaluation&lt;/li&gt;
&lt;li&gt;the NN only get about 40% accuracy on CIFAR-10, while human achieve 94% and CNN achieve already 95%!&lt;/li&gt;
&lt;li&gt;the L1 or L2 distances on raw pixel is not adequate since more strongly relative with backgrounds and color distributions rather than semantic content&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Practice-with-kNN&quot;&gt;&lt;a href=&quot;#Practice-with-kNN&quot; class=&quot;headerlink&quot; title=&quot;Practice with kNN:&quot;&gt;&lt;/a&gt;Practice with kNN:&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;Preprocessing: Normalize the data in zero mean and unit variance&lt;/li&gt;
&lt;li&gt;If the data is high dimensional, using dimensionality reduction technique such as PCA or even Random Projections&lt;/li&gt;
&lt;li&gt;Split your traiing data randomly into train/val splits. About 70%~90% of data usually goes to the train split. It depens on how many hyperparameters you have and how much influence you expect them to have. (Cross-validation with the more folds the better, but more expensive)&lt;/li&gt;
&lt;li&gt;Train and evaluate kNN on validation data for many choices of k and across different distance types(暴力人为去尝试，加上自己实验的理解)&lt;/li&gt;
&lt;li&gt;If kNN running too long, consider using ANN library(FLANN, cost of some accuracy)&lt;/li&gt;
&lt;li&gt;Normaly do not use the validation set into the training data, we burned it for unestimated influence. Then evaluate with the test set and report the result as the performance of the kNN models.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Linear-Claissification&quot;&gt;&lt;a href=&quot;#Linear-Claissification&quot; class=&quot;headerlink&quot; title=&quot;Linear Claissification&quot;&gt;&lt;/a&gt;Linear Claissification&lt;/h4&gt;&lt;p&gt;kNN disadvantages: 1.需要存储training data for comparison&lt;br&gt;                   2.与数据库comparison十分耗时&lt;/p&gt;
&lt;p&gt;Using a score function and loss function to build a powerful model rather than the kNN&lt;br&gt;$f(x_i,W,b) = Wx_i+b$&lt;/p&gt;
&lt;p&gt;这里主要把W,b的参数学习，x为图片输入，将像素和通道展开成一维超长向量，假设有10类，则b为【10*1】为，得到一个10维的向量，分别表示对应类别的得分。如此一来，新来样本分类只要计算一个矩阵乘法和向量加法就得到结果了，比原先kNN不知道快到哪里去。&lt;/p&gt;
&lt;p&gt;思考：这里Linear Classification相当于做了什么，怎么去理解？1.学习了对应类别的一个模板匹配 2.在高维度空间对数据样本做线性分类学习（有点像SVM)&lt;br&gt;这里将学习得到的Linear Classification再重新可视化之后，得到以下的结果&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/cs231n060302.png&quot; alt=&quot;类别模板可视化&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;回来积极投身CNN的学习和研究中，受到博后哥哥宪标的推荐，毅然决然去学习standford CS231n关于CNN的公开课CNN for Visual Recognition，主要由飞飞姐和Karpathy、Johnson主讲，&lt;br&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ngXbD21b4qk&amp;amp;index=2&amp;amp;list=PLrZmhn8sSgye6ijhLzIIXiU9GNaIwbF8B&quot;&gt;Youtube视频&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;http://cs231n.stanford.edu/syllabus.html&quot;&gt;课程主页&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>书单</title>
    <link href="https://csrjtan.github.io/2016/06/01/books/"/>
    <id>https://csrjtan.github.io/2016/06/01/books/</id>
    <published>2016-06-01T11:28:07.000Z</published>
    <updated>2016-06-02T15:12:13.000Z</updated>
    
    <content type="html">&lt;p&gt;这里记录一下书单，包括在读的、想读的、他人推荐读的。后面可以写一下正在进展的项目和工作，最后记录已读的。&lt;/p&gt;
&lt;h2 id=&quot;在读：&quot;&gt;&lt;a href=&quot;#在读：&quot; class=&quot;headerlink&quot; title=&quot;在读：&quot;&gt;&lt;/a&gt;在读：&lt;/h2&gt;&lt;p&gt;《情人》、《时间简史》、《MATLAB从入门到精通》&lt;/p&gt;
&lt;h2 id=&quot;想读：&quot;&gt;&lt;a href=&quot;#想读：&quot; class=&quot;headerlink&quot; title=&quot;想读：&quot;&gt;&lt;/a&gt;想读：&lt;/h2&gt;&lt;h3 id=&quot;面试微软之前的十本书&quot;&gt;&lt;a href=&quot;#面试微软之前的十本书&quot; class=&quot;headerlink&quot; title=&quot;面试微软之前的十本书&quot;&gt;&lt;/a&gt;面试微软之前的十本书&lt;/h3&gt;&lt;p&gt;Code: The Hidden Language of Computer Hardware and Software （《编码的奥秘》）&lt;br&gt;Computer System: A Programmer’s Perspective （《深入理解计算机系统》） / Windows via C/C++ （《Windows核心编程》 / 《程序员的自我修养》&lt;br&gt;Code Complete 2（《代码大全》）/ The Pragmatic Programmer （《程序员修炼之道》，我也把这本书称为《代码小全》）&lt;br&gt;Programming Pearls （《编程珠玑》） / Algorithms / Algorithm Design / 《编程之美》&lt;br&gt;The C Programming Language&lt;br&gt;The C++ Programming Language / Programming: Principles and Practice Using C++ / Accelerated C++&lt;br&gt;The Structure and Interpretation of Computer Programs （《计算机程序的构造和解释》）&lt;br&gt;Clean Code / Implementation Patterns&lt;br&gt;Design Patterns （《设计模式》） / Agile Software Development, Principles, Patterns, and Practices&lt;br&gt;Refactoring （《重构》）&lt;/p&gt;
&lt;h3 id=&quot;云风推荐&quot;&gt;&lt;a href=&quot;#云风推荐&quot; class=&quot;headerlink&quot; title=&quot;云风推荐&quot;&gt;&lt;/a&gt;云风推荐&lt;/h3&gt;&lt;p&gt;C++编程思想&lt;br&gt;Effective C++&lt;br&gt;深度探索C++对象模型&lt;br&gt;C++语言的设计和演化&lt;br&gt;C专家编程&lt;br&gt;C陷阱与缺陷&lt;br&gt;C语言接口与实现&lt;br&gt;Lua程序设计&lt;br&gt;Linkers and Loaders&lt;br&gt;COM本质论&lt;br&gt;Windows核心编程&lt;br&gt;深入解析Windows操作系统&lt;br&gt;程序员修炼之道&lt;br&gt;代码大全&lt;br&gt;UNIX编程艺术&lt;br&gt;设计模式&lt;br&gt;代码优化：有效使用内存&lt;br&gt;深入理解计算机系统&lt;br&gt;深入理解LINUX内核&lt;br&gt;TCP/IP 详解&lt;/p&gt;
&lt;h3 id=&quot;冯大辉&quot;&gt;&lt;a href=&quot;#冯大辉&quot; class=&quot;headerlink&quot; title=&quot;冯大辉&quot;&gt;&lt;/a&gt;冯大辉&lt;/h3&gt;&lt;p&gt;软件随想录&lt;br&gt;黑客与画家&lt;br&gt;重来&lt;br&gt;UNIX编程艺术&lt;br&gt;编程人生&lt;/p&gt;
&lt;h3 id=&quot;豆瓣CTO&quot;&gt;&lt;a href=&quot;#豆瓣CTO&quot; class=&quot;headerlink&quot; title=&quot;豆瓣CTO&quot;&gt;&lt;/a&gt;豆瓣CTO&lt;/h3&gt;&lt;p&gt;Code Complete 2&lt;br&gt;The Mythical Man-Month （《人月神话》）&lt;br&gt;Code: The Hidden Language of Computer Hardware and Software （《编码的奥秘》）&lt;br&gt;TAOCP （不解释）&lt;br&gt;The Pragmatic Programmer （《程序员修炼之道》）&lt;br&gt;Design Patterns （《设计模式》）&lt;br&gt;The Structure and Interpretation of Computer Programs （《计算机程序的构造和解释》）&lt;br&gt;Refactoring （《重构》）&lt;br&gt;The C Programming Language&lt;br&gt;Introduction to Algorithms （《算法导论》）&lt;/p&gt;
&lt;h2 id=&quot;已读：&quot;&gt;&lt;a href=&quot;#已读：&quot; class=&quot;headerlink&quot; title=&quot;已读：&quot;&gt;&lt;/a&gt;已读：&lt;/h2&gt;&lt;h3 id=&quot;技术&quot;&gt;&lt;a href=&quot;#技术&quot; class=&quot;headerlink&quot; title=&quot;技术&quot;&gt;&lt;/a&gt;技术&lt;/h3&gt;&lt;p&gt;《统计学习方法》、《这就是搜索引擎》、《浪潮之巅》、《数学之美》&lt;/p&gt;
&lt;h3 id=&quot;非技术&quot;&gt;&lt;a href=&quot;#非技术&quot; class=&quot;headerlink&quot; title=&quot;非技术&quot;&gt;&lt;/a&gt;非技术&lt;/h3&gt;&lt;p&gt;《苏菲的世界》、《如何阅读一本书》、《黑客与画家》、《解忧杂货铺》、《当我在跑步，我在谈论什么》、《白夜行》、《一个人的朝圣》、《人性的弱点》、《从0到1》、《35岁前要做的33件事》、《站在两个世界的边缘》、《极简欧洲史》、《未来在现实的第几层》、《再穷也要去旅游》、《活着》、《小王子》、《自控力》&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这里记录一下书单，包括在读的、想读的、他人推荐读的。后面可以写一下正在进展的项目和工作，最后记录已读的。&lt;/p&gt;
&lt;h2 id=&quot;在读：&quot;&gt;&lt;a href=&quot;#在读：&quot; class=&quot;headerlink&quot; title=&quot;在读：&quot;&gt;&lt;/a&gt;在读：&lt;/h2&gt;&lt;p&gt;《情人》、《
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
  </entry>
  
  <entry>
    <title>潮汕之旅&amp;拼图合照</title>
    <link href="https://csrjtan.github.io/2016/05/30/%E6%BD%AE%E6%B1%95%E4%B9%8B%E6%97%85/"/>
    <id>https://csrjtan.github.io/2016/05/30/潮汕之旅/</id>
    <published>2016-05-30T06:47:13.000Z</published>
    <updated>2016-06-01T14:49:47.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Seminar-Report&quot;&gt;&lt;a href=&quot;#Seminar-Report&quot; class=&quot;headerlink&quot; title=&quot;Seminar Report&quot;&gt;&lt;/a&gt;Seminar Report&lt;/h3&gt;&lt;p&gt;理大上学期的十个Seminar Report的1500 words的总结&lt;br&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B5mtSYlvfwArMVAzblpPZjRRNmM/view&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Seminar Report&lt;/a&gt;&lt;br&gt;买设备的单据&lt;br&gt;&lt;a href=&quot;https://drive.google.com/drive/folders/0B5mtSYlvfwArbDI2N1lIdlFpZ0U&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;电脑单据&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;潮汕&quot;&gt;&lt;a href=&quot;#潮汕&quot; class=&quot;headerlink&quot; title=&quot;潮汕&quot;&gt;&lt;/a&gt;潮汕&lt;/h3&gt;&lt;p&gt;在深圳工作了一会儿了，周末借着万圣节的假期和珊爷出去玩，由于港客特别多放假，珠海长隆和周边的温泉都爆满了，所以决定去潮汕享受一下美食。结果却累得不行，时间不够，交通紧张，没有领略到什么旅游的特色，倒是和珊宝确实走了更多的路了。&lt;/p&gt;
&lt;p&gt;去了两天，住在状元街周边的旅店，总体感觉消费也不低，但人确实有点凶，不大适合旅游，受到小明的建议，决定到此体验一下潮汕的文化和美食。毕竟大学堆里有不少潮汕的朋友，这有利于了解他们的生活方式。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053001.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;潮州状元坊&quot;&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;这个状元坊就是当年的秀才考取功名，衣锦还乡而建的，一条街证明大家都是为了这个奋发，读书走这条路为的就是衣锦还乡呀。所以潮汕的教育应该还是很不错，相对来说还是比较重视教育和后代的，所以才会出现那么严重的超生、重男轻女之类的，确实很有趣。现在珠三角的年轻人群体不乏潮汕群体，而且公司和大学也很多，所以这个地方还是值得去了解一下，遗憾的是时间不够，没有去到汕头。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053002.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;潮汕牛肉面&quot;&gt;&lt;br&gt;潮汕的牛肉丸、牛杂和牛肉面自然是不容错过的，只是感觉味精有点多，不适合我这种传统顺德口味。回来还发烧和嘴巴发炎了，太上火了，以致于现在的口味也趋向清淡了。也应了年轻的时候轻狂，过了这段也就归于本性；年轻的时候爱吃辣，过了就知道自己自小的培养起来的口味和体质，还是趋于清淡。（家里人的口味和小珊的口味熏陶了我）。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053003.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;驸马府&quot;&gt;&lt;br&gt;在潮汕很多那些电动三轮，虽然导致交通阻塞，但却很受用，上了一个把驸马府、西湖都转了个遍，毕竟潮州的景点也不大。所以在这儿当了一回驸马，了解了很多潮州以及华南地区的建筑格局和模式。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053004.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;芝麻茶和杏仁茶&quot;&gt;&lt;br&gt;其实就是糊，不过口味还挺不错的，值得一试。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053006.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;广济桥合照&quot;&gt;&lt;br&gt;这是历史已久的桥，后来李嘉诚斥巨资翻修，很多的潮汕人漂洋过海谋求发展，功成名就就帮助建设家乡，汕头大学也是因此受惠不少。奈何潮州这个地区好像经济发展还是比较颓势，新城区可能还好一些吧。&lt;/p&gt;
&lt;p&gt;总结：这趟旅程只有两天但其实有点时间不足，交通上耗时较多，到旅游点后也没有了解和玩到太多的东西，要多加锻炼自己的策划能力，看了很多的攻略但没有地图确实还是不好弄，只有手机软件还是不够用的。需要做好手绘地图攻略，合理安排好时间出行。特别找饭店这个好像一直都不大重视，但食是旅游中十分重要的一件事情。下次改进吧。&lt;/p&gt;
&lt;h3 id=&quot;拼图合照&quot;&gt;&lt;a href=&quot;#拼图合照&quot; class=&quot;headerlink&quot; title=&quot;拼图合照&quot;&gt;&lt;/a&gt;拼图合照&lt;/h3&gt;&lt;p&gt;这里把lofter和手机拼图都放在一起了，有空可以怀缅一下。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053005.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;可爱的人&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053007.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;大四时光&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053008.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;合照&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053009.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;哥哥大婚&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Seminar-Report&quot;&gt;&lt;a href=&quot;#Seminar-Report&quot; class=&quot;headerlink&quot; title=&quot;Seminar Report&quot;&gt;&lt;/a&gt;Seminar Report&lt;/h3&gt;&lt;p&gt;理大上学期的十个Seminar Report的1500 words的总结&lt;br&gt;&lt;a href=&quot;https://drive.google.com/file/d/0B5mtSYlvfwArMVAzblpPZjRRNmM/view&quot;&gt;Seminar Report&lt;/a&gt;&lt;br&gt;买设备的单据&lt;br&gt;&lt;a href=&quot;https://drive.google.com/drive/folders/0B5mtSYlvfwArbDI2N1lIdlFpZ0U&quot;&gt;电脑单据&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;潮汕&quot;&gt;&lt;a href=&quot;#潮汕&quot; class=&quot;headerlink&quot; title=&quot;潮汕&quot;&gt;&lt;/a&gt;潮汕&lt;/h3&gt;&lt;p&gt;在深圳工作了一会儿了，周末借着万圣节的假期和珊爷出去玩，由于港客特别多放假，珠海长隆和周边的温泉都爆满了，所以决定去潮汕享受一下美食。结果却累得不行，时间不够，交通紧张，没有领略到什么旅游的特色，倒是和珊宝确实走了更多的路了。&lt;/p&gt;
&lt;p&gt;去了两天，住在状元街周边的旅店，总体感觉消费也不低，但人确实有点凶，不大适合旅游，受到小明的建议，决定到此体验一下潮汕的文化和美食。毕竟大学堆里有不少潮汕的朋友，这有利于了解他们的生活方式。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CS053001.jpg?imageView2/2/w/400/q/90&quot; alt=&quot;潮州状元坊&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Life" scheme="https://csrjtan.github.io/categories/Life/"/>
    
    
      <category term="旅游 美食" scheme="https://csrjtan.github.io/tags/%E6%97%85%E6%B8%B8-%E7%BE%8E%E9%A3%9F/"/>
    
  </entry>
  
  <entry>
    <title>重回理大</title>
    <link href="https://csrjtan.github.io/2016/05/29/%E9%87%8D%E5%9B%9E%E7%90%86%E5%A4%A7/"/>
    <id>https://csrjtan.github.io/2016/05/29/重回理大/</id>
    <published>2016-05-29T05:18:43.000Z</published>
    <updated>2016-06-01T14:27:44.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;在深圳最后一周&quot;&gt;&lt;a href=&quot;#在深圳最后一周&quot; class=&quot;headerlink&quot; title=&quot;在深圳最后一周&quot;&gt;&lt;/a&gt;在深圳最后一周&lt;/h3&gt;&lt;p&gt;从今年的3月中旬去到了相机部门里面去实习，认识了很多牛人，迄今为止一次在公司里比较真切完整的体验，几乎足足有三个月。（不想说有多苦，宝宝心里苦，宝宝认真上班）总结来说并没有进步很多，但确实学到不少，企业的管理模式，内部沟通机制，安全机制等，我住在新安的宿舍，每天上班需要40分钟，过着早上10点上班，中午12点半点外卖，午休到2点，晚饭6点吃完，7点休息聊天看书，8点回去散漫工作的日子。虽然紧张，但规律有节奏的生活带来的好处却是有目共睹的。很庆幸认识了共同入职的新伙伴，陪我度&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;过了这段富有意义的旅程。遗憾的是没有想象中的那样学到很多很有意义的东西，一方面是自己实力或者积极性不够的原因，一方面也是公司内部管理以及机密性原因，对实习生确实不能太坦诚相对。这是一家非常棒的公司，拥有非常棒的员工，大家工作节奏快而有效，虽然缺少一些生活的气息，但已经感觉到他们的工作与生活是无法割离的。这样的长时间工作带来了高薪但却缺少了个人娱乐以及陪伴家人的时间（其实还是有的，主要是在周末吧）。不得不说这段岁月过得飞快，每天都能拿出绝大部分的时间放在技术、代码上，这才是应该要有的学习和进步的态度，希望自己能保持。&lt;/p&gt;
&lt;p&gt;这最后一周本来还不想离去，但我家的小珊考完期末试，没人陪她玩，愣是过来骚扰我了，于是我就白天上班，晚上陪她去了。周二的第一天我们去了创维大厦的藕厨，点了个番茄鱼。继水煮鱼和番茄鱼之后，又刷新我世界观的🐟。还有肉团和爆炒娃娃菜，我家宝宝是有多爱吃娃娃菜~第二天去了COCO PARK，为了吃到她朋友SHOW的美奈小馆，一个吃非常FRESH的越南菜的馆子，还等了几乎一个小时，肚子又要快饿扁了，真希望能健康按时地作息。接下来秀一下拍的FRESH越南菜美食：&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052901.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;宝宝试衣&quot;&gt;这个衣服还是跟宝宝很配的，宝宝的穿衣审美一直希望尝试新风格突破自我，所以经常想尝试欧美风，奈何骨架太小，人还偏瘦，想穿衣好看，就得吃饭。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052905.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;薄荷紫苏柠七&quot;&gt;还有如此清新可口的饮料&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052902.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;绿豆糕&quot;&gt;还行，但太黏了，不及我二姑妈做的呀！&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052904.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;越南春卷&quot;&gt;野味，唯一一个比较多肉的，满足我食肉兽欲望的菜式&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052903.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;招牌越南寿司&quot;&gt;感觉不到好味之处，只是各种酸甜香辣还有些芒果肉混在其中，这就是越南菜让人回味的特点。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052906.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;美奈小馆&quot;&gt;&lt;br&gt;最后一晚去了科技园旁边的一个西餐厅，点了双人套餐，吃了两份大扒还有自助，吃得也是够称的，那块香喷喷的牛肋确实是值得再尝，8分熟旁边拌上椒盐和蛋黄酸甜汁，好吃到不要不要的。还带宝宝第一次体验了一下沐足，确实有点玩过头了，回去要好好工作了！&lt;/p&gt;
&lt;h3 id=&quot;重回理大&quot;&gt;&lt;a href=&quot;#重回理大&quot; class=&quot;headerlink&quot; title=&quot;重回理大&quot;&gt;&lt;/a&gt;重回理大&lt;/h3&gt;&lt;h4 id=&quot;周六&quot;&gt;&lt;a href=&quot;#周六&quot; class=&quot;headerlink&quot; title=&quot;周六&quot;&gt;&lt;/a&gt;周六&lt;/h4&gt;&lt;p&gt;早上：回到学校的感觉真好，劳累了两个多月，是要好好做些喜欢的事情，比如说看个球什么的，今年常规赛勇士太猛，在81场常规赛里拿到了73场胜利，破了当年乔丹带领的公牛队的联盟记录。库里也大丰收，拿到了常规赛MVP，常规赛三分球也破了联盟记录了，可谓了人在巅峰的丰收年了，上一年拿到了总冠军，今年不知道是否也能冲击卫冕。早上起来看的是热火对阵猛龙，不得不说今年猛龙确实进步神速，双枪德罗赞和小钢炮罗瑞发挥出色，高歌挺进了东决，奈何詹姆斯、欧文和勒夫三巨头的骑士融合得和谐有节奏，事实上还是差距许多，特别赞许今年詹姆斯的球风和领袖气质日趋成熟稳重，主动的助攻和分球，使得除了猛龙的两场发挥出色的比赛，可谓一路在季后赛上无人能挡的，冲击总冠军的势头也是十分的猛。詹姆斯的身体素质和技术还是十分的强悍，联盟第一人确实不是儿戏，基本上两个人也防不住，看的这一场三巨头基本上也是三双，早早就结束悬念了。&lt;/p&gt;
&lt;p&gt;中午：PolyU的Research OpenDay,看到老师和同学们在展厅展示的DEMO，有分布式机器人阵列、老姐的云计算、我们的深度场景重建和辉辉的HDR；大张组的生物识别类的根据呼吸检查糖尿病、掌纹特征打卡、根据舌头识别之类的；一些基于社交信息的数据挖掘、手势控制飞机、游戏等等，看到高校里丰富多彩的应用也是欣喜十足，回来继续做学术的感觉也是真好。下午和新栋、刘日升老师一起去射射篮，单挑一下。&lt;/p&gt;
&lt;p&gt;晚上： 研究了一下HEXO，缘起看到中大师兄小土刀的博客，感觉自己也应该记录一下生活，多花点生活记录每一点点滴，可以看到自己的人生轨迹，也在写作中不断沉淀思考，做更好的自我吧。把分类和图片设置大小的做起来，七牛那可以帮助把图片设成对应所需要的大小,用&lt;a href=&quot;http://developer.qiniu.com/code/v6/api/kodo-api/image/imageview2.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;imageView2&lt;/a&gt;:&lt;br&gt;&lt;figure class=&quot;highlight dts&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;imageView2/&lt;span class=&quot;params&quot;&gt;&amp;lt;mode&amp;gt;&lt;/span&gt;&lt;span class=&quot;meta-keyword&quot;&gt;/w/&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;&amp;lt;LongEdge&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 &lt;span class=&quot;meta-keyword&quot;&gt;/h/&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;&amp;lt;ShortEdge&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 &lt;span class=&quot;meta-keyword&quot;&gt;/format/&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;&amp;lt;Format&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 &lt;span class=&quot;meta-keyword&quot;&gt;/interlace/&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;&amp;lt;Interlace&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 &lt;span class=&quot;meta-keyword&quot;&gt;/q/&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;&amp;lt;Quality&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;                 &lt;span class=&quot;meta-keyword&quot;&gt;/ignore-error/&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;&amp;lt;ignoreError&amp;gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h4 id=&quot;周日&quot;&gt;&lt;a href=&quot;#周日&quot; class=&quot;headerlink&quot; title=&quot;周日&quot;&gt;&lt;/a&gt;周日&lt;/h4&gt;&lt;p&gt;早上：好不容易8点钟爬起来了，想着好好学习，奈何雷霆对阵勇士的GAME6,现在雷霆几乎要淘汰勇士了，身为勇士的支持者，当然需要支持一下球队。这个系列赛可以看到二少的成长，球风趋于稳重，进攻侵略性不变之余，投篮和技术都在渐进，基本上可以称为联盟最强突破控卫了。雷霆这边一帮人等身体素质都是好得一比，各种篮底进攻，前场篮板球都是如探囊取物来着。反观勇士这边打得很累，各种掩护后依然没有出手空间，各种突破后屡遭封盖或者近距离投射但面对着大山大墙却命中不高。所幸的是今天汤神发挥又再超神，一记又一记的三分球帮勇士把命续到最好两分钟，两队打平。勇士下半场的三分手感火热，几乎没有投失，雷霆的篮底冲击和中投依然是十分稳定，两队不断飚分上扬，知道最后两分钟，汤神再来一记三分，最好11记三分拿到全场最高的41分还破了季后赛三分最多的联盟记录。雷霆士气关键时刻在主场士气反而有点低落，威少连续两个末节关键失误断送了在主场淘汰勇士的机会，最后一场抢七大战将会在勇士展开，我只想说主场优势还是很明显，这很可能是我想看到的最终骑士对阵勇士的大战，三巨头大战水花，两队的三分都是十分强劲，而骑士这边有詹姆斯相对来说，全队实力更为稳定和全面。&lt;/p&gt;
&lt;p&gt;下午： 去整理一下以前的相片和文字，前移到HEXO这里来吧，在这里记录我的生活，展示我的人生，思考奋斗和调整我的方向&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052908.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;理大小广场的一角&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052909.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;理大校道&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Life052910.jpg?imageView2/2/w/300/q/90&quot; alt=&quot;设计大楼&quot;&gt;&lt;br&gt;晚上： 约了宝宝大人一起去看五月天的演唱会，十分期待，相信一定是一个难忘的体验，第一场就是五月天了，肯定要挥泪青春岁月的节奏了！&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;在深圳最后一周&quot;&gt;&lt;a href=&quot;#在深圳最后一周&quot; class=&quot;headerlink&quot; title=&quot;在深圳最后一周&quot;&gt;&lt;/a&gt;在深圳最后一周&lt;/h3&gt;&lt;p&gt;从今年的3月中旬去到了相机部门里面去实习，认识了很多牛人，迄今为止一次在公司里比较真切完整的体验，几乎足足有三个月。（不想说有多苦，宝宝心里苦，宝宝认真上班）总结来说并没有进步很多，但确实学到不少，企业的管理模式，内部沟通机制，安全机制等，我住在新安的宿舍，每天上班需要40分钟，过着早上10点上班，中午12点半点外卖，午休到2点，晚饭6点吃完，7点休息聊天看书，8点回去散漫工作的日子。虽然紧张，但规律有节奏的生活带来的好处却是有目共睹的。很庆幸认识了共同入职的新伙伴，陪我度
    
    </summary>
    
      <category term="Life" scheme="https://csrjtan.github.io/categories/Life/"/>
    
    
      <category term="感想" scheme="https://csrjtan.github.io/tags/%E6%84%9F%E6%83%B3/"/>
    
  </entry>
  
  <entry>
    <title>Demosaic Comparison</title>
    <link href="https://csrjtan.github.io/2016/05/16/ColorDemosaicComparison/"/>
    <id>https://csrjtan.github.io/2016/05/16/ColorDemosaicComparison/</id>
    <published>2016-05-16T13:12:12.000Z</published>
    <updated>2016-06-01T14:50:34.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Demosaic-Comparison&quot;&gt;&lt;a href=&quot;#Demosaic-Comparison&quot; class=&quot;headerlink&quot; title=&quot;Demosaic Comparison&quot;&gt;&lt;/a&gt;Demosaic Comparison&lt;/h3&gt;&lt;p&gt;  进入公司2个月多了，对于ISP和Demosaic才刚起步，赶紧把CNN掌握好，做出点工作来吧！&lt;/p&gt;
&lt;p&gt;总体来说， nnr和sht直接插值，锯齿感太强，Lu和NAT的方法效率不行，然后感觉AP和SA的PSNR虚高，实际效果不行。可以考虑测一下CPSNR和CIE L&lt;em&gt;a&lt;/em&gt;b或者锯齿等其它指标。&lt;br&gt;  下面比较一下AP[1], SA,LCC1和DLMMSE[2], RI[3]的结果。&lt;/p&gt;
&lt;p&gt;[1] SA, &lt;a href=&quot;http://www.csee.wvu.edu/~xinl/demo/demosaic.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.csee.wvu.edu/~xinl/demo/demosaic.html&lt;/a&gt;&lt;br&gt;[2] DLMMSE, Zhang L, Wu X. Color demosaicking via directional linear minimum mean square-error estimation[J]. Image Processing, IEEE Transactions on, 2005, 14(12): 2167-2178.&lt;br&gt;[3] RI, &lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&lt;/a&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CDC-5281.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CDC-5282.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/CDC-5283.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;结果总结&quot;&gt;&lt;a href=&quot;#结果总结&quot; class=&quot;headerlink&quot; title=&quot;结果总结&quot;&gt;&lt;/a&gt;结果总结&lt;/h3&gt;&lt;p&gt;总体来说，这些方法都在大部分地方插值准确，肉眼不容易区分，都没有发现有锯齿等明显不和谐区域的出现。主要是在变化剧烈的边缘和光亮变化强的区域出现Artifacts。时间上以SA、AP、LCC1、RI占优，效果上以DLMMSE和RI最优。&lt;br&gt;从实现来说LCC1是简单高效的，AP做了一个映射也是可以的，DLMMSE主要做了PCA的分解，SA是有迭代的求解，RI有待进一步学习。&lt;/p&gt;
&lt;h3 id=&quot;ImageJ&quot;&gt;&lt;a href=&quot;#ImageJ&quot; class=&quot;headerlink&quot; title=&quot;ImageJ&quot;&gt;&lt;/a&gt;ImageJ&lt;/h3&gt;&lt;p&gt;看了不少的论文和代码了，及时地来总结一下吧，马上又要开展对于DL的学习了。先来ImageJ的吧？把JAva各个类和用例都看了，然而并没有派上用场，所以应该吸取教训，先学足够的，马上就用。不然看完也没有机会用，看完也用不上，看完也还是不会用，对于CODING这样的事情来说就是实用至上，不断使用行动，付出并成为一种习惯，从而变成一种轻松的反射或者习惯，最后培养成为爱好。ImageJ主要是一个科学图像的小插件，由JAVA框架开发，可以不依赖系统，自带JRE。一般分为MARCRO,SCRIPTS等，做些命令脚本批量处理之类的。系统自带功能包括图像基本操作、处理和分析，强大之处在于用户可以开发插件Plugin快速量身定做图像处理工具。&lt;/p&gt;
&lt;p&gt;Plugin分为普通plugin，图片filter plugin以及堆 stack plugin。先setup了，获得指定图片类型后，然后用run()方法对读入的图片进行处理。总体还是看一下一本图像处理ImageJ实战和ImageJ手册吧，要用就回头去看一下。现在先放一放ImageJ吧，主力还是在Matlab和MatConv,高层的调用可以帮助开发者在思维和方法层面上更专注，不然用c和c++这样的还是需要花费力气在数据结构和指针，语言组织上，确实吃力不讨好的事情。&lt;/p&gt;
&lt;h3 id=&quot;ISP&quot;&gt;&lt;a href=&quot;#ISP&quot; class=&quot;headerlink&quot; title=&quot;ISP&quot;&gt;&lt;/a&gt;ISP&lt;/h3&gt;&lt;p&gt;   再者说一下关于ISP的流程吧，进来后发现组里是做相机的，包括从硬到软的各个层面，硬件-&amp;gt;FPGA-&amp;gt;嵌入式-&amp;gt;图像算法-&amp;gt;IQ等等。这里说一下相机出图的ISP流程，从RAW到用户看到的JPEG： RAW-&amp;gt;BLC-&amp;gt;LSC-&amp;gt;AWB-&amp;gt;DEMOSAIC-&amp;gt;DENOISE-&amp;gt;CC-&amp;gt;GAMMA-&amp;gt;JPEG，里面每个算法和相机原理都是进来才学习了解到的。希望对以后有用。&lt;/p&gt;
&lt;h3 id=&quot;Demosaic&quot;&gt;&lt;a href=&quot;#Demosaic&quot; class=&quot;headerlink&quot; title=&quot;Demosaic&quot;&gt;&lt;/a&gt;Demosaic&lt;/h3&gt;&lt;p&gt;   然后回到今天要记录的重点，Demosaic的papers和学习总结：首先看了Comparison和Survey这两篇关于去马赛克发展的重要文章，科普了不少要点：比如说如何用空间相关信息和谱间相关信息来恢复Downsample后的信息，讲述了主要包括空域和谱域的方法，color ratio and color difference的基本假设。空域上利用插值，bilinear以及梯度适应的adaptive gradient interpolation，还有转到其他频域如傅里叶和小波上面去做滤波的，根据不同频段的相关性来进行近似恢复。这里着重说一下影响力比较高的文章，首先是Alternating Projection：将谱间的强相关性信息映射到一个POCS(Project onto convex set）里面，然后求解convex问题得到一个较优的像素解来作为插值。然后是Succesive Approximate是将谱间差值的difference变成一个由局部迭代成局部最优的过程，先从简单的插值后，然后迭代更新color difference从而到达局部较优的位置。SSD是利用增强自相关性，还没仔细了解。还有利用非局部相似块的方法，如定义Non-local Similarity，如果它表达的相关性（梯度小）比当前块强，则用该块作为当前块的插值结果。然后我老板的两个比较突破性的论文：DLMMSE提出了去马赛克噪声，然后引入去噪模型，转换成求解最优color difference的方法，里面有些数学证明还待细看，该工作直接把PSNR提高了5db。后来的LDI_NAT也是经过LDI的梯度插值后，然后使用PCA的方法分解构造出sparse模型，从而去掉artifacts. 再后来的方法就包括一些sparse模型，dictionary learning，tv等，还有Tokyo Insitute 的RI方法，利用残差的方法，快速有效进行去马赛克。&lt;/p&gt;
&lt;h3 id=&quot;CNN&quot;&gt;&lt;a href=&quot;#CNN&quot; class=&quot;headerlink&quot; title=&quot;CNN&quot;&gt;&lt;/a&gt;CNN&lt;/h3&gt;&lt;p&gt;   后面用凯爷的网络跑了一下CNN的结果，目测要比Tokyo Institute的RI要好，这里用的是5层卷积神经网络，使用柯德IQA的库中500多张图片作为TrainingSets,Kodak的24张图作为TestSets，使用的是MatconvNet的框架。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Demosaic-Comparison&quot;&gt;&lt;a href=&quot;#Demosaic-Comparison&quot; class=&quot;headerlink&quot; title=&quot;Demosaic Comparison&quot;&gt;&lt;/a&gt;Demosaic Comparison&lt;/h3&gt;&lt;p&gt;  进入公司2个月多了，对于ISP和Demosaic才刚起步，赶紧把CNN掌握好，做出点工作来吧！&lt;/p&gt;
&lt;p&gt;总体来说， nnr和sht直接插值，锯齿感太强，Lu和NAT的方法效率不行，然后感觉AP和SA的PSNR虚高，实际效果不行。可以考虑测一下CPSNR和CIE L&lt;em&gt;a&lt;/em&gt;b或者锯齿等其它指标。&lt;br&gt;  下面比较一下AP[1], SA,LCC1和DLMMSE[2], RI[3]的结果。&lt;/p&gt;
&lt;p&gt;[1] SA, &lt;a href=&quot;http://www.csee.wvu.edu/~xinl/demo/demosaic.html&quot;&gt;http://www.csee.wvu.edu/~xinl/demo/demosaic.html&lt;/a&gt;&lt;br&gt;[2] DLMMSE, Zhang L, Wu X. Color demosaicking via directional linear minimum mean square-error estimation[J]. Image Processing, IEEE Transactions on, 2005, 14(12): 2167-2178.&lt;br&gt;[3] RI, &lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot;&gt;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="paper Demosaic" scheme="https://csrjtan.github.io/tags/paper-Demosaic/"/>
    
  </entry>
  
  <entry>
    <title>Ted《光荣与梦想》</title>
    <link href="https://csrjtan.github.io/2016/04/21/ted-glories-and-dream/"/>
    <id>https://csrjtan.github.io/2016/04/21/ted-glories-and-dream/</id>
    <published>2016-04-21T08:48:13.000Z</published>
    <updated>2016-06-01T14:52:06.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;特奥会冠军讲解智障人士生活&quot;&gt;&lt;a href=&quot;#特奥会冠军讲解智障人士生活&quot; class=&quot;headerlink&quot; title=&quot;特奥会冠军讲解智障人士生活&quot;&gt;&lt;/a&gt;特奥会冠军讲解智障人士生活&lt;/h3&gt;&lt;p&gt;首先看完一个感动的TED TALK，关于社会对智障人士的看法，一位特奥会的冠军以身作则提及他们的生活，受歧视，然特奥会提供了一个平台，展示属于他们生命的价值，他们的梦想和他们的尊严。相比于我们，诚然他们的舞台太小，但我们应该看到他们所作的努力。对于自己，四肢健全，家庭幸福安康，应该有更多的理由去追逐幸福，有时候不要一直想着缺少的，应该惦记自己所拥有的，记得感恩。并去勇敢自信的追逐自己所想所求，不要害怕失败，不要害怕别人的目光，勇敢的be yourself.虽然那可能不容易，但人生只有一次，时间是宝贵的&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;，追逐自己所看重的东西吧。成长在于做减法，在于专注，努力。奉献，寻找自己的价值，承担应有的价值。看到了不丹的视频，信仰让他们满足，与自然的好好相处让他们轻松。自己看得多可能欲望也多，但有时候压抑一下自己的欲望，追逐真正渴求的，也是一种成熟，我不知道是否经历过才算真的看透，但有些事情觉得经历了也不一定幸福，所以还是应该保有自己，一直是不断地思考迷茫，殊不知其实自己静不下来，无法专注于自己的学业。我认为应当认真一丝不苟地完成自己的任务，才是最大的意义，多去看有用实用的书，做有价值的事情，珍惜自己有的机会。完成好课程，做好实习的任务，要有一个研究生的觉悟。&lt;/p&gt;
&lt;p&gt;另外，追逐幸福的要素：&lt;br&gt;1.找到喜欢的工作，高收入，受到社会的尊重&lt;br&gt;2.减少上下班耗费的时间，有充足的社交时间&lt;br&gt;3.对国家和社会有政治热情，参与度。&lt;/p&gt;
&lt;h3 id=&quot;笔记本里的诗&quot;&gt;&lt;a href=&quot;#笔记本里的诗&quot; class=&quot;headerlink&quot; title=&quot;笔记本里的诗&quot;&gt;&lt;/a&gt;笔记本里的诗&lt;/h3&gt;&lt;p&gt;不论曾经的彼此多么幼稚，多么可笑&lt;br&gt;终有一天我们都变得成熟；&lt;br&gt;也终有一天，我们都会老去；&lt;br&gt;可是，却没有人可以永远不长大，&lt;br&gt;却没有人可以永远年轻，&lt;br&gt;成熟，有时候会让人心痛、很无奈。&lt;br&gt;那个时候才会懂得–&lt;br&gt;爱情本不是件该执着的事情。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/poem5291.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;特奥会冠军讲解智障人士生活&quot;&gt;&lt;a href=&quot;#特奥会冠军讲解智障人士生活&quot; class=&quot;headerlink&quot; title=&quot;特奥会冠军讲解智障人士生活&quot;&gt;&lt;/a&gt;特奥会冠军讲解智障人士生活&lt;/h3&gt;&lt;p&gt;首先看完一个感动的TED TALK，关于社会对智障人士的看法，一位特奥会的冠军以身作则提及他们的生活，受歧视，然特奥会提供了一个平台，展示属于他们生命的价值，他们的梦想和他们的尊严。相比于我们，诚然他们的舞台太小，但我们应该看到他们所作的努力。对于自己，四肢健全，家庭幸福安康，应该有更多的理由去追逐幸福，有时候不要一直想着缺少的，应该惦记自己所拥有的，记得感恩。并去勇敢自信的追逐自己所想所求，不要害怕失败，不要害怕别人的目光，勇敢的be yourself.虽然那可能不容易，但人生只有一次，时间是宝贵的
    
    </summary>
    
      <category term="Life" scheme="https://csrjtan.github.io/categories/Life/"/>
    
    
      <category term="Ted" scheme="https://csrjtan.github.io/tags/Ted/"/>
    
  </entry>
  
</feed>
