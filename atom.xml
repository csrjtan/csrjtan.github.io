<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CSRJTAN</title>
  <subtitle>Keep Moving</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://csrjtan.github.io/"/>
  <updated>2016-08-30T06:11:50.000Z</updated>
  <id>https://csrjtan.github.io/</id>
  
  <author>
    <name>CsrjTan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CS231n_总结</title>
    <link href="https://csrjtan.github.io/2016/08/30/CS231n-%E6%80%BB%E7%BB%93/"/>
    <id>https://csrjtan.github.io/2016/08/30/CS231n-总结/</id>
    <published>2016-08-30T05:42:05.000Z</published>
    <updated>2016-08-30T06:11:50.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;结束CS231N课程笔记&quot;&gt;&lt;a href=&quot;#结束CS231N课程笔记&quot; class=&quot;headerlink&quot; title=&quot;结束CS231N课程笔记&quot;&gt;&lt;/a&gt;结束CS231N课程笔记&lt;/h3&gt;&lt;p&gt;CS231N课程的总结，到了后面关于RNN的用法以及detection和sequential学习都是新颖领域。&lt;/p&gt;
&lt;p&gt;(知乎专栏的翻译版)[&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;1.首先是PYTHON的教学，NUMPY使用。&lt;br&gt;2.图像分类方法：线性分类，SOFTMAX,SVM&lt;br&gt;3.优化方法：梯度下降、最优化方法&lt;br&gt;4.BP的具体原理和实现细节&lt;br&gt;5.CNN的学习&lt;br&gt;6.如何设置参数以及学习率&lt;br&gt;7.现在RNN发展和DETECTION&lt;/p&gt;
&lt;h3 id=&quot;回到香港，最后一年的准备和学习&quot;&gt;&lt;a href=&quot;#回到香港，最后一年的准备和学习&quot; class=&quot;headerlink&quot; title=&quot;回到香港，最后一年的准备和学习&quot;&gt;&lt;/a&gt;回到香港，最后一年的准备和学习&lt;/h3&gt;&lt;p&gt;经过了一年的放养，每天度假似的过得战战兢兢，如履薄冰。遗憾于自己不抓紧，没有自学到很多东西之余，拖延着使得任务也一点一点的搁浅，让自己和周围的朋友都失望，实在是愧对自己。如何展现自己的能力和让自己得到价值的证明是首要思考的。&lt;/p&gt;
&lt;p&gt;保持看书、锻炼的习惯，养成早起，日子过得很滋润，也得让自己抓紧有所贡献。就像王健林所说的，先划一个一个小目标，比如说先赚他一个亿。只是内心对于走科研的路子和决心越来越不能肯定了，还是只是希望自己混点小日子就过活，虽然明明知道自己过小日子也不会幸福快活，奈何对自己没有充足的信任。找到自己的才华和发力点，兴趣点是关键。热爱音乐，艺术，游戏的我，能在年轻的路上走得多远，我们拭目以待。当然英语我也是不排斥的，趁着年轻，可以逼着自己做些不喜欢的事情，考验自己的能力和内心承受。&lt;/p&gt;
&lt;h3 id=&quot;关于人生方向和目标&quot;&gt;&lt;a href=&quot;#关于人生方向和目标&quot; class=&quot;headerlink&quot; title=&quot;关于人生方向和目标&quot;&gt;&lt;/a&gt;关于人生方向和目标&lt;/h3&gt;&lt;p&gt;这里设立五年的目标：1.经济上：能负起首付，买上小车，自给自足，一步一步过上满意的生活。&lt;br&gt;2.事业上：拿到PHD学位或者获得良好的工作岗位并得到升职的空间 3.家庭上：帮爸妈过上小康的生活，与另一半稳定温暖的生活 4.兴趣上：吉他和健身的造诣得到提升，还可以培养更多的兴趣，可以研发一下游戏周边有意义的活动 5.身心上：身体要锻炼，心灵要熏陶，眼界要开阔，精力要丰富，做成更多有意义的事情，建立自信。&lt;/p&gt;
&lt;p&gt;一步一步的小目标：1.坚持早睡早起 2.坚持跑步和健身 3.坚持背单词和写代码 4.坚持看论文和看书 5.定期总结&lt;/p&gt;
&lt;p&gt;设定了小目标之后，需要及时检验，以我对自己的了解，我喜欢玩游戏，所以这种及时和即时的反馈是十分重要。在获得正面反馈之后，必须及时定下新的任务，一步一步的挑战，下副本和打boss。这样的能力提高过程，伴随能力的提高以及自信的建立，重要的是建立量化指标和衡量能力的有效途径，对于经济，明显就是投资和金钱；对于事业，一方面是学位和职位，另一方面就是掌握的知识结构；对于家庭和生活，情感是最难以衡量的，只能尽自己的心情地去关怀和付出了；对于兴趣，吉他的熟练和记谱，健身的体重与肌肉，跑步的速度与长度；对于身心，每天多对自己微笑和加油，生活是自己的，每个人的世界都是由自己所决定的；&lt;/p&gt;
&lt;p&gt;对于小目标来说：1.坚持早睡早起30天，50天，100天，300天 2.跑步和健身需要错开，一周保持3~4次，每次不少于30分钟，还需要量化统计自己的健身，看到自己的进步 3.单词和代码也是很好量化统计的 4.论文和看书也不例外。  这里建议使用特定的软件和本子来统计自己的进度和进步，用电脑或者笔记来总结和记录自己的进步吧，关键在于精力差的时候能走出破坏习惯的怪圈。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;结束CS231N课程笔记&quot;&gt;&lt;a href=&quot;#结束CS231N课程笔记&quot; class=&quot;headerlink&quot; title=&quot;结束CS231N课程笔记&quot;&gt;&lt;/a&gt;结束CS231N课程笔记&lt;/h3&gt;&lt;p&gt;CS231N课程的总结，到了后面关于RNN的用法以及dete
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
  </entry>
  
  <entry>
    <title>GoodMood</title>
    <link href="https://csrjtan.github.io/2016/07/28/GoodMood/"/>
    <id>https://csrjtan.github.io/2016/07/28/GoodMood/</id>
    <published>2016-07-28T08:52:33.000Z</published>
    <updated>2016-07-28T09:25:07.000Z</updated>
    
    <content type="html">&lt;p&gt;刚完成了Confirmation,压力好大，缓不过气，每天都要充实的学习做实验和生活。阅读、记录、代码、健身、音乐，早睡早起，多交朋友，保持健康。&lt;/p&gt;
&lt;p&gt;这里搬运一些让自己好心情的方子：&lt;/p&gt;
&lt;h4 id=&quot;14条交友原则&quot;&gt;&lt;a href=&quot;#14条交友原则&quot; class=&quot;headerlink&quot; title=&quot;14条交友原则&quot;&gt;&lt;/a&gt;14条交友原则&lt;/h4&gt;&lt;p&gt;1.保证&lt;strong&gt;充足睡眠&lt;/strong&gt;情况下，早起让每天多出几个小时&lt;br&gt;2.做事情留出至少10分钟的余地，不要&lt;strong&gt;赶时间&lt;/strong&gt;&lt;br&gt;3.&lt;strong&gt;和喜欢的人说笑&lt;/strong&gt;&lt;br&gt;4.&lt;strong&gt;日事日毕&lt;/strong&gt;，尽量8小时内解决问题，不要把工作带入生活&lt;br&gt;5.每两天来一次酣畅淋漓的&lt;strong&gt;运动&lt;/strong&gt;&lt;br&gt;6.对不重要的事情&lt;strong&gt;不争抢不较劲&lt;/strong&gt;，如开车&lt;br&gt;7.多&lt;strong&gt;接触新事物&lt;/strong&gt;带来新鲜感，多&lt;strong&gt;学习新技能&lt;/strong&gt;带来成就感&lt;br&gt;8.&lt;strong&gt;改造环境&lt;/strong&gt;，比如装饰房间&lt;br&gt;9.仔细读&lt;strong&gt;好书&lt;/strong&gt;，让心灵成熟、自由，有更多创造快乐的方法&lt;br&gt;10.&lt;strong&gt;偶尔放松&lt;/strong&gt;，通宵看球，和妹子开黑，吃零食看剧，躺床上看一天小说什么的。&lt;br&gt;11.每隔一段时间就换环境呆一段时间，&lt;strong&gt;度个假，旅个游&lt;/strong&gt;&lt;br&gt;12.每天给自己&lt;strong&gt;独处&lt;/strong&gt;的时间&lt;br&gt;13.&lt;strong&gt;早睡&lt;/strong&gt;，心里不会有负罪感，第二天精力充沛&lt;br&gt;14.&lt;strong&gt;不和不重要的人撕逼&lt;/strong&gt;&lt;br&gt;15.&lt;strong&gt;远离傻逼&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;交友原则&quot;&gt;&lt;a href=&quot;#交友原则&quot; class=&quot;headerlink&quot; title=&quot;交友原则&quot;&gt;&lt;/a&gt;交友原则&lt;/h4&gt;&lt;p&gt;1.不要非和某人做朋友，不喜欢就保持距离&lt;br&gt;2.合得来的人要好好相处，不计较地乐于助人&lt;br&gt;3.不要胡思乱想，顺势而为&lt;br&gt;4.管理好自己的形象，衣着配饰得体，运动整洁&lt;br&gt;5.尽最大努力去赚钱，理清现实后不妄想得不到的东西&lt;br&gt;6.爱，不苟求。‘与有情人做快乐事，不理是劫还是缘’&lt;br&gt;7.温柔的对待父母&lt;br&gt;8.不买，可有可无的东西；必需品则买经典耐用的&lt;br&gt;9.有话就说，不知道怎么说才好就照直了说，恶言恶语当场反驳&lt;br&gt;10.别给自己的行为贴不好的标签，内向就是内向，不是抑郁&lt;br&gt;11.爱情本身不会影响生活，对爱情犹豫不决才会，为爱情忽略自我才会&lt;br&gt;12.找机会与看似快乐的陌生人玩耍，和爱自己的亲人吃饭。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/Beauty.jpg&quot; alt=&quot;美女们&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;刚完成了Confirmation,压力好大，缓不过气，每天都要充实的学习做实验和生活。阅读、记录、代码、健身、音乐，早睡早起，多交朋友，保持健康。&lt;/p&gt;
&lt;p&gt;这里搬运一些让自己好心情的方子：&lt;/p&gt;
&lt;h4 id=&quot;14条交友原则&quot;&gt;&lt;a href=&quot;#14条交友原则&quot;
    
    </summary>
    
      <category term="Life" scheme="https://csrjtan.github.io/categories/Life/"/>
    
    
      <category term="health" scheme="https://csrjtan.github.io/tags/health/"/>
    
  </entry>
  
  <entry>
    <title>matconvnet配置</title>
    <link href="https://csrjtan.github.io/2016/06/26/matconvnet%E9%85%8D%E7%BD%AE/"/>
    <id>https://csrjtan.github.io/2016/06/26/matconvnet配置/</id>
    <published>2016-06-26T08:12:44.000Z</published>
    <updated>2016-06-26T08:35:55.000Z</updated>
    
    <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.vlfeat.org/matconvnet/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;matconvnet&lt;/a&gt;,使用CNN做Image Demosaicking，由于组内的师兄主要使用这个框架，率先对这个框架进行快速上手使用和学习，CS231N也不能落下，之后可以考虑对CAFFE进行学习。&lt;/p&gt;
&lt;h4 id=&quot;配置&quot;&gt;&lt;a href=&quot;#配置&quot; class=&quot;headerlink&quot; title=&quot;配置&quot;&gt;&lt;/a&gt;配置&lt;/h4&gt;&lt;p&gt;首选由于选择软件的版本上也做了点无用功，亲测之下使用一下组合是有效的。&lt;strong&gt;win8.1+VS2013+MatlabR2014a+CUDA7.5+Cudnn-rc5&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;由于系统和Matlab的兼容性问题，感觉如此的组合是最为高效可靠的。&lt;br&gt;首先是mex -setup的问题，MatlabR2014a尚不支持VS2015的，为此我还体验了一会儿WIN10和VS2015.但考虑到后期开发和兼容性的问题，使用稳定版本是最为可靠的！对于下载后的源码，mex -setup设置成功后，直接跑vl_compilenn，则通过编译CPU的版本。这里着重说一下GPU版本，因为编译执行了很多次，不是编译就是运行代码时候遇到问题了，这里说一下自己的理解和亲测的过程。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.voidcn.com/blog/Hungryof/article/p-5047632.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;matconvnet gpu的方法&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;首先使用了CUDA5.5的版本，但由于在编译时遇到了点问题，意识到应该使用7.5版本，而且无论caffe还是最近来说，7.5版本是比较稳定，而且适应我当前使用的TITAN X的显卡设备。然后使用vl_complinn(‘enableGpu’,true)则可实现普通GPU的版本。然而一直卡在使用cuDnn包的时候编译或者运行就出错。后来发现是用的rc-4的包不正确，应当使用官方的包，直接下了rc-5的版本。[建议任何的框架和库都使用官方版本！]最后终于成功了，跑cifar的example,1500Hz for gpu; cuDnn成功后，达到6700Hz!&lt;/p&gt;
&lt;h4 id=&quot;学习&quot;&gt;&lt;a href=&quot;#学习&quot; class=&quot;headerlink&quot; title=&quot;学习&quot;&gt;&lt;/a&gt;学习&lt;/h4&gt;&lt;p&gt;这俩天认真的学习了一下MatconvNet,主要看官网的所有资料，以及example例子，然后就是VGG的&lt;a href=&quot;http://www.robots.ox.ac.uk/~vgg/practicals/cnn/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;顺带有空把后面每一个函数的注释看一下，学会用法；针对于使用CNN，可以参考一下过程：&lt;br&gt;&lt;strong&gt;&lt;br&gt;1.Prepare Data&lt;br&gt;2.Set up Training parameters&lt;br&gt;&lt;a href=&quot;http://3.Training&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;3.Training&lt;/a&gt; Process:&lt;br&gt;    for num = 1:nEpoch&lt;br&gt;        train model on training set&lt;br&gt;        test on validation set&lt;br&gt;    end&lt;br&gt;4.Test on fianl test data
&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.vlfeat.org/matconvnet/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;matconvnet&lt;/a&gt;,使用CNN做Image Demosaicking，由于组内的师兄主要使用这个框架，率先对这个框
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="matconvNet" scheme="https://csrjtan.github.io/tags/matconvNet/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_8_9</title>
    <link href="https://csrjtan.github.io/2016/06/21/CS231n-8/"/>
    <id>https://csrjtan.github.io/2016/06/21/CS231n-8/</id>
    <published>2016-06-21T11:16:47.000Z</published>
    <updated>2016-06-21T12:47:49.000Z</updated>
    
    <content type="html">&lt;h3 id=&quot;Lec8&quot;&gt;&lt;a href=&quot;#Lec8&quot; class=&quot;headerlink&quot; title=&quot;Lec8&quot;&gt;&lt;/a&gt;Lec8&lt;/h3&gt;&lt;p&gt;Spatial Localization and Detection&lt;/p&gt;
&lt;h4 id=&quot;Tasks&quot;&gt;&lt;a href=&quot;#Tasks&quot; class=&quot;headerlink&quot; title=&quot;Tasks&quot;&gt;&lt;/a&gt;Tasks&lt;/h4&gt;&lt;p&gt;Classification, Classificatin+Localization, Object Detection, Instance Segmentation.&lt;/p&gt;
&lt;p&gt;Localization, I:Image O:Box in the image(x,y,w,h) E:Intersection over Union.(IoU)&lt;/p&gt;
&lt;h4 id=&quot;Claissification-Localization&quot;&gt;&lt;a href=&quot;#Claissification-Localization&quot; class=&quot;headerlink&quot; title=&quot;Claissification+Localization&quot;&gt;&lt;/a&gt;Claissification+Localization&lt;/h4&gt;&lt;p&gt;Output: Single Label and Bounding Box&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Idea one&lt;/strong&gt;: Two task head&lt;br&gt;1.Train a CNN&lt;br&gt;2.Attach new fully-connected “regression head” to the network(FC)&lt;br&gt;  2.1 Classification Head&lt;br&gt;  2.2 Regression Head&lt;br&gt;3.Train the regression head only with SGD and L2 loss&lt;br&gt;&lt;a href=&quot;http://4.At&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;4.At&lt;/a&gt; test time use both heads&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Idea two&lt;/strong&gt;: Sliding Window&lt;br&gt;Input: Bounding Box&lt;br&gt;Iteratively refine the BB into a optimal size and place.&lt;/p&gt;
&lt;h4 id=&quot;Objects-Detection&quot;&gt;&lt;a href=&quot;#Objects-Detection&quot; class=&quot;headerlink&quot; title=&quot;Objects Detection&quot;&gt;&lt;/a&gt;Objects Detection&lt;/h4&gt;&lt;p&gt;Output: all the exist labels and BBs&lt;/p&gt;
&lt;p&gt;Problem: Need to test many positions and scales, use computationally demanding classifier&lt;/p&gt;
&lt;p&gt;Solution: Only look at a tiny subset of possible positions&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Region Proposal&lt;/strong&gt;:Bottom-up segmentation.&lt;/p&gt;
&lt;p&gt;RCNN: 1. Train a classification model on ImageNet&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Fine-tune model for detection(Throw finaly FC rathter than 20 Objects and one background, that is 4096*21 for the last layer.)&lt;/li&gt;
&lt;li&gt;Extract Features: Extract region proposals for all images, save the pool5 features to disk.&lt;/li&gt;
&lt;li&gt;Train one binary SVM per class to claissify region features.&lt;/li&gt;
&lt;li&gt;Bbox regression: Train a linear model to fine-grain the bbox&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Fast-RCNN: Build an end-to-end framework, much faster than RCNN.&lt;/p&gt;
&lt;h4 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0621classification.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Lec9-Understanding-and-Visualizing&quot;&gt;&lt;a href=&quot;#Lec9-Understanding-and-Visualizing&quot; class=&quot;headerlink&quot; title=&quot;Lec9 Understanding and Visualizing&quot;&gt;&lt;/a&gt;Lec9 Understanding and Visualizing&lt;/h3&gt;&lt;p&gt;Visualizing the weights, t-SNE visualization&lt;/p&gt;
&lt;p&gt;Deconv Approaches:&lt;br&gt;1.Feed image into net&lt;br&gt;2.pick a layer, set gradients of the score vector to [0 0 1 .. 0], then bp to image&lt;br&gt;&lt;a href=&quot;http://3.Do&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;3.Do&lt;/a&gt; a small “Image Update”&lt;br&gt;4.Forward the Image&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Go to step 2&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0621deconv.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;Deconv&quot;&gt;&lt;a href=&quot;#Deconv&quot; class=&quot;headerlink&quot; title=&quot;Deconv&quot;&gt;&lt;/a&gt;Deconv&lt;/h4&gt;&lt;p&gt;Learn to visualize the weights, also deconv to reconstruct an larger size output.&lt;/p&gt;
&lt;p&gt;Deconv: reverse the convolution filter&lt;br&gt;DePool: record the position and set other be zero.&lt;br&gt;DeReLU: The same as the ReLU.&lt;/p&gt;
&lt;h4 id=&quot;Neural-Style&quot;&gt;&lt;a href=&quot;#Neural-Style&quot; class=&quot;headerlink&quot; title=&quot;Neural Style&quot;&gt;&lt;/a&gt;Neural Style&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;extract content targets&lt;/li&gt;
&lt;li&gt;extract style targets&lt;/li&gt;
&lt;li&gt;Optimize over image &lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;BackPropping-is-powerful&quot;&gt;&lt;a href=&quot;#BackPropping-is-powerful&quot; class=&quot;headerlink&quot; title=&quot;BackPropping is powerful&quot;&gt;&lt;/a&gt;BackPropping is powerful&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Understanding&lt;/li&gt;
&lt;li&gt;Segmenting Objects in the Image&lt;/li&gt;
&lt;li&gt;Inverting codes and introducing privacy concerns&lt;/li&gt;
&lt;li&gt;Fun(NeuralStyle/DeepDream)&lt;/li&gt;
&lt;li&gt;Confusion and chaos(Adversarial Examples)&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;Lec8&quot;&gt;&lt;a href=&quot;#Lec8&quot; class=&quot;headerlink&quot; title=&quot;Lec8&quot;&gt;&lt;/a&gt;Lec8&lt;/h3&gt;&lt;p&gt;Spatial Localization and Detection&lt;/p&gt;
&lt;h4 id=&quot;Tasks&quot;&gt;&lt;a href=
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="CNN 公开课" scheme="https://csrjtan.github.io/tags/CNN-%E5%85%AC%E5%BC%80%E8%AF%BE/"/>
    
  </entry>
  
  <entry>
    <title>Bilateral_Guided_Filter</title>
    <link href="https://csrjtan.github.io/2016/06/13/Bilateral-Guided-Filter/"/>
    <id>https://csrjtan.github.io/2016/06/13/Bilateral-Guided-Filter/</id>
    <published>2016-06-13T02:24:43.000Z</published>
    <updated>2016-06-13T04:09:51.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;Bilateral-Filter&quot;&gt;&lt;a href=&quot;#Bilateral-Filter&quot; class=&quot;headerlink&quot; title=&quot;Bilateral Filter&quot;&gt;&lt;/a&gt;Bilateral Filter&lt;/h4&gt;&lt;p&gt;双边滤波主要考虑了邻域里的像素加权，权重受几何距离和色彩距离相关。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613bilateral.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;双边滤波具有Non-linear, edge-preseving and noise-reducing smoothing的特性。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613bi1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;Guided-Filter&quot;&gt;&lt;a href=&quot;#Guided-Filter&quot; class=&quot;headerlink&quot; title=&quot;Guided Filter&quot;&gt;&lt;/a&gt;Guided Filter&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613guided.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;加入了引导图像的抽象，可以不一定沿着自身而做bilateral filter的。但这里guided filter还是用自身的保持边缘滤波来先理解。&lt;/p&gt;
&lt;p&gt;与bilateral的区别在于不是简单地利用spatial和range,而是建立一个局部的线性关系，在当前更新pixel的局部窗口k中，建立一个局部线性关系。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613linear.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后根据线性回归，对每个像素求解出其对应的参数$a_k,b_k$,再分“High variance”和”Flat patch”进行处理。&lt;br&gt;如果a-&amp;gt;1,b-&amp;gt;0:High Variance,保持值不变&lt;br&gt;如果a-&amp;gt;0,b-&amp;gt;$\mu_k$:Flat patch,使用临近像素平均&lt;/p&gt;
&lt;h4 id=&quot;具体数学分析&quot;&gt;&lt;a href=&quot;#具体数学分析&quot; class=&quot;headerlink&quot; title=&quot;具体数学分析&quot;&gt;&lt;/a&gt;具体数学分析&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613gui1.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0613gui2.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;保留了Bilateral filter的优点，同时克服了缺点，使得平滑之余达到边沿保留。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;Bilateral-Filter&quot;&gt;&lt;a href=&quot;#Bilateral-Filter&quot; class=&quot;headerlink&quot; title=&quot;Bilateral Filter&quot;&gt;&lt;/a&gt;Bilateral Filter&lt;/h4&gt;&lt;p&gt;双边滤波主要考虑了邻域里的像
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
  </entry>
  
  <entry>
    <title>时间简史</title>
    <link href="https://csrjtan.github.io/2016/06/12/%E6%97%B6%E9%97%B4%E7%AE%80%E5%8F%B2/"/>
    <id>https://csrjtan.github.io/2016/06/12/时间简史/</id>
    <published>2016-06-12T03:23:17.000Z</published>
    <updated>2016-06-12T03:45:43.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h4&gt;&lt;p&gt;这是霍金在2010出版的书，讲述近代纯物理学的一些研究成果以及围绕宇宙学来展开的一系列科普理论。&lt;br&gt;这个评价很高也让我了解到物理学是怎么去做research的，然而无奈自己太多理论没有接触过，也没有上过《大学物理》这个课程，中间太多断层的知识唯有靠瞎蒙，无奈第一次十分不理解地看完了。想做点笔记，也只能围绕书本的结构顺序展开基本的描述，也参考了一下豆瓣上的笔记之类的，在这里总结一下，毕竟这个书前前后后读了2周，依然云里雾里。庆幸的是我对为何宇宙膨胀，黑洞、虫洞、空间曲率等有了更深的理解。因为我很喜欢关于宇宙题材的电影，包括《火星救援》、《星际穿越》、《星际迷航》等等。还是很值得一看，这是个重要的科学问题，也是一个哲学问题。&lt;/p&gt;
&lt;p&gt;最后，大部分的朋友也是认为此书看不懂是正常的，甚至连物理系的学生也可能不能完全读通，主要是一来物理学未成大体系，二来目前研究还很粗糙，霍金用个人的理解和总结来描述，总不免有未能顾及大众科普，三来对基本理论的掌握要求比较高，不然无法延伸出来这些观点。&lt;/p&gt;
&lt;h4 id=&quot;文章结构&quot;&gt;&lt;a href=&quot;#文章结构&quot; class=&quot;headerlink&quot; title=&quot;文章结构&quot;&gt;&lt;/a&gt;文章结构&lt;/h4&gt;&lt;p&gt;这里把看书的笔记列一下，比较杂乱:&lt;br&gt;人类发展以来的宇宙观和世界观：地方说-&amp;gt;地圆说（上帝说）-&amp;gt;日心说（哥白尼）-&amp;gt;椭圆轨道-&amp;gt;万有引力（牛顿）-&amp;gt;狭义相对论-&amp;gt;广义相对论-&amp;gt;宇宙大爆炸&lt;/p&gt;
&lt;p&gt;组成成分的认识： 四元素（亚里士多德）-&amp;gt;原子论（道尔）-&amp;gt;布朗运动-&amp;gt;电子（卢瑟福）-&amp;gt;中子（查德威克）-&amp;gt;夸克（加州理工1969）&lt;/p&gt;
&lt;p&gt;四种力：万有引力、电磁力、弱核力、强作用力&lt;/p&gt;
&lt;p&gt;量子物理（微观）：量子假设、不确定性原理、薛定谔的猫&lt;br&gt;热力学熵增（有序到无序）：热力学箭头，心理学箭头，宇宙学箭头&lt;br&gt;黑洞的“无毛定力”，称为“不能逃逸远处的时间集合”、弱人择原理、不完备定理、虫洞（空间扭曲）、宇宙弦（张力大的橡筋），光速C为常量且最快，粒子无法提速到99.99%*c,无论功率如何加大。还有光锥、高维空间、PST对称原理等。&lt;/p&gt;
&lt;h4 id=&quot;借鉴总结&quot;&gt;&lt;a href=&quot;#借鉴总结&quot; class=&quot;headerlink&quot; title=&quot;借鉴总结&quot;&gt;&lt;/a&gt;借鉴总结&lt;/h4&gt;&lt;p&gt;【引用自豆瓣 川贝】&lt;/p&gt;
&lt;p&gt;一、物质（Substance）&lt;br&gt;物质即一种存在。物质由一些基本粒子（自旋为1/2）构成。物质的绝对静止是不存在的，物质的绝对状态是不停运动变化的。质量和能量是描述物质状态的两个重要属性，两者皆满足广泛意义上的守恒定律，且可以互相转化。力（自旋为0，1，2的虚粒子）和波（自旋为0，1，2的实粒子）描述了物质间的相互作用及效果，自然界归纳出四种基本的力：引力、电磁力、强核力、弱核力。&lt;/p&gt;
&lt;p&gt;二、时空（Time&amp;amp;Space）&lt;br&gt;当我们跳出低维度的视角去思考这个世界，时间和空间是一个混合的概念，时空的本质是物质的散漫态，而时间只是物质状态变迁的一种度量。时间箭头是基于热力学方向（闭合系统中的熵总是随时间增加）、心理学方向（取决于热力学方向）、宇宙学方向（方向不定，但根据人择原理，现在它与前两个方向一致）的。关于广义相对论和时空曲率的一些论证及推论让我们看到通过旋转黑洞、虫洞进行时空旅行的可能性。&lt;/p&gt;
&lt;p&gt;三、科学（Science）&lt;br&gt;从最初亚里士多德的权威说法到牛顿的经典理论再到爱因斯坦的相对论和近代物理学的量子论，科学理论的提出、完善、应用乃至推翻，每每令人惊叹随即错愕。让我来回想一下部分基本理论及关键字：&lt;br&gt;1、电磁场理论：四个方程，似乎没什么好说的。做大一统工作的人总能博得满堂彩，向麦克斯韦致敬。也正是这个理论方程关于伽利略变换的不谐洽导致了洛伦兹变换和相对论的提出。&lt;br&gt;2、相对论：狭义相对论凭借两条简洁的假设，开拓了一个崭新的时空观，重新探讨了惯性系中物体的运动规律，由此衍生出来的一系列推论和预言近乎完美的解释并验证了诸多难题，继而广义相对论又对非惯性系中的物体运动规律做了进一步研究，赋予了引力场和惯性等物理概念以新的科学内涵，有力地推动了天文宇宙物理学的快速发展。&lt;br&gt;3、量子理论：光电效应、波谱研究、康普顿效应、德布罗意波-&amp;gt;量子化（从普朗克到波尔）！海森堡不确定性原理（俗称测不准原理）放弃了量子状态的精确测量、泡利不相容原理－&amp;gt;概率波、薛定谔方程，还有一大堆基本粒子及其量子状态描述（复杂从略），量子物理学作为研究物质微观机理的近代理论还在不断的完善中……&lt;br&gt;4、近代宇宙学：宇宙的起源及演化（热大爆炸学说，弗里德曼闭合宇宙，宇宙无边界设想）、黑洞理论（坍塌，高密度，大引力）、虫洞(时空负曲率)、人择原理（最莫名其妙的原理：“不要问为什么，因为这就是答案”）、暗物质（反粒子）、弦理论、……关于宇宙的理论与设想自古以来就没少过。&lt;br&gt;5、理论的统一：广义相对论用以描述宇宙的大尺度结构（几公里到1亿亿亿英里），量子力学用以处理极小尺度现象（百万亿分之一米），然而，可惜的是这两个理论不是互相协调的——它们不可能都对！现在科学家们正在思索并探寻一种被称为“量子引力论”的统一理论。自然界中的四种基本力中除引力外的其他三种力的统一已经在GUT（大统一理论）中初见端倪，然而离最终得到包含包括引力在内的所有力和普适物理规律的统一理论还有相当长的一段路要走。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h4&gt;&lt;p&gt;这是霍金在2010出版的书，讲述近代纯物理学的一些研究成果以及围绕宇宙学来展开的一系列科普理论。&lt;br&gt;这个评价很高也让我了解到物理学是怎么
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="Read" scheme="https://csrjtan.github.io/tags/Read/"/>
    
  </entry>
  
  <entry>
    <title>CS231n-7</title>
    <link href="https://csrjtan.github.io/2016/06/09/CS231n-7/"/>
    <id>https://csrjtan.github.io/2016/06/09/CS231n-7/</id>
    <published>2016-06-09T06:33:36.000Z</published>
    <updated>2016-06-09T13:33:20.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;CNN&quot;&gt;&lt;a href=&quot;#CNN&quot; class=&quot;headerlink&quot; title=&quot;CNN&quot;&gt;&lt;/a&gt;CNN&lt;/h4&gt;&lt;p&gt;终于进入CNN的话题了，介绍一下CONV,POOL,FC层的做法，具体的结构、参数、运算量等。&lt;/p&gt;
&lt;p&gt;回顾一下，Mini-batch SGD&lt;br&gt;Loop: 1. &lt;strong&gt;Sample&lt;/strong&gt; a batch of data&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Forward&lt;/strong&gt; prop it through the graph, get loss&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Backprop&lt;/strong&gt; to calculate the gradients&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Update&lt;/strong&gt; the parameters using the gradient&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609CNN.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;卷积操作过程的参数计算公式图，趋向于用数量更多的小Filter,更深的网络。&lt;br&gt;ConV的卷积核深度总是和输入的立方Feature Map的深度一致，而Kernel的个数就是新的FeatureMap的Depth.&lt;/p&gt;
&lt;p&gt;一般来说：Max Pool with 2*2 filters and stride 2&lt;/p&gt;
&lt;p&gt;FC： Containes Neurons connect to the entire input volume&lt;/p&gt;
&lt;p&gt;ConV的参数取决于Filter,例如227&lt;em&gt;227&lt;/em&gt;3通道的Feature Map,用Stride为4的96个Kernel 11&lt;em&gt;11 Filters,则有(11&lt;/em&gt;11&lt;em&gt;3)&lt;/em&gt;96=35K， Output Volum [((227-11)/4+1)&lt;em&gt;55&lt;/em&gt;96]&lt;/p&gt;
&lt;p&gt;Pool的参数为0，FC的参数最多.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609ALEX.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2012的ALEXNET的网络架构&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609VGG.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;2014的VGGNET网络架构和参数，主要占显存的是头几层的FeatureMap,而主要占用参数是FC层，VGG是初始化效果最佳的网络之一。&lt;br&gt;TOTAL MEMORY: 24M&lt;em&gt;4bytes ~= 93MB/image (Only forward!~&lt;/em&gt;2 for bwd)&lt;br&gt;TOTAL params: 138M parameters&lt;/p&gt;
&lt;p&gt;之后是GoogleNET(2014),6.7% for top5 error,12X less params than ALEXNET&lt;br&gt;然后是MSRA的RESNET（2015）， 3.6% top5 error, at runtime: faster than VGGNet&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0609RES.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;特点：BN after every CONV, Xavier/2 for initialization, SGD+Momentum(0.9), Learning rate,0.1 and dived by 10 when validation error plateaus. Mini-batch size 256, Weight decay of 1e-5, No dropout&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;CNN&quot;&gt;&lt;a href=&quot;#CNN&quot; class=&quot;headerlink&quot; title=&quot;CNN&quot;&gt;&lt;/a&gt;CNN&lt;/h4&gt;&lt;p&gt;终于进入CNN的话题了，介绍一下CONV,POOL,FC层的做法，具体的结构、参数、运算量等。&lt;/p&gt;
&lt;p&gt;回顾一下，Mini-b
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>CS231n_6</title>
    <link href="https://csrjtan.github.io/2016/06/09/CS231n-6/"/>
    <id>https://csrjtan.github.io/2016/06/09/CS231n-6/</id>
    <published>2016-06-09T04:34:02.000Z</published>
    <updated>2016-06-09T06:33:55.000Z</updated>
    
    <content type="html">&lt;p&gt;开始新一课之前，先来把上一节的相关阅读材料的知识补充上来。&lt;/p&gt;
&lt;h3 id=&quot;Lecture-5-Notes2-amp-3&quot;&gt;&lt;a href=&quot;#Lecture-5-Notes2-amp-3&quot; class=&quot;headerlink&quot; title=&quot;Lecture 5 Notes2&amp;amp;3&quot;&gt;&lt;/a&gt;Lecture 5 Notes2&amp;amp;3&lt;/h3&gt;&lt;h4 id=&quot;Regularization&quot;&gt;&lt;a href=&quot;#Regularization&quot; class=&quot;headerlink&quot; title=&quot;Regularization&quot;&gt;&lt;/a&gt;Regularization&lt;/h4&gt;&lt;p&gt;L1,L2的Loss function 还有Max Norm constraints: 对于系数向量w,有$w^2 &amp;lt; c$ ，C一般为3或4.&lt;br&gt;Dropout的技术：一般采用P=0.5,每个神经元的激活概率为0.5，然后每个样本对应一个新的Mask之后的子网络进行训练，最后测试的时候开启全部神经元但得到的结果需要乘上P=0.5这个系数。这种技术直观的好处是：1.迫使网络学习冗余的表达能力  2.实现了大型的学习模型，具有共享参数特性 &lt;/p&gt;
&lt;p&gt;Practice: 使用single,global L2 Regularization(cross-validated)+ Dropout(p=0.5)&lt;/p&gt;
&lt;h4 id=&quot;Loss-Functions&quot;&gt;&lt;a href=&quot;#Loss-Functions&quot; class=&quot;headerlink&quot; title=&quot;Loss Functions&quot;&gt;&lt;/a&gt;Loss Functions&lt;/h4&gt;&lt;p&gt;针对classification的任务，使用Softmax或者SVM Loss. 针对类别多的情况，可以使用Hierarchical Softmax. &lt;/p&gt;
&lt;p&gt;Attribute Classification可以用Logistic regression classifier with two classes(0,1)&lt;/p&gt;
&lt;p&gt;Regression任务，一般使用L2或者L1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;br&gt;When faced with a regression task, first consider if it is absolutely necessary. Instead, have a strong preference to discretizing your outputs to bins and perform classification over them whenever possible.
&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;Gradient-Checks&quot;&gt;&lt;a href=&quot;#Gradient-Checks&quot; class=&quot;headerlink&quot; title=&quot;Gradient Checks&quot;&gt;&lt;/a&gt;Gradient Checks&lt;/h4&gt;&lt;p&gt;Use centered formula,求梯度用左右方向的平均。$$\frac{df(x)}{dx} = \frac{f(x+h)-f(x-h)}{2h}$$&lt;/p&gt;
&lt;p&gt;Use relative error for the comparison, relative error&lt;br&gt;$$ \frac{ |f_a - f_n | }{max(f_a,f_n)} $$  . $f_a$ 为analytic gradient  , $f_n$ 为numberic gradient &lt;/p&gt;
&lt;p&gt;In practice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;relative error &amp;gt; 1e-2 usually means the gradient is probably wrong&lt;/li&gt;
&lt;li&gt;1e-2&amp;gt;relative error&amp;gt;1e-4 should make you feel uncomfortable&lt;/li&gt;
&lt;li&gt;1e-4&amp;gt;relative error is usually okay for objectives with kinks, but if there are no kinks(such tanh nonlinearities and softmax) , then 1e-4 is too high.&lt;/li&gt;
&lt;li&gt;1e-7 and less you should be happy&lt;/li&gt;
&lt;li&gt;if too small like or than 1e-10, absolute value is worrying&lt;br&gt;越深的网络，relative errors越大，如果10层，则1e-2是可以接受的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Summary: Careful with step size h, Gradcheck important, Don’t let regularization overwhelm the data, turn off the dropout/augmentations when gradient check, check only few dimensions.&lt;/p&gt;
&lt;h3 id=&quot;Lecture-6&quot;&gt;&lt;a href=&quot;#Lecture-6&quot; class=&quot;headerlink&quot; title=&quot;Lecture 6&quot;&gt;&lt;/a&gt;Lecture 6&lt;/h3&gt;&lt;h4 id=&quot;How-to-do-parameter-Updates&quot;&gt;&lt;a href=&quot;#How-to-do-parameter-Updates&quot; class=&quot;headerlink&quot; title=&quot;How to do parameter Updates&quot;&gt;&lt;/a&gt;How to do parameter Updates&lt;/h4&gt;&lt;p&gt;1.SGD: $x+= -learning rate *dx$&lt;br&gt;2.Momentum:  allow velocity build up, velocity damped in steep due to changing sign&lt;/p&gt;
&lt;p&gt;v = mu &lt;em&gt; v - learning_rate &lt;/em&gt; dx&lt;br&gt;x += v&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Nestreov Momentum:&lt;br&gt;$v_t = \mu v_{t-1} - \epsilon \Delta f(\theta_{t-1} + \mu V_{t-1})$&lt;br&gt;$\theta_t = \theta_{t-1} + V_t$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;4.Adagrad: Equalization the steep and shallow direction&lt;br&gt;cache + = dx &lt;em&gt;*2&lt;br&gt;x += - learn_rate &lt;/em&gt; dx / (sqrt(cache)+1e-7)&lt;/p&gt;
&lt;p&gt;5.Adam: Great enough with bias correct&lt;br&gt;m = beta1 &lt;em&gt; m + (1-beta1)&lt;/em&gt;dx&lt;br&gt;v = beta2 &lt;em&gt; v + (1-beta2)&lt;/em&gt;(dx &lt;em&gt;*2)&lt;br&gt;x += -learn_rate &lt;/em&gt; m/(sqrt(v)+1e-7)&lt;br&gt;一般beta1和beta2可以设置为0.9和0.995&lt;/p&gt;
&lt;h4 id=&quot;Second-Order-Optimization&quot;&gt;&lt;a href=&quot;#Second-Order-Optimization&quot; class=&quot;headerlink&quot; title=&quot;Second Order Optimization&quot;&gt;&lt;/a&gt;Second Order Optimization&lt;/h4&gt;&lt;p&gt;1.泰勒展开&lt;br&gt;2.Newton Gradient: Jacobian H is too large with O(n^3),n is million&lt;br&gt;3.Quasi-Newton O(n^2)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;L-BFGS(Limited Memory BFGS):work well in full patch,but can not transfoer well to mini-batch search.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Practice: 1.Train Multiple Indeoendent model&lt;br&gt;&lt;a href=&quot;http://2.At&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;2.At&lt;/a&gt; test time average the results &lt;/p&gt;
&lt;p&gt;Fun tricks: get small boost from average multiple initilization model, keep track running average parametre vector.&lt;/p&gt;
&lt;h4 id=&quot;Annealing-learning-rate&quot;&gt;&lt;a href=&quot;#Annealing-learning-rate&quot; class=&quot;headerlink&quot; title=&quot;Annealing learning rate&quot;&gt;&lt;/a&gt;Annealing learning rate&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;step dcay: learning rate by half every t epochs&lt;/li&gt;
&lt;li&gt;Exponential decay $\alpha = \alpha_0 e^{-kt}$&lt;/li&gt;
&lt;li&gt;1/t decay: $\alpha = \alpha_0 /(1+kt)$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Hyperparameter-optimzation&quot;&gt;&lt;a href=&quot;#Hyperparameter-optimzation&quot; class=&quot;headerlink&quot; title=&quot;Hyperparameter optimzation&quot;&gt;&lt;/a&gt;Hyperparameter optimzation&lt;/h4&gt;&lt;p&gt;stage search from coarse to fine&lt;br&gt;bayesian hyperparameter optimization&lt;br&gt;Model ensemble, improve the performance of NN a few percent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Same Model, Different Initializations&lt;/li&gt;
&lt;li&gt;Top models discovered during cross-validation&lt;/li&gt;
&lt;li&gt;Different Checkpoints of a single model: Training is very expensive, taking the different checkpoints of single network and using those to form an ensemble.(Cheap and practice，选取一些好的epoch模型)&lt;/li&gt;
&lt;li&gt;Running averatge of parameters during training(用训练过程模型中的均值，直观来看在碗状徘徊，均值更有利于接近底部)&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Summary&quot;&gt;&lt;a href=&quot;#Summary&quot; class=&quot;headerlink&quot; title=&quot;Summary&quot;&gt;&lt;/a&gt;Summary&lt;/h4&gt;&lt;p&gt;1.针对少量的样本，gradient check很重要，并注意正确的初始化&lt;br&gt;2.the magnitude of updates should be ~1e-3 in first-layer&lt;br&gt;3.推荐用SGD+Nesterov Momentum or Adam&lt;br&gt;4.Decay learning rate over the period of training&lt;br&gt;5.Search good hyperparameters with random search(not grid), stage coarse to fine&lt;br&gt;6.Form model ensembles for extra performance&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;开始新一课之前，先来把上一节的相关阅读材料的知识补充上来。&lt;/p&gt;
&lt;h3 id=&quot;Lecture-5-Notes2-amp-3&quot;&gt;&lt;a href=&quot;#Lecture-5-Notes2-amp-3&quot; class=&quot;headerlink&quot; title=&quot;Lecture 5 N
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="公开课 CNN" scheme="https://csrjtan.github.io/tags/%E5%85%AC%E5%BC%80%E8%AF%BE-CNN/"/>
    
  </entry>
  
  <entry>
    <title>LDI-NAT《Color Demosaicking by Local Directional Interpolation and Nonlocal Adaptive Thresholding》</title>
    <link href="https://csrjtan.github.io/2016/06/07/paper-reading-20160607/"/>
    <id>https://csrjtan.github.io/2016/06/07/paper-reading-20160607/</id>
    <published>2016-06-07T07:51:31.000Z</published>
    <updated>2016-06-07T08:29:38.000Z</updated>
    
    <content type="html">&lt;h4 id=&quot;IDEA&quot;&gt;&lt;a href=&quot;#IDEA&quot; class=&quot;headerlink&quot; title=&quot;IDEA&quot;&gt;&lt;/a&gt;IDEA&lt;/h4&gt;&lt;p&gt;这是张老师11年的文章，效果也是很好的，至今依然不断拿来对比实验。Demosaick的做法还是初始化，然后建立CDM噪声模型，然后根据样本统计拟合出符合样本的实际值。（这个建模思路很耐用，其实还是为了更好的挖掘空域和频域信息的相关性）&lt;/p&gt;
&lt;p&gt;这里用Local Directional Interpolation(LDI)的方法进行复杂的梯度插值初始化，然后比较Non-local Minimize(NLM)的方法和Non-local Adaptive Thresholding（NAT）的方法。这里NLM是指扫描附近满足相似度的Patch，对这些patch进行distance weighted的使用；而NAT基于找到Non-local Similar Patch之后，用这些作为观测样本，在噪声模型里结合SVD、PCA的方法（假定满足Sparse），来进行分解，由于噪声v与x较少相关性，通过设定Adaptive Threshold来提取v的主成分，从而保证拟合的值更准确。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;LDI&quot;&gt;&lt;a href=&quot;#LDI&quot; class=&quot;headerlink&quot; title=&quot;LDI&quot;&gt;&lt;/a&gt;LDI&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI3.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI1.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607LDI2.png&quot; alt=&quot;LDI&quot;&gt;&lt;br&gt;中间还有个$d_gr$的梯度影响因子，这种梯度的插值方法还是比较常见的。如上图，假设插值$R_0$，我们可以利用整块的CFA信息，通过和其它频段的信息如G的差来求出变化的梯度，如$\Delta_n$为$R_0$在北方向的梯度，距离远的影响少的原则，然后得到各个方向的梯度；根据梯度的大小作为权值来加权四方的color difference插值。&lt;/p&gt;
&lt;p&gt;这种方法在Color Demosaicking很常见，早期简单的方法是同一频段下的线性、双线性插值，然后利用其它频段的color difference或者color ratio来有效利用局部空间的信息，一般平滑的区域这个假设更有效，而对于变换剧烈的地方往往处理不好出现artifacts或者超过了采样原理。出现梯度变化最小的插值方法、多方向加权的插值方法等，复杂的空域插值方法、sparse adaptive的抑制噪声的插值方法等等&lt;/p&gt;
&lt;h4 id=&quot;NLM-Non-local-Minimum&quot;&gt;&lt;a href=&quot;#NLM-Non-local-Minimum&quot; class=&quot;headerlink&quot; title=&quot;NLM(Non-local Minimum)&quot;&gt;&lt;/a&gt;NLM(Non-local Minimum)&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607NLM.png&quot; alt=&quot;NLM&quot;&gt;&lt;br&gt;这个方法是要挖掘更多的Non-local信息，所以去寻找一些局部相似的Patch，因为CDM和DNS、SR等图像研究具有相似性，denoise BM3D的成功说明了图像上的Patch往往会具有相似性或者重复出现的，所以用简单的Minimum比较获得Similar Patch,再利用这些信息恢复当前Patch的信息。如这个方法里的distance weighted；也有看过一篇是直接correlated比当前patch高，且梯度更平滑，则直接用Non-local Patch恢复的pixel代替当前pixel等；&lt;/p&gt;
&lt;p&gt;上图就是用L1的patch distance确定similar patch,然后将这些恢复的值进行distance weighted加权。&lt;/p&gt;
&lt;h4 id=&quot;NAT&quot;&gt;&lt;a href=&quot;#NAT&quot; class=&quot;headerlink&quot; title=&quot;NAT&quot;&gt;&lt;/a&gt;NAT&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0607NAT.png&quot; alt=&quot;NLM&quot;&gt;&lt;br&gt;这个在获得Non-local Similar patch之后，利用这些patch作为可靠的观测样本，进行CDM噪声模型的建立，从而采用PCA的方法获得optimal solution。&lt;/p&gt;
&lt;p&gt;这里的矩阵F范数是指矩阵的值绝对值相加再开平方，也就是观测和PCA值的误差尽可能少，而且主成分的个数也尽可能小；（满足sparse的假设）&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;IDEA&quot;&gt;&lt;a href=&quot;#IDEA&quot; class=&quot;headerlink&quot; title=&quot;IDEA&quot;&gt;&lt;/a&gt;IDEA&lt;/h4&gt;&lt;p&gt;这是张老师11年的文章，效果也是很好的，至今依然不断拿来对比实验。Demosaick的做法还是初始化，然后建立CDM噪声模型，然后根据样本统计拟合出符合样本的实际值。（这个建模思路很耐用，其实还是为了更好的挖掘空域和频域信息的相关性）&lt;/p&gt;
&lt;p&gt;这里用Local Directional Interpolation(LDI)的方法进行复杂的梯度插值初始化，然后比较Non-local Minimize(NLM)的方法和Non-local Adaptive Thresholding（NAT）的方法。这里NLM是指扫描附近满足相似度的Patch，对这些patch进行distance weighted的使用；而NAT基于找到Non-local Similar Patch之后，用这些作为观测样本，在噪声模型里结合SVD、PCA的方法（假定满足Sparse），来进行分解，由于噪声v与x较少相关性，通过设定Adaptive Threshold来提取v的主成分，从而保证拟合的值更准确。&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="Paper Demosaick" scheme="https://csrjtan.github.io/tags/Paper-Demosaick/"/>
    
  </entry>
  
  <entry>
    <title>论文阅读《Residual Interpolation for color image demosaicking》</title>
    <link href="https://csrjtan.github.io/2016/06/06/paper-reading-20160606/"/>
    <id>https://csrjtan.github.io/2016/06/06/paper-reading-20160606/</id>
    <published>2016-06-06T12:19:45.000Z</published>
    <updated>2016-06-07T08:29:40.000Z</updated>
    
    <content type="html">&lt;p&gt;首先将东京工业大学新提出的基于Residual difference interpolation的几篇文章扫一遍，这是第一篇，提出residual difference rather than color difference&lt;br&gt;&lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;网站&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;idea&quot;&gt;&lt;a href=&quot;#idea&quot; class=&quot;headerlink&quot; title=&quot;idea&quot;&gt;&lt;/a&gt;idea&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606ri.png&quot; alt=&quot;主要流程&quot;&gt;&lt;br&gt;左边为正常的Demosaicking流程是：先fine-grained地对G通道插值，然后对R通道插值的时候，是根据R-G的谱间具有相似差异性的原理进行，得到delta,在插值过程中得到R图再把delta加上的过程。&lt;br&gt;现在RI提出直接使用G图做差值插值由于变换太过剧烈的地方会造成Artifact,如今用一些处理使得这个G变成G尖，这个G尖的图像满足平滑和准确的特性。如此利用这个谱间相关性的时候误差会更小，出来的效果更好。&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;具体内容&quot;&gt;&lt;a href=&quot;#具体内容&quot; class=&quot;headerlink&quot; title=&quot;具体内容&quot;&gt;&lt;/a&gt;具体内容&lt;/h3&gt;&lt;p&gt;提出了Residual Interpolation基于GBTF的Demosaick初始化,这里用的是GBTF做G通道的初始化插值，然后Guided Filter得到G尖。我们来看看这两个论文。&lt;/p&gt;
&lt;h4 id=&quot;GBTF&quot;&gt;&lt;a href=&quot;#GBTF&quot; class=&quot;headerlink&quot; title=&quot;GBTF&quot;&gt;&lt;/a&gt;GBTF&lt;/h4&gt;&lt;p&gt;喔，这篇文章是基于我老板的DLMMSE文章优化，简要说一下老板的思路：先求出G-R和G-B图像在横竖方向上的differences，然后建立一个噪声估计模型，结合了optimal LMMSE的方法，直接将performance比以前提高了5个dp。（我老板就说那些人全都是瞎搞的。）这里GBTF提了DLMMSE两点缺陷：1.只利用了4-Neighbor的像素 2.将原来的两个方向解耦成四个方向 3.利用了较好的sparse adaptive初始化方法&lt;br&gt;实验的结论比LPA好0.14dB，比DLMMSE好0.64dB（基本上小打小闹的trick）.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606sp.png&quot; alt=&quot;Sparse Adaptive&quot;&gt;&lt;br&gt;在DLMMSE基础上，对G的插值使用了Gradient Weighted Based的方法，对R和B的通道使用了[3]的sparse adaptive interpolation(一定程度可以通道稀疏来抑制噪声，有空看看这篇什么鬼)。&lt;/p&gt;
&lt;h4 id=&quot;MMSE&quot;&gt;&lt;a href=&quot;#MMSE&quot; class=&quot;headerlink&quot; title=&quot;MMSE&quot;&gt;&lt;/a&gt;MMSE&lt;/h4&gt;&lt;p&gt;首先说一下这个优化方法，MMSE指Minimum Mean Square Error。问了一下师兄，懂了不少。&lt;br&gt;这个是一个知道函数形式，拟合参数的模型，y为Ground Truth,$\hat x(y)$ of x is any function of y. Model一个$MSE=tr{E{(\hat x-x)(\hat x=x)^T}}$ 则有$$\hat x_{MMSE}(y) = arg min_{\hat x}MSE$$&lt;br&gt;这个模型假定你知道了x与y的函数形式，用最小化MSE的方法求解函数的具体参数。&lt;/p&gt;
&lt;p&gt;传统的做法是假设函数形式，然后用Monte Carlo或者Gradient Descent去寻找最优解，但这样仍然需要评价指标。所以简单来说，一般用线性的模型可以变成Optimal LMMSE的问题。 $$min_{W,b}MSE \ \  s.t. \hat x = Wy+b$$&lt;br&gt;Optimal b and W is given by: $b = \overline x - W \overline y, W = C_{XY}C_Y^{-1}$ 然后用样本集的统计值来求解。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Minimum_mean_square_error&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;具体查看Wiki&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&quot;DLMMSE&quot;&gt;&lt;a href=&quot;#DLMMSE&quot; class=&quot;headerlink&quot; title=&quot;DLMMSE&quot;&gt;&lt;/a&gt;DLMMSE&lt;/h4&gt;&lt;p&gt;这里老板借鉴了LMMSE即Linear MMSE的方法，来拟合PSD(pirmer signal difference)和LCC1初始化后的Vertical和Horizontal的噪声。这里有点复杂：首先理解了Demosaicking里面的Color Difference原理是利用了局部区域谱间差值为常量，这个协同性原理。然而这个差值为常量的假设并不准确，所以很多人在这个问题上面做文章。我们发现，有时候出现Artifact是因为变化过于剧烈，这里面已经超过了信号的采样原理，所以信息是丢失无法恢复的。我们只能加入一些约束和先验知识来弥补（后面扩展的工作）。所以这个PSD就是Color Difference并不准确，我们来拟合它。这里直接使用一个LCC1作为G通道插值的初始化，然后简单计算V和H方向上的梯度，与PSD相减得到误差$\epsilon$ 。&lt;br&gt;到这里，我们可以建模了，n代表位置，将x代表PSD,y代表我们拟合真正的结果，$\epsilon$就是初始化方法的误差。$$y(n) = x(n) + v(n)$$&lt;/p&gt;
&lt;p&gt;引入MMSE模型来求解拟合真正的x，y为数据观测值，传统MMSE未定形式不好求解，所以使用LMMSE,得到$\hat x = E[x] + \frac{Conv(x,y)}{Var(y)(y-E[y])}$,自然地假设x和v是为locally Gaussian processes,而且经验性地发现demosaicking noise $\epsilon_{g,r}^h$ 和 $\epsilon_{g,r}^v$为zero-mean random process,且uncorrelated with $\Delta_{g,r}$ (经过实验测出的，数值在0~0.08之间)所以可以简化式子为$$\hat x = \mu_x + \frac{\sigma_x^2}{(\sigma_x^2+\sigma_v^2)}(y-\mu_x)$$ 这里不用计算x的后验和真正样本的均值，因为基于上述假设，可以用x的期望代替了。Cov(x,y)用Cov(x)替代了。这样，我们就拟合预测出优化的PSD $\hat x$，用这个来拟合通道之间的信息更有效！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结:&lt;/strong&gt; LMMSE就是提出y和x的线性关系，然后根据最小MSE去根据观测样本的分布来拟合出符合分布的观测值$\hat x$，关键是用数据样本拟合出线性模型的参数，然后新来的样本经过模型得到拟合的值，会比原来观测的值更符合样本分布。（假设观测样本和预测样本是同分布的）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;看了源码&lt;/strong&gt;：可以看到在实现里面，先对图像做了横向和纵向的滤波，然后在8*8的patch里面进行LMMSE的求解拟合的。&lt;/p&gt;
&lt;h4 id=&quot;RI&quot;&gt;&lt;a href=&quot;#RI&quot; class=&quot;headerlink&quot; title=&quot;RI&quot;&gt;&lt;/a&gt;RI&lt;/h4&gt;&lt;p&gt;回到RI，想法也是拟合一个better PSD，只是这里的做法是用一个比较好的初始化方法，GBTF，在这个之上用了何大神的Guided Filter做平滑上采样（文中这么说），然后得到一个比较好的tentative estimate,用这个来拟合channel difference,取得了更好的效果，接下来就看一下这个guided filter和RI延伸出来的Improvement工作。&lt;/p&gt;
&lt;p&gt;RI在IMAX和Kodak的30张Images取得CPSNR 37.92dB&lt;/p&gt;
&lt;p&gt;参考：&lt;br&gt;[1]I. Pekkucuksen and Y. Altunbasak, “Gradient based threshold free color filter array interpolation,” Proc. of IEEE Int. Conf. on Image Processing (ICIP), pp. 137– 140, 2010.&lt;/p&gt;
&lt;p&gt;[2]Zhang, L. and X. Wu (2005). “Color demosaicking via directional linear minimum mean square-error estimation.” Image Processing, IEEE Transactions on 14(12): 2167-2178.&lt;/p&gt;
&lt;p&gt;[3] D. Paliy, V. Katkovnik, R. Bilcu, S. Alenius, and K. Egiazarian, “Spatially adaptive color filter array interpo- lation for noiseless and noisy data,” International Journal of Imaging Systems and Technology, vol. 17, no. 3, pp. 105-122, 2007.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;首先将东京工业大学新提出的基于Residual difference interpolation的几篇文章扫一遍，这是第一篇，提出residual difference rather than color difference&lt;br&gt;&lt;a href=&quot;http://www.ok.ctrl.titech.ac.jp/res/DM/RI.html&quot;&gt;网站&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;idea&quot;&gt;&lt;a href=&quot;#idea&quot; class=&quot;headerlink&quot; title=&quot;idea&quot;&gt;&lt;/a&gt;idea&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/0606ri.png&quot; alt=&quot;主要流程&quot;&gt;&lt;br&gt;左边为正常的Demosaicking流程是：先fine-grained地对G通道插值，然后对R通道插值的时候，是根据R-G的谱间具有相似差异性的原理进行，得到delta,在插值过程中得到R图再把delta加上的过程。&lt;br&gt;现在RI提出直接使用G图做差值插值由于变换太过剧烈的地方会造成Artifact,如今用一些处理使得这个G变成G尖，这个G尖的图像满足平滑和准确的特性。如此利用这个谱间相关性的时候误差会更小，出来的效果更好。&lt;br&gt;
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="paper demosaick" scheme="https://csrjtan.github.io/tags/paper-demosaick/"/>
    
  </entry>
  
</feed>
