<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CSRJTAN</title>
  <subtitle>Keep Moving</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://csrjtan.github.io/"/>
  <updated>2017-04-13T06:42:16.000Z</updated>
  <id>https://csrjtan.github.io/</id>
  
  <author>
    <name>CsrjTan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>精进_2</title>
    <link href="https://csrjtan.github.io/2017/04/13/%E7%B2%BE%E8%BF%9B-2/"/>
    <id>https://csrjtan.github.io/2017/04/13/精进-2/</id>
    <published>2017-04-13T02:14:01.000Z</published>
    <updated>2017-04-13T06:42:16.000Z</updated>
    
    <content type="html">&lt;p&gt;接着上一节读书笔记，讲完时间和选择之后，讨论一下如何全面地选择和执行行动&lt;/p&gt;
&lt;h3 id=&quot;如何选择&quot;&gt;&lt;a href=&quot;#如何选择&quot; class=&quot;headerlink&quot; title=&quot;如何选择&quot;&gt;&lt;/a&gt;如何选择&lt;/h3&gt;&lt;h4 id=&quot;克服选择弱势&quot;&gt;&lt;a href=&quot;#克服选择弱势&quot; class=&quot;headerlink&quot; title=&quot;克服选择弱势&quot;&gt;&lt;/a&gt;克服选择弱势&lt;/h4&gt;&lt;p&gt;精细化：1.重新定义问题 2.因素穷举 3.因素赋权 4.列表比较 （但在主观意识强和牵涉面广的情况下不适用）&lt;/p&gt;
&lt;p&gt;因素穷举在工作选择的例子上：考虑冒险、权威、竞争、创造性、弹性时间、助人、收入、独立、影响他人、智力刺激和领导，户外工作、说服、劳动、声望、公共关注接触、认可度、研究性、季节性、旅行和变动性，以及工作强度、团队氛围、考评制度、晋升空间和工作环境、艺术性等因素&lt;/p&gt;
&lt;h4 id=&quot;人生的构造是可以校正，做出建设性改变&quot;&gt;&lt;a href=&quot;#人生的构造是可以校正，做出建设性改变&quot; class=&quot;headerlink&quot; title=&quot;人生的构造是可以校正，做出建设性改变&quot;&gt;&lt;/a&gt;人生的构造是可以校正，做出建设性改变&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;深刻的经历和体验会被永久地保留下来，成为人生中无法改变的印痕&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Jeannie Suk《我想看到的世界》，反复鼓励年轻人“去发现和追求自己所热爱的东西”，不要只是追寻“某种预设期待的轨迹”。从芭蕾舞-&amp;gt;文学博士-&amp;gt;法学博士&lt;/p&gt;
&lt;p&gt;”规则遵循理论“：人作出决定时，往往基于自己的身份，依循自己身份所应遵守的规则来判断。会产生”我们应该做什么“，而不是”我们想要做什么“；会想”我们只能做什么“，而不是”我们擅长做什么“；会纠结在”我现在已经是谁“，而不是”我未来可以是谁“；&lt;/p&gt;
&lt;p&gt;校正假设、重新选择的过程被称为”建设性的改变“，这并不意味着重头再来，曾经的想法、选择、努力一定会在我们的人生中留下深刻的印记。&lt;/p&gt;
&lt;h4 id=&quot;小节总结&quot;&gt;&lt;a href=&quot;#小节总结&quot; class=&quot;headerlink&quot; title=&quot;小节总结&quot;&gt;&lt;/a&gt;小节总结&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;所谓选择，就是要权衡好本末轻重，清楚自己人生中到底想要什么、追求什么。&lt;/li&gt;
&lt;li&gt;为自己设定更高的目标，就会发现更多更好的选项，做出更加完美的决定。&lt;/li&gt;
&lt;li&gt;过去的经历、习惯和思维惯性，常在完美思考时自动植入”隐含假设“，让我们意识不到更多的”可能选项“&lt;/li&gt;
&lt;li&gt;如果有太多的可选项，应该把选择对象分解为不同的维度，然后对可选项从不同的维度做出评估。&lt;/li&gt;
&lt;li&gt;在做涉及情感、喜好等主观性特别强的选择时，最好的方法是聆听内心的声音。&lt;/li&gt;
&lt;li&gt;不管做了哪个选择，你的某些东西永远不会改变，最终带着你走向目的地的，可能并不是某一个选择，而是那些你不会改变的东西。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;如何行动&quot;&gt;&lt;a href=&quot;#如何行动&quot; class=&quot;headerlink&quot; title=&quot;如何行动&quot;&gt;&lt;/a&gt;如何行动&lt;/h3&gt;&lt;h4 id=&quot;最有效的就是即刻行动&quot;&gt;&lt;a href=&quot;#最有效的就是即刻行动&quot; class=&quot;headerlink&quot; title=&quot;最有效的就是即刻行动&quot;&gt;&lt;/a&gt;最有效的就是即刻行动&lt;/h4&gt;&lt;p&gt;开始并完成一件事，比做好它更重要。只要开始了，就有机会做好，而且会变得越来越容易做好。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;逃避拖延带来的心理成本比去努力做好这一件事更累。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;1.把必须要做的小事要处理掉&lt;br&gt;2.对要做的事情做计划&lt;br&gt;3.实行最小化可行产品 &lt;/p&gt;
&lt;p&gt;产品的定义：1.不是过程，而是结果 2.不是堆积，而是结构性的整合 3.能被别人检验使用的 4.能够独立地产生正向价值和影响的 5.同时它也是一种媒介，传递价值，传递你的才能 &lt;/p&gt;
&lt;p&gt;传统的教育提醒我们”做准备“，然而过多的准备并没有直接”精益创业“来得直接&lt;/p&gt;
&lt;p&gt;在切换任务的同时，也需要注意”转换消耗“带来的损失：在转换时，我们需要承受认知惯性和认知重构的代价&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/read_20170413_01.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;大部分的事情，真正有用和结构性的思考只在其中小部分的复杂问题，当把这些最难的部分解决之后，事情也就完成了大半，其余都是些打扫、完善、铺成的工作，作者把一件事情的思维比喻成三文治，我们做一件事之前，先把最关键的难题想明白了，其余的事情就水到渠成了。&lt;/p&gt;
&lt;h4 id=&quot;前瞻性和总结性&quot;&gt;&lt;a href=&quot;#前瞻性和总结性&quot; class=&quot;headerlink&quot; title=&quot;前瞻性和总结性&quot;&gt;&lt;/a&gt;前瞻性和总结性&lt;/h4&gt;&lt;p&gt;对于即将执行的行动或者已经完成的行动，我们需要及时地进行前瞻性和总结性的分析，这使得我们在行动中不断地反省和进步；&lt;/p&gt;
&lt;p&gt;因为文字和媒体并不能承载和表达所有的知识，一些实践类的知识涵盖过多较深的细节，而这些细节可能并没有办法被抽象地表达出来的；这就需要直接动手，积极反思。&lt;/p&gt;
&lt;p&gt;如何反思？ 从以下的方面思考：1.信息：哪些是关键信息、从哪获得 2.预期：什么造成预期和事实的偏差 3.结果：怎样评价和描述结果 4.进度：什么影响了进度，过快还是过慢 5.工具：哪些有用的工具，如何使其发挥更好功效 6.情绪：我的情绪是什么引发的，如何有意识地调整 7.阻碍：做事过程暴露什么缺点，遇到哪些批评 8.意义：这件事对于我的意义，对于社会的意义&lt;br&gt;反思要主要三个关键：保证及时性、梳理事情的反应链、关注意外现象&lt;/p&gt;
&lt;h4 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;当一件事情，不知道怎么做的时候，就直接开始做。只要开始了第一步，就会有第二、第三步。&lt;/li&gt;
&lt;li&gt;克服”过度准备“的惯性，向前一步，把未完成的事情完成&lt;/li&gt;
&lt;li&gt;乐于接受反面意见，有勇气否定并重新构造自己的产品&lt;/li&gt;
&lt;li&gt;多线程工作，首先需要一段专注不受干扰的时间，完成工作中最核心部分的思考。&lt;/li&gt;
&lt;li&gt;集中处理同质性的工作，可以减少不同质工作间的转换消耗。&lt;/li&gt;
&lt;li&gt;从理论出发不一定能指导实践，只有在实践中通过反思积累的知识才能指导实践&lt;/li&gt;
&lt;li&gt;行动后要及时反思，并梳理这件事情的”反应链“，特别关注其中发生的意外现象&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;小节实践练习&quot;&gt;&lt;a href=&quot;#小节实践练习&quot; class=&quot;headerlink&quot; title=&quot;小节实践练习&quot;&gt;&lt;/a&gt;小节实践练习&lt;/h4&gt;&lt;p&gt;哪些小事，由于拖延而带来更大的负担，请在一个月内立刻完成这些事：1.整理生活和工作环境 2.整理笔记本信息 3.开始去做要事：配置环境，着手写论文，改代码等&lt;/p&gt;
&lt;p&gt;最小化可行产品：编写TIP论文，最核心的部分是：核心结构的编写、CNN-CDM、CNN-JDD的实验比较，完成这个产品可以分为：1.编写框架结构 2.编写文段 3.设计实验 4.制作图表 5.完善各部分， 将成果公布并收集反馈意见，根据建议修正产品&lt;/p&gt;
&lt;p&gt;在行动中反思：最近发生最大的一件事是ICME ORALS的论文，实验在很早就开始了，但人生第一篇论文一直砍不下来，跑了很多对比实验和参数，耗费了大部分的时间，关键的贡献都在其中1~2天内思考并完成了；得到启示：遇到问题要正面思考，不要拖延和回避，并积极请教，有经验的人确实能指导很大；意外：本应该如意的结果却在实验中体验不出来，在科研实验过程要严谨记录、尽量使工作具有连贯性，避免朝三暮四。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;接着上一节读书笔记，讲完时间和选择之后，讨论一下如何全面地选择和执行行动&lt;/p&gt;
&lt;h3 id=&quot;如何选择&quot;&gt;&lt;a href=&quot;#如何选择&quot; class=&quot;headerlink&quot; title=&quot;如何选择&quot;&gt;&lt;/a&gt;如何选择&lt;/h3&gt;&lt;h4 id=&quot;克服选择弱势&quot;&gt;&lt;a hr
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="精进 励志 成长" scheme="https://csrjtan.github.io/tags/%E7%B2%BE%E8%BF%9B-%E5%8A%B1%E5%BF%97-%E6%88%90%E9%95%BF/"/>
    
  </entry>
  
  <entry>
    <title>A Holistic Approach to Cross-Channel Image Noise Modeling and its Application to Image Denoising</title>
    <link href="https://csrjtan.github.io/2017/04/12/paper-reading-20170412/"/>
    <id>https://csrjtan.github.io/2017/04/12/paper-reading-20170412/</id>
    <published>2017-04-12T13:04:11.000Z</published>
    <updated>2017-04-12T13:26:22.000Z</updated>
    
    <content type="html">&lt;p&gt;这是CVPR16的一篇Orals，主要的工作是Argues RGB噪声经过In-camera imaging之后，不再具有channel-independent的特性；提出用多元高斯分布来拟合RGB dependent noise，并提出了一个NN模型来估计Patch based的多元高斯模型的参数&lt;/p&gt;
&lt;h4 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h4&gt;&lt;p&gt;Modelling and analyzing noise in images is a funda-&lt;br&gt;mental task in many computer vision systems. Tradition- ally, noise has been modelled per color channel assum- ing that the color channels are independent. Although the color channels can be considered as mutually independent in camera RAW images, signals from different color chan- nels get mixed during the imaging process inside the cam- era due to gamut mapping, tone-mapping, and compression. We show the influence of the in-camera imaging pipeline on noise and propose a new noise model in the 3D RGB space to accounts for the color channel mix-ups. A data-driven approach for determining the parameters of the new noise model is introduced as well as its application to image de- noising. The experiments show that our noise model rep- resents the noise in regular JPEG images more accurately compared to the previous models and is advantageous in image denoising.&lt;/p&gt;
&lt;h4 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h4&gt;&lt;p&gt;两点贡献：1.提出观察RGB经过camera imaging之后会产生channel dependent的噪声 2.提出3D RGB空间来观察Patch based noise，然后训练MLP模型来预测噪声参数&lt;/p&gt;
&lt;h4 id=&quot;Related-Work&quot;&gt;&lt;a href=&quot;#Related-Work&quot; class=&quot;headerlink&quot; title=&quot;Related Work&quot;&gt;&lt;/a&gt;Related Work&lt;/h4&gt;&lt;p&gt;最早的噪声估计是channel-independent Gaussian model,因为简单而且在camera imaging前，RGB的channel noise确实相关性比较低；后来Foi et al.[Practical poissonian-gaussian noise modeling and fitting for single-image raw-data.]提出了Poisonian-Gaussian Noise；之后Granados结合temporal和spatial noise来重构HDR图片噪声；Hwang et al.提出用Skellam distribution来表示噪声分布；&lt;/p&gt;
&lt;p&gt;最近比较Robust的有Noise Level Function(NLF) [Statistical calibration of ccd imaging process],效果还不错。&lt;/p&gt;
&lt;h4 id=&quot;Methodology&quot;&gt;&lt;a href=&quot;#Methodology&quot; class=&quot;headerlink&quot; title=&quot;Methodology&quot;&gt;&lt;/a&gt;Methodology&lt;/h4&gt;&lt;p&gt;首先，作者列出在camera imaging过程中，导致R/G/B的Skellam分布变化；&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/paper_read_20170412_01.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;该图列出了在camera imaging前后（RAW,JPEG)的channel covariance发生巨大的变化，所以noise变得channel dependent;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/paper_read_20170412_02.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;接着，从QQ-Plot来观察图像块（一般而言，分位图用于识别两个数据集的分布或者看它们是否同属于同一分布),从统计分布直观可得，噪声可以用多元高斯分布来建模估计：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/paper_read_20170412_03.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;Experiments&quot;&gt;&lt;a href=&quot;#Experiments&quot; class=&quot;headerlink&quot; title=&quot;Experiments&quot;&gt;&lt;/a&gt;Experiments&lt;/h4&gt;&lt;p&gt;作者使用MLP来学习估计patch based多元噪声估计模型的参数，Ground Truth数据是通过时域求均值得到的noise-free image。用了L2的Loss function，再在准确的噪声估计基础上，使用BNLM[Bayesian non-local mean filter],效果比原来NBLM和BM3D都好。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这是CVPR16的一篇Orals，主要的工作是Argues RGB噪声经过In-camera imaging之后，不再具有channel-independent的特性；提出用多元高斯分布来拟合RGB dependent noise，并提出了一个NN模型来估计Patch ba
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="paper" scheme="https://csrjtan.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>精进_1</title>
    <link href="https://csrjtan.github.io/2017/04/12/%E7%B2%BE%E8%BF%9B-1/"/>
    <id>https://csrjtan.github.io/2017/04/12/精进-1/</id>
    <published>2017-04-12T05:58:25.000Z</published>
    <updated>2017-04-12T07:33:03.000Z</updated>
    
    <content type="html">&lt;p&gt;再次读到采铜写的《精进：如何成为一个厉害的人》，诚然，每个人都希望自己能够成为一个厉害的人，也希望自己能够精进，获得某种锻炼和技能，这是一本个人心灵成长的书籍。如同任何鸡汤的书一样，理论和知识的理解并不困难，只要用一种轻松或者让人能理解的方式去写出来，但每一件事情的思考到落实却需要许多的毅力来执行；尤其当其成为习惯与持之以恒的行动时，我们才能看到真正的转变，这就需要我们不断地操练和提醒，积极地反馈自我。&lt;/p&gt;
&lt;h3 id=&quot;序言：用勇敢的方式去生活&quot;&gt;&lt;a href=&quot;#序言：用勇敢的方式去生活&quot; class=&quot;headerlink&quot; title=&quot;序言：用勇敢的方式去生活&quot;&gt;&lt;/a&gt;序言：用勇敢的方式去生活&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;生活就像一面多棱镜，它有不止一个镜面，相应地，也有不止一种可观察和理解的视角&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这也透露出生活具有的多元性和丰富性，正是因为这，也才使得人生是那么的丰富多彩，充满了意义。&lt;/p&gt;
&lt;p&gt;本书从人生重要的七个维度展开：时间、选择、行动、学习、思维、才能和成功来论述理想中符合自我的生活和人生。时间是前提与坐标；选择使我们认清自我以及在世界中的位置；行动则是真正生命力的象征，也是解决问题的能力；学习则是一生的修为与锻炼；思考是伟大而有价值的，需要我们来发现其价值与意义；成功的定义应该是坚持做一个你所喜欢的自己；&lt;br&gt;全书追求的一个目标是：思考如何才能获得丰盈、独特、完整和自足的人生，摆脱内心的禁锢，勇敢开阔地去生活。&lt;/p&gt;
&lt;p&gt;我的见解：思考生活和思考人生是一个永无止境的课题，此中是毫无答案却是意义非凡，每一次的思考哲学也是跟“自我”的对话，当然这是一个耗费精力的过程，应该张弛有度。过于频繁一般多因生活的不如意而导致“人生是虚空，没有意义”的消极观点，但其实生活是充满意义的，只是它在你的眼中、你的世界彰显出来的意义不一；有人说人生的意义，自己对于生活、世界的意义一般是在青春期或中年时期才会变得那样的频繁和重要；因为小孩子对未来充满了希望，他们总是希望等待自己的长大来成为希望的人，从不去担忧着生活；而老年人经历了一切回归于生活的时候，他们已经确认自己在世界和人生里面的定位，不会再去思索太多，只需按着自己的步伐享受拥有的生活。&lt;br&gt;我相信每一个人都对自我充满了期待和梦想，只是有些时候我们因为挫败而丢掉了对自己的期许或者一时被遮蔽了梦想，才重新去探索如果实现不了这个事情，我的人生的意义又从何觅起，这是因为自己的自卑、懒惰或者人性的弱点而导致自己缺乏了生命力；希望每一位消极或者抑郁的人都能振作起来，了解到生命本身就是宝贵的，更毋庸说生活带来的意义，我们确实应该郑重地对待生命的宝贵和时间的宝贵。&lt;/p&gt;
&lt;h3 id=&quot;关于时间与选择&quot;&gt;&lt;a href=&quot;#关于时间与选择&quot; class=&quot;headerlink&quot; title=&quot;关于时间与选择&quot;&gt;&lt;/a&gt;关于时间与选择&lt;/h3&gt;&lt;h4 id=&quot;对待时间的态度&quot;&gt;&lt;a href=&quot;#对待时间的态度&quot; class=&quot;headerlink&quot; title=&quot;对待时间的态度&quot;&gt;&lt;/a&gt;对待时间的态度&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;一个人如何对待他的时间，决定了他可以成为什么样的人&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;对待时间应用的态度是：郑重！ 具体来说是，不敷衍、不迟疑、不摇摆，认真地聚焦当下的事情，自觉而专注地投入其中&lt;/p&gt;
&lt;p&gt;斯坦福心理学家Philip Zimbardo从时间视角划分了不同的心态：积极过去（感恩）、消极过去（抑郁）、享乐主义（幸福）、宿命论（消极）、未来视角（积极）；而我们的生活应该在积极过去、享乐主义与未来视角中取得平衡，按着自我的需要和场景切换。&lt;br&gt;为了让自己更好地去做”正确“的事情，我们可以：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让远期未来目标具体化、情景化和使其可实施&lt;/li&gt;
&lt;li&gt;降低”无用行为“的便利性，主动挑战难度&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;合理地利用时间=选择去做”正确“的事情，但由于选择和诱惑的增多，现代人面临选择无能（不容易判断)和执行无能（拖延症），这里作者提出一个守则：少做短半衰期的事情，只要是能积累的长衰期事情就要认真积极地完成。&lt;/p&gt;
&lt;p&gt;e.g. 长半衰期的事情有:积累可信知识、训练实践技能、提升审美品位、构建新的思维模式、建立和维持相互信任关系、寻找并获得稀缺资源、反思和总结个人经历、保持与促进健康、探索独创见解与发明、获得高峰体验等等&lt;/p&gt;
&lt;p&gt;”长半衰期“的”时间之尺“是一个非常好用的评判标准，经历时间洗礼的”经典“含着接近”事物本质“和”生命本质“的东西。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;《反脆弱》的林迪效应：对于会自然消亡的事物生命每增加一天，预期寿命就会缩短一些，就像人类自己。对于不会自然消亡的事物，生命每增加一天，意味着更长的预期剩余寿命。就像经典著作和对别人的影响。&lt;br&gt;作者提出一种好玩的假设，阅读经典就像把历史的杰出人物加为微信好友，畅游在他们的朋友圈中，你能汲取他们的智慧和精华，会发现他们都是个性鲜明有趣的人；这些杰出的人拥有各自的特点，也存在着让他们杰出的共性：每个人都明白自己独特的特点，并能将其在环境中表露和得到发挥，当中的大部分人是不会受朝代和潮流所影响，他们有自己坚守独特的品质，你能从中认识到各有各伟大的地方。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我的见解：这让我不禁觉得历史是一个好东西，以前确实忽视了，只从客观事实和教科书去学习历史其实是很low的，当你从人和思考的角度来看，历史鲜活起来的时候，它变得那样的真实、动人和有趣，而你也正身处在历史的潮流中，你又会成为怎样的历史呢？心中有一把”时间之尺“去衡量自己，衡量生活，衡量东西，这就是当你迷茫是，其中一个重要和不变的标准。这与孔夫子的立德（耶稣、儒家、佛教）、立功、立言（著书)有异曲同工之妙。再说一下效益和半衰期的事情，和牛人固然是效益高、半衰期长的事情，但是这种好事需要我们先重复练习做效益低、半衰期长的事情，积累起来之后，在业内才能碰到这种好事，也就是越努力越幸运，所以我们需要提前做好艰苦打基础的心理准备！&lt;/p&gt;
&lt;h4 id=&quot;快与慢&quot;&gt;&lt;a href=&quot;#快与慢&quot; class=&quot;headerlink&quot; title=&quot;快与慢&quot;&gt;&lt;/a&gt;快与慢&lt;/h4&gt;&lt;p&gt;回归到生活之中，并非简单地一味求快就是最佳，生活应该张弛有度，快慢适宜。简单来说是，工作要快，生活要慢；毕竟人生的第一桩要事是生活，生活应该是享受、体验和培养生机的过程。&lt;/p&gt;
&lt;p&gt;在现代忙碌的生活中，我们可以享受体验的慢事如：坐在公园的长椅观察、夜晚在吊床上看星星、漫无目的地散步、在静寂中看一本书、阳光草坪下小睡片刻、在烛光中洗澡等&lt;/p&gt;
&lt;p&gt;另外，要注意求慢的事情有：与家人共度闲暇、欣赏艺术作品、自我反思、思考重大决策、创造性活动的酝酿、为挑战性任务的准备&lt;/p&gt;
&lt;p&gt;人在爱好上，在闲暇中放松与满足的程度取决于质量而非长度，进入”心流“的专注模式会让人得到更多深度的体验，而相应地在爱好上获得的成就让你更放松和满足。所以从现在开始，请找到并保持至少一项长期的业余爱好吧。&lt;/p&gt;
&lt;h4 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;平衡看待过去、现在和未来，郑重地过好当下，联结过去和未来&lt;/li&gt;
&lt;li&gt;用未来视角工作，用享乐主义生活&lt;/li&gt;
&lt;li&gt;用时间之尺审视事情，尽可能删减不必要的事情&lt;/li&gt;
&lt;li&gt;快慢结合，区分”求快“，”求慢”的事件&lt;/li&gt;
&lt;li&gt;提升时间的深度，减少被动休闲的比例，保持至少一项长期的业余爱好&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;如何行动&quot;&gt;&lt;a href=&quot;#如何行动&quot; class=&quot;headerlink&quot; title=&quot;如何行动&quot;&gt;&lt;/a&gt;如何行动&lt;/h3&gt;&lt;p&gt;成为一个厉害的人，或者精进自我，就需要提出设立高标准的原则，让自己成为高标准的人。&lt;/p&gt;
&lt;p&gt;在学生中，高标准的体现包括：1.选择好的课外在线课程 2.选择优秀的国外教材 3.跟优秀的人进行交流 4.选择有挑战性的竞赛&lt;/p&gt;
&lt;p&gt;我们需要时刻以最高标准为原则，设定价值尺度，从“目标”、”眼界“和”信念“来划分4种人：盲众、逐利者、理念人和至善之人（史怀哲）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;人不能只为他自己而活。我们必须认知所有的生命都是珍贵的，而我们和所有的生命是结合在一起的。这种认知指引了我们心灵和宇宙的关系。 -史怀哲&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一般遇到困难的时候，都是因为隐性假设在阻碍着我们发展，我们可以冷静合理地分析这些隐性假设，寻找突破现状的新可能。&lt;br&gt;中国社会生活中存在的四个典型假设：赛道假设、低关联假设、僵固型心智、零和博弈&lt;/p&gt;
&lt;p&gt;在设立多目标的时候，我们可以尝试目标悬挂，就像国外实行的”开环大学“，让本科学士学位可以在六年内修完，中间与工作和实践结合，更好地学以致用；还有就是能力嫁接，让其他的能力充分发挥，最后进行特性改造，将消费型爱好转化成生产型爱好。&lt;/p&gt;
&lt;h3 id=&quot;课后习题&quot;&gt;&lt;a href=&quot;#课后习题&quot; class=&quot;headerlink&quot; title=&quot;课后习题&quot;&gt;&lt;/a&gt;课后习题&lt;/h3&gt;&lt;p&gt;这里我把自己阅读的课后习题答案稍微写一下（相当于揭短，让内心的黑暗接受阳光的洗礼）：&lt;br&gt;最近自己不好的事情，学到了什么？：1.GRE考试失败，从中明白要好好备考，英语是很重要的，虽然GRE的单词生僻枯燥，但若能熬过这一关也证明了自我。 2.论文拖延症：认识到自己的拖延和懒惰，一味地逃避正确的事情，会让自己越来越痛苦，甚至怀疑自己 3.过度娱乐：由于没有太多的驱赶和压力，自己迷失了自我，忘记了初心；尤其当下的视频媒体各方面做得极具吸引力，在国外YOUTUBE资源多网速好，简直一个不小心休息就连看1小时视频，还有其他电视剧、综艺、电影之类的，视频对大脑的刺激实在来得太剧烈，就算没有多巴胺、尼古丁或者可卡因都能上瘾；对于如此自制力的我，估计这辈子都得远离烟酒毒品什么的！希望自己能少看视频，多读文字，看看书。&lt;/p&gt;
&lt;p&gt;最近的成就，它对人生的意义： 1.之前写了的雅思总结笔记，把自己的经历和书籍分享给别人，感觉自己帮助了别人，也巩固了经验心得，意义非凡！ 2.完成了ICME的投稿，最近出了ORALS的结果，自己的写作和科研上的探索得到了肯定，能将自己学习到的知识和探索的成果传播出去，让自己的自信又多了一点点了！ 3.之前做的这个博客，虽然没有什么访问量，但它就像一本日记一样，记录着我的生命轨迹，我的喜怒哀乐，虽然经常会忘掉它；但我渐渐发现，不是它（我期待的读者）需要我，是我需要它，所以希望自己能坚持更新，更新自己的心情，更新我的学习和成长。&lt;/p&gt;
&lt;p&gt;五年目标：说到底，这个东西每年都写一次，每年都觉得自己并没有离目标更近一点了，这次定一个稍微现实一点，希望能让自己往目标靠得更近一点。 1.找到好的、如意的工作：我希望从事教育和技术结合的工作，我发现自己还是对教育充满了兴趣，可是自己还是没能往前迈出这一步。 2.出一本书，无论是自费还是挣钱，希望自己这一生能留下一点什么，所以自己写作并出版一本书对我来说意义非凡，希望自己能多阅读，多积累！ 3.成家立室，提到这个目标其实有点早，因为本来期待30+才想这个事情，而且这个应该不需要订目标太早吧？还能放进5年计划？这不时机成熟，条件充分，一下子就好了吗？然而现在结婚需要的压力或者时机越来越复杂了，提前一点准备，多挣钱，多看世界，多尝试吧。&lt;/p&gt;
&lt;p&gt;每周让自己放松的事情：运动是最大的爱好！包括跑步、爬山、篮球、骑车和健身；然后就是阅读，要多读经典，多读历史；可以珍惜在香港的时间，多听听讲座、展览、美术&lt;br&gt;长期培养的爱好：1.写博客 2.写书或者小说 3.写代码 4.吉他&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;再次读到采铜写的《精进：如何成为一个厉害的人》，诚然，每个人都希望自己能够成为一个厉害的人，也希望自己能够精进，获得某种锻炼和技能，这是一本个人心灵成长的书籍。如同任何鸡汤的书一样，理论和知识的理解并不困难，只要用一种轻松或者让人能理解的方式去写出来，但每一件事情的思考到落
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="精进 励志 成长" scheme="https://csrjtan.github.io/tags/%E7%B2%BE%E8%BF%9B-%E5%8A%B1%E5%BF%97-%E6%88%90%E9%95%BF/"/>
    
  </entry>
  
  <entry>
    <title>VisualComputing_3</title>
    <link href="https://csrjtan.github.io/2017/04/11/VisualComputing-3/"/>
    <id>https://csrjtan.github.io/2017/04/11/VisualComputing-3/</id>
    <published>2017-04-11T12:43:32.000Z</published>
    <updated>2017-04-12T11:57:59.000Z</updated>
    
    <content type="html">&lt;p&gt;这一节讲解如何用Dictionary learning做Classification Task&lt;/p&gt;
&lt;h3 id=&quot;Sparse-representation-Classificaton&quot;&gt;&lt;a href=&quot;#Sparse-representation-Classificaton&quot; class=&quot;headerlink&quot; title=&quot;Sparse representation Classificaton&quot;&gt;&lt;/a&gt;Sparse representation Classificaton&lt;/h3&gt;&lt;p&gt;Problem Modeling:&lt;br&gt;$label(y) = argmin_k(r_k)$&lt;br&gt;$where\ \ r_k = ||y-X_k \hat{\alpha_k}||_2$&lt;/p&gt;
&lt;p&gt;prons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;novel use sparse coding for classification&lt;/li&gt;
&lt;li&gt;widely studied, improved and extended&lt;/li&gt;
&lt;li&gt;good performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;cons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SRC is owed to use of sparse coding which is not accurate&lt;/li&gt;
&lt;li&gt;new type of classifier although the sparsity is helpful&lt;/li&gt;
&lt;li&gt;不是有效的局部结构性特征&lt;/li&gt;
&lt;li&gt;针对遮挡问题，字典过大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过局部特征（Gabor,SIFT)来解决局部特征，用robust coding可以解决遮挡问题的字典过大。&lt;br&gt;LASSO和L1-LASSO最大的区别是数据保真项$e=y-X\alpha$分别服从i.i.d. Gaussian or Laplacian distribution&lt;/p&gt;
&lt;p&gt;LASSO: $ min_{\alpha} ||y-X\alpha||_2^2 \ \ \ s.t.\ ||\alpha||_1&amp;lt;=\sigma$&lt;/p&gt;
&lt;p&gt;L1-LASSO: $min_{\alpha}||y-X\alpha||_1 \ \ \ s.t.\ ||\alpha||_1&amp;lt;=\sigma$&lt;/p&gt;
&lt;h4 id=&quot;MLE&quot;&gt;&lt;a href=&quot;#MLE&quot; class=&quot;headerlink&quot; title=&quot;MLE&quot;&gt;&lt;/a&gt;MLE&lt;/h4&gt;&lt;p&gt;最大似然估计提供了一种给定观察数据来评估模型参数的方法，“模型已定，参数未知”。一个重要的假设：所有的采样都是独立同分布的。&lt;br&gt;假设$x_1,x_2,…,x_n$为独立同分布采样，$\theta$为模型参数，$f$为模型，则产生上述采样可表示为 $$f(x_1,x_2,…,x_n|\theta)= f(x_1|\theta)*f(x_2|\theta)…,f(x_n|\theta)$$&lt;/p&gt;
&lt;p&gt;似然的定义:$ L(\theta|x_1,…,x_n)=f(x_1,…,x_n|\theta)= f(x_1|\theta)*f(x_2|\theta)…,f(x_n|\theta) $&lt;/p&gt;
&lt;p&gt;最大似然对数: $ \hat{\theta}_{mle} = argmax_{\theta} \ell(\theta|x_1,…,x_n), \ell=\frac{1}{n} lnL$&lt;/p&gt;
&lt;p&gt;最大似然估计的步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;写出似然函数&lt;/li&gt;
&lt;li&gt;对似然函数取对数，并整理&lt;/li&gt;
&lt;li&gt;求导数&lt;/li&gt;
&lt;li&gt;解似然方程&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;MAP&quot;&gt;&lt;a href=&quot;#MAP&quot; class=&quot;headerlink&quot; title=&quot;MAP&quot;&gt;&lt;/a&gt;MAP&lt;/h4&gt;&lt;p&gt;最大后验估计是根据经验数据对难以观察的量的点估计(Point Estimation)，与MLE类似；不同的是，MLE&lt;strong&gt;融入了估计量的先验分布&lt;/strong&gt;在其中，MAP可以看做规则化的MLE。&lt;br&gt;回顾x为采样，$\theta$为模型参数，f为模型，则MLE可以表示为：$$\hat{\theta}_{MLE}(x) = argmax_{\theta} f(x|\theta)$$&lt;/p&gt;
&lt;p&gt;对于MAP，现在假设$\theta$的先验分布为g,通过贝叶斯理论，对于$\theta$的后验分布如下：$$\theta \mapsto f(\theta|x) = \frac{f(x|\theta)g(\theta)}{\int_{\theta} f(x|\theta^{*})g(\theta^{*})d\theta^{*}}$$&lt;/p&gt;
&lt;p&gt;则MAP的目标为：$$\hat{\theta}_{MAP}(x)=argmax_{\theta} f(\theta|x) = argmax_{\theta} f(x|\theta)g(\theta)$$&lt;/p&gt;
&lt;p&gt;可以看出，MAP和MLE最大的区别是MAP加入了模型参数本身的概率分布，或者说MLE的模型参数概率为均匀固定值。&lt;/p&gt;
&lt;h3 id=&quot;Collaborative-nature-of-SRC&quot;&gt;&lt;a href=&quot;#Collaborative-nature-of-SRC&quot; class=&quot;headerlink&quot; title=&quot;Collaborative nature of SRC&quot;&gt;&lt;/a&gt;Collaborative nature of SRC&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_01.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;对于正则项，L1为sparse,L2为Collaborative&lt;/p&gt;
&lt;p&gt;佳哥的CVPR16文章A Probabilistic Collaborative Representation based Approach&lt;br&gt;for Pattern Classification，主要解释为什么SRC/CRC WORK,具有怎样的特性，结合了proCRC的Modeling，构建出这一分类器比传统分类器要较优；寻找一个common point for joint projection;分类问题相当于在分布空间上的映射。&lt;/p&gt;
&lt;h3 id=&quot;Discriminative-Dictionary-Learning-DL&quot;&gt;&lt;a href=&quot;#Discriminative-Dictionary-Learning-DL&quot; class=&quot;headerlink&quot; title=&quot;Discriminative Dictionary Learning(DL)&quot;&gt;&lt;/a&gt;Discriminative Dictionary Learning(DL)&lt;/h3&gt;&lt;p&gt;Motivation:1.学习compacted字典 2.学习discriminative 3.effected&lt;/p&gt;
&lt;h4 id=&quot;Shared-DL&quot;&gt;&lt;a href=&quot;#Shared-DL&quot; class=&quot;headerlink&quot; title=&quot;Shared DL&quot;&gt;&lt;/a&gt;Shared DL&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_02.png&quot; alt=&quot;LC-KSVD&quot;&gt;&lt;br&gt;Label Consistent-KSVD目的：学习一个线性变换A来约束了Sparse Code的Ideal形式,这里Q是预定义的理想编码形式，T是约束系数大小的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_03.png&quot; alt=&quot;LC-KSVD&quot;&gt;&lt;br&gt;首先计算Sparse Code，然后WX的结果就是分类类别结果&lt;/p&gt;
&lt;p&gt;Support Vector Guided DL(SVGDL), idea:自适应地对coding vector进行参数化。有些编码重要，部分编码相对不重要。&lt;/p&gt;
&lt;h4 id=&quot;Class-specific-DL&quot;&gt;&lt;a href=&quot;#Class-specific-DL&quot; class=&quot;headerlink&quot; title=&quot;Class-specific DL&quot;&gt;&lt;/a&gt;Class-specific DL&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_04.png&quot; alt=&quot;DDL&quot;&gt;&lt;br&gt;所谓决策性字典学习就是把负样本也放进学习过程中进行字典训练。&lt;/p&gt;
&lt;p&gt;Fisher DDL exploit both representation residual and coding coefficient,引入使用了Fisher Criterion&lt;/p&gt;
&lt;h4 id=&quot;Dictionary-Pair-Learning&quot;&gt;&lt;a href=&quot;#Dictionary-Pair-Learning&quot; class=&quot;headerlink&quot; title=&quot;Dictionary Pair Learning&quot;&gt;&lt;/a&gt;Dictionary Pair Learning&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_05.png&quot; alt=&quot;DDL&quot;&gt;&lt;br&gt;同一个Sparse Code,但是针对类别适应的字典，有点像多个2分类的SVM.&lt;/p&gt;
&lt;h3 id=&quot;Collaborative-representation-for-image-sets&quot;&gt;&lt;a href=&quot;#Collaborative-representation-for-image-sets&quot; class=&quot;headerlink&quot; title=&quot;Collaborative representation for image sets&quot;&gt;&lt;/a&gt;Collaborative representation for image sets&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_06.png&quot; alt=&quot;ISCR&quot;&gt;&lt;br&gt;将Image Classification扩展到Image Set Classification&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这一节讲解如何用Dictionary learning做Classification Task&lt;/p&gt;
&lt;h3 id=&quot;Sparse-representation-Classificaton&quot;&gt;&lt;a href=&quot;#Sparse-representation-Classifi
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="VisualComputing" scheme="https://csrjtan.github.io/tags/VisualComputing/"/>
    
  </entry>
  
  <entry>
    <title>VisualComputing_2</title>
    <link href="https://csrjtan.github.io/2017/04/08/VisualComputing-2/"/>
    <id>https://csrjtan.github.io/2017/04/08/VisualComputing-2/</id>
    <published>2017-04-08T07:13:57.000Z</published>
    <updated>2017-04-10T03:08:31.000Z</updated>
    
    <content type="html">&lt;p&gt;上一节讲了CV的介绍和Sparse Representation的内容，包括CV的概念、应用和难点；Sparse Representation的formulation, method以及步骤。当然还有为何Sparse Representation can work. 这一节讲一下Dictionary Learning和Representative works&lt;/p&gt;
&lt;h3 id=&quot;Dictionary-Learning&quot;&gt;&lt;a href=&quot;#Dictionary-Learning&quot; class=&quot;headerlink&quot; title=&quot;Dictionary Learning&quot;&gt;&lt;/a&gt;Dictionary Learning&lt;/h3&gt;&lt;h4 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h4&gt;&lt;p&gt;在稀疏编码之前，需要学习一组过完备的字典，从而使得编码向量是稀疏的。以下分为两种字典，Analytical and Learn;&lt;br&gt;Analytical包括DCT bases, Wavelets, Curvelets…; Learn dictionaries from natural images: K-SVD, Coordinate descent, Online dictionary learning;&lt;/p&gt;
&lt;p&gt;为什么需要字典学习？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Over-complete learned dictionary often work better than analytically&lt;/li&gt;
&lt;li&gt;More adaptive to specific task/data&lt;/li&gt;
&lt;li&gt;Less strict constraints on mathematical properties of bases&lt;/li&gt;
&lt;li&gt;More flexible to model data&lt;/li&gt;
&lt;li&gt;Tend to produce sparser solution&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;L0：K-SVD&quot;&gt;&lt;a href=&quot;#L0：K-SVD&quot; class=&quot;headerlink&quot; title=&quot;L0：K-SVD&quot;&gt;&lt;/a&gt;L0：K-SVD&lt;/h4&gt;&lt;p&gt;对于L0稀疏的字典学习，我们可以用K-SVD方法近似求解，其中可以看成是K-MEANS的一种扩展&lt;br&gt;字典学习的问题可以Modeling为：&lt;br&gt;$$min_{D,A}||Y-DA||_F^2 \ \ s.t.\ \ ||a_i||_0 &amp;lt;= T_0$$ 其中i为任意正数，$T_0$为稀疏值&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_01.png&quot; alt=&quot;K-SVD&quot;&gt;&lt;br&gt;如图，对于字典学习：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先是稀疏编码，可以用Matching Pursuit来优化求解；然后用K-SVD方法更新字典。 &lt;/li&gt;
&lt;li&gt;然后将DA进行K次分片叠加得到$DA=\sum_{i=1}^K d_i a_i^T$, 这里便是一个可用词典；剥离第K条，寻找新的d,x来更新该条目&lt;/li&gt;
&lt;li&gt;最后，只抽取非零的a组成新的矩阵$\Omega$作为系数矩阵，对误差能量矩阵作SVD分解，d取U的第一行，x取$\sum V^T$的乘积第一列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;K-SVD的思想：K次分片，使得最后学得的字典over-complete; 选用第K个条目更新，每次只更新一个字典atom(one column in fat matrix); 对剥离后的‘空洞’做K-SVD， $E_k = U \sum V^T$, 新的d,a则取里面能量最大的元素， 这是对误差’空洞’的最佳逼近；只抽取非零系数组成新矩阵更新，有助于保持原来字典的稀疏性；&lt;/p&gt;
&lt;p&gt;对于L1字典，可以对D和A交替学习：当更新D时，这是Quadratic Programming; 当更新A时，这是LASSO Optimization (ADMM); &lt;/p&gt;
&lt;h4 id=&quot;Representative-Work&quot;&gt;&lt;a href=&quot;#Representative-Work&quot; class=&quot;headerlink&quot; title=&quot;Representative Work&quot;&gt;&lt;/a&gt;Representative Work&lt;/h4&gt;&lt;p&gt;Online learning: 考虑新来的样本，直接在原来基础上更新词典的策略以及收敛性&lt;/p&gt;
&lt;p&gt;Multi-scale Dictionary learning: 由于complexity increases exponentially with signal dimension,所以一般用较小的patch size; 而multi-scale可以自适应地融合不同scale字典编码&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_02.png&quot; alt=&quot;Multi-Scale&quot;&gt;&lt;/p&gt;
&lt;p&gt;Double Sparsity: 可以针对高层次稀疏特征或者large patch再进行一次dictionary learning, 基于稀疏编码或着高维编码的再一次稀疏表示；&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_03.png&quot; alt=&quot;Double Sparsity&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;Restoration-Methods&quot;&gt;&lt;a href=&quot;#Restoration-Methods&quot; class=&quot;headerlink&quot; title=&quot;Restoration Methods&quot;&gt;&lt;/a&gt;Restoration Methods&lt;/h3&gt;&lt;p&gt;Filtering-based methods: Isotropic method, Anisotropic method&lt;br&gt;Transformation methods: Motivation, find new representation where signal and noise can be better separated; Wavelet transform&lt;/p&gt;
&lt;h4 id=&quot;K-SVD-denoising&quot;&gt;&lt;a href=&quot;#K-SVD-denoising&quot; class=&quot;headerlink&quot; title=&quot;K-SVD denoising&quot;&gt;&lt;/a&gt;K-SVD denoising&lt;/h4&gt;&lt;p&gt;Basic Idea: 1.train over-complete dictionary 2.adopt trained dictionary to denoise patch in noisy image 3.Utilize the patch to reconstruct&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_04.png&quot; alt=&quot;Modeling&quot;&gt;&lt;br&gt;Limitations: 1.Solving sparse coding not effective enough 2.L0 is not good choice &lt;/p&gt;
&lt;h4 id=&quot;BM3D&quot;&gt;&lt;a href=&quot;#BM3D&quot; class=&quot;headerlink&quot; title=&quot;BM3D&quot;&gt;&lt;/a&gt;BM3D&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_05.png&quot; alt=&quot;BM3D&quot;&gt;&lt;br&gt;BM3D denoising算是业内最为经典的去噪算法了，其中结合了Nonlocal self-similarity和sparsity两个最重要的priors，效果非常不错，速度一般&lt;/p&gt;
&lt;p&gt;步骤：首先通过non-local matching找到一组图片块；组成tensor进行维纳滤波，之后进行阈值抑制（这里相当于稀疏去噪）；最后对新的tensor结合原来的tensor再重复做维纳滤波和阈值抑制；得到去噪patches reconstruct到图像即可&lt;/p&gt;
&lt;p&gt;优缺点：1.有效挖掘了nonlocal similarity和sparsity 2.在DWT（小波)做协同滤波并不能描述复杂的图像结构&lt;/p&gt;
&lt;h4 id=&quot;LSSC&quot;&gt;&lt;a href=&quot;#LSSC&quot; class=&quot;headerlink&quot; title=&quot;LSSC&quot;&gt;&lt;/a&gt;LSSC&lt;/h4&gt;&lt;p&gt;&lt;strong&gt;Group Sparsity&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_06.png&quot; alt=&quot;Group SPARSITY&quot;&gt;&lt;br&gt;与普通的L1 sparsity不同，Marial提出系数矩阵满足group sparsity的L1，2范数；使得同样的patch，在字典下应该具有统一的稀疏编码，保持元组具有相同稀疏的特性；仔细看12范数的表达形式，j是行，i是列，使得系数尽可能在同一行；&lt;/p&gt;
&lt;p&gt;整个流程和BM3D相似，只是在协同滤波和阈值抑制上，改成用group sparsity的字典学习和稀疏编码去噪&lt;/p&gt;
&lt;p&gt;Adaptive Sparse Domain Selection： 由于大的词典使得稀疏编码过程非常耗时，而大的词典对于描述图像局部结构又是很有必要；这个方法提出从大字典中选择一个子集可以提速&lt;/p&gt;
&lt;p&gt;Piece-wise Linear Estimation (PLE), Motivations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sparse representation assumes &lt;strong&gt;Laplacian&lt;/strong&gt; prior on coefficients, lead to nonlinear sparse coding estimator&lt;/li&gt;
&lt;li&gt;Use &lt;strong&gt;Mixture of Gaussians&lt;/strong&gt; to approximate Laplacian&lt;/li&gt;
&lt;li&gt;Select one appropriate Gaussian Prior to reconstruct&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Coupled-Dictionary-Learning&quot;&gt;&lt;a href=&quot;#Coupled-Dictionary-Learning&quot; class=&quot;headerlink&quot; title=&quot;Coupled Dictionary Learning&quot;&gt;&lt;/a&gt;Coupled Dictionary Learning&lt;/h4&gt;&lt;p&gt;Motivations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Used coupled dictionary to model the relationship between degraded image and its corresponding images&lt;/li&gt;
&lt;li&gt;Build the corresponding in sparse domain(same code but different dictionary)&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_07.png&quot; alt=&quot;SRSR&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Semi-coupled Dictionary Learning: flexible the relationship between two dictionary, the sparse code with a pre-learned mapping&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;上一节讲了CV的介绍和Sparse Representation的内容，包括CV的概念、应用和难点；Sparse Representation的formulation, method以及步骤。当然还有为何Sparse Representation can work. 这一节
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="VisualComputing" scheme="https://csrjtan.github.io/tags/VisualComputing/"/>
    
  </entry>
  
  <entry>
    <title>Very Deep Super Resolution</title>
    <link href="https://csrjtan.github.io/2017/04/07/VDSR/"/>
    <id>https://csrjtan.github.io/2017/04/07/VDSR/</id>
    <published>2017-04-07T15:15:59.000Z</published>
    <updated>2017-04-07T15:43:16.000Z</updated>
    
    <content type="html">&lt;p&gt;这一篇是CVPR16 Kim的VDSR，通过VERY DEEP的简单模型，又快又好地解决了SR问题，成为暂时这个问题上的标杆模型。&lt;/p&gt;
&lt;h4 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h4&gt;&lt;p&gt;Our final model uses 20 weight layers. By cascading small filters many times in a deep network structure, contextual infor- mation over large image regions is exploited in an efficient way. With very deep networks, however, convergence speed becomes a critical issue during training. We propose a sim- ple yet effective training procedure. We learn residuals only and use extremely high learning rates (104 times higher than SRCNN [6]) enabled by adjustable gradient clipping.&lt;/p&gt;
&lt;h4 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h4&gt;&lt;p&gt;Single image super-resolution(SISR):upsampling方法，而后neighbor embedding,如今用CNN； SRCNN的limitation: 1.relies on context of small image regions; 2.only works for single scale； VDSR的主要优点有：1.通过small size kernel but very deep, to obtain a large context(receptive region) 2.Convergence very fast by residual-learning and BN high learning rate 3.Multi-Scale Factor,把多个scale的SR融合进一个网络模型 &lt;/p&gt;
&lt;h4 id=&quot;Methodology&quot;&gt;&lt;a href=&quot;#Methodology&quot; class=&quot;headerlink&quot; title=&quot;Methodology&quot;&gt;&lt;/a&gt;Methodology&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/paper_20170407_01.png&quot; alt=&quot;ARCHITECTURE&quot;&gt;&lt;br&gt;20层CONV+BN+RELU，L2 LOSS, HIGH LEARN RATE WITH RESIDUAL LEARNING AND ADJUSTABLE WEIGHT CLIPPING.&lt;/p&gt;
&lt;h4 id=&quot;Experiment&quot;&gt;&lt;a href=&quot;#Experiment&quot; class=&quot;headerlink&quot; title=&quot;Experiment&quot;&gt;&lt;/a&gt;Experiment&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;THE DEEPER THE BETTER ON PSNR/SSIM&lt;/li&gt;
&lt;li&gt;RESIDUAL LEARNING WORKS&lt;/li&gt;
&lt;li&gt;MULTI-SCALE MODEL BETTER THAN SINGLE SCALE ON LARGE SCALE&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;这一篇是CVPR16 Kim的VDSR，通过VERY DEEP的简单模型，又快又好地解决了SR问题，成为暂时这个问题上的标杆模型。&lt;/p&gt;
&lt;h4 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abs
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="paper" scheme="https://csrjtan.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>VisualComputing_1</title>
    <link href="https://csrjtan.github.io/2017/04/07/VisualComputing-1/"/>
    <id>https://csrjtan.github.io/2017/04/07/VisualComputing-1/</id>
    <published>2017-04-07T13:30:44.000Z</published>
    <updated>2017-04-10T06:18:48.000Z</updated>
    
    <content type="html">&lt;p&gt;老板的CV课程，在期末前做一下相关笔记总结&lt;/p&gt;
&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;h4 id=&quot;What-is-vision&quot;&gt;&lt;a href=&quot;#What-is-vision&quot; class=&quot;headerlink&quot; title=&quot;What is vision?&quot;&gt;&lt;/a&gt;What is vision?&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Perceive an integration of image data and prior knowledge in brain&lt;/li&gt;
&lt;li&gt;A field acquiring, processing, analyzing and understanding visual data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Computer Vision &amp;amp; Human Vision?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ill-posed problems&lt;/li&gt;
&lt;li&gt;mathematical models&lt;/li&gt;
&lt;li&gt;discrete vs. continuous&lt;/li&gt;
&lt;li&gt;local vs. global optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;What-kinds-of-Topics&quot;&gt;&lt;a href=&quot;#What-kinds-of-Topics&quot; class=&quot;headerlink&quot; title=&quot;What kinds of Topics?&quot;&gt;&lt;/a&gt;What kinds of Topics?&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_01.png&quot; alt=&quot;相关学科&quot;&gt;&lt;br&gt;Low Level: Image Denoising, Deblurring, Super-Resolution, photo-sketch synthesis, texture synthesis, optical flow, image matching&lt;/p&gt;
&lt;p&gt;Middle Level: image segmentation, motion capture, visual tracking, 3D reconstruction&lt;/p&gt;
&lt;p&gt;High Level: object detection, image understanding, video understanding&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_02.png&quot; alt=&quot;具体应用问题&quot;&gt;&lt;/p&gt;
&lt;p&gt;Related Problems: medical imaging, optical character recognition (OCR), face detection, smile detection, vision-based biometrics, shape capture, automatic driving&lt;/p&gt;
&lt;h4 id=&quot;Why-image-restoration-challenging&quot;&gt;&lt;a href=&quot;#Why-image-restoration-challenging&quot; class=&quot;headerlink&quot; title=&quot;Why image restoration challenging?&quot;&gt;&lt;/a&gt;Why image restoration challenging?&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;Real noise much more complex than additive white Gaussian&lt;/li&gt;
&lt;li&gt;Blur is non-uniform and complex to accurately estimate&lt;/li&gt;
&lt;li&gt;Space of image local structures is huge, inverse problem highly ill-posed&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Sparse-Representation-and-Dictionary-Learning-on-Restoration&quot;&gt;&lt;a href=&quot;#Sparse-Representation-and-Dictionary-Learning-on-Restoration&quot; class=&quot;headerlink&quot; title=&quot;Sparse Representation and Dictionary Learning on Restoration&quot;&gt;&lt;/a&gt;Sparse Representation and Dictionary Learning on Restoration&lt;/h3&gt;&lt;p&gt;Linear system $Ax=b$, if A full rank, $x = A^{-1}b$; if tall matrix(over-determined) than approximate solution by $minimize||Ax-b||_2^2$; if fat matrix(underdetermined), no solution in general and some constraint should be imposed&lt;/p&gt;
&lt;p&gt;假设estimation与observer的最小距离是L0,L1,L2或其他：L0，非凸优化； L1，tightest convex relaxation of L0, 稀疏解; L2有闭合Dense解。具体到一个优化问题的等高线逼近时，各个NORM BALL的图形如下。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_03.png&quot; alt=&quot;各个Norm Ball&quot;&gt;&lt;br&gt;尽管L1能逼近L0，但有时候L1也会出现非稀疏解，数学上已经证明，满足RIP性质的话，用L1近似L0能确保得到稀疏解。RIP又称有限等距性质,直观解释为从A矩阵中的部分列向量与任意向量x的乘积结果收敛在一个环形邻域，如下图&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_04.png&quot; alt=&quot;RIP&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_05.png&quot; alt=&quot;直观解释&quot;&gt;&lt;/p&gt;
&lt;p&gt;图像复原问题&lt;/p&gt;
&lt;h4 id=&quot;Modeling&quot;&gt;&lt;a href=&quot;#Modeling&quot; class=&quot;headerlink&quot; title=&quot;Modeling&quot;&gt;&lt;/a&gt;Modeling&lt;/h4&gt;&lt;p&gt;$y=Hx+v$, H:observation matrix, v:noise&lt;br&gt;Keys to solve ill-posed problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Modeling the degradation process&lt;/li&gt;
&lt;li&gt;Good Prior knowledge about the clean image&lt;/li&gt;
&lt;li&gt;Good objective function for minimization&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中H在denoise是identity matrix; deblurring为blurring matrix; supperresolution是compound matrix of blurring and downsampling matrix; Inpainting是indication matrix of damaged pixels; &lt;/p&gt;
&lt;h4 id=&quot;Methodology&quot;&gt;&lt;a href=&quot;#Methodology&quot; class=&quot;headerlink&quot; title=&quot;Methodology&quot;&gt;&lt;/a&gt;Methodology&lt;/h4&gt;&lt;p&gt;Filter based methods: Gaussian low-pass, PDE-based anisotropic diffusion, Bilateral filtering, Nonlocal means filtering; (local-&amp;gt;non local performance improve greatly)&lt;/p&gt;
&lt;p&gt;Transform based methods: Fourier(‘Global, Orthogonal’), Wavelet(‘local, small’), Ridgelet(‘more redundant’), Dictionary Learning(‘over-complete’)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Represent x over dictionary D, enforcing the new vector be sparse(robust)&lt;/li&gt;
&lt;li&gt;objective model $min_\alpha ||HD\alpha-y||_2^2+\lambda ||\alpha||_1$&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;The-basic-procedure&quot;&gt;&lt;a href=&quot;#The-basic-procedure&quot; class=&quot;headerlink&quot; title=&quot;The basic procedure&quot;&gt;&lt;/a&gt;The basic procedure&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;Partition degraded image into overlapped patches(8*8)&lt;/li&gt;
&lt;li&gt;For each patch, solve the nonlinear L1-norm sparse coding problem:&lt;br&gt;$\hat{\alpha} = argmin_\alpha ||HD\alpha-y||_2^2+\lambda||\alpha||_1$&lt;/li&gt;
&lt;li&gt;Reconstruct each patch by $\hat{x}=D\hat{\alpha}$&lt;/li&gt;
&lt;li&gt;put the reconstructed patch back and average the overlapped pixels&lt;/li&gt;
&lt;li&gt;In practice, the 1~4 can be iterated for several rounds&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;why sparse?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Neuronscience&lt;/li&gt;
&lt;li&gt;Bayersian &lt;/li&gt;
&lt;li&gt;Compressive Sensing&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;How-to-solve&quot;&gt;&lt;a href=&quot;#How-to-solve&quot; class=&quot;headerlink&quot; title=&quot;How to solve?&quot;&gt;&lt;/a&gt;How to solve?&lt;/h4&gt;&lt;p&gt;L0: Greddy search(Matching pursuit, Orthogonal matching pursuit)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MP: 贪婪地选取相关性最大的atoms&lt;/li&gt;
&lt;li&gt;OMP: 正交地，把曾选的atoms的信息均用上，组合出新的投影向量&lt;br&gt;L1: &lt;/li&gt;
&lt;li&gt;Linear programming&lt;/li&gt;
&lt;li&gt;Iteratively reweighted least squares：Trickly weighted L2 to L1&lt;/li&gt;
&lt;li&gt;Proximal gradient descent: Soft-Thresholding with analytic solution&lt;/li&gt;
&lt;li&gt;Augmented Lagrangian methods(Alternating Direction Method of Multipliers, ADMM)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;ADMM&quot;&gt;&lt;a href=&quot;#ADMM&quot; class=&quot;headerlink&quot; title=&quot;ADMM&quot;&gt;&lt;/a&gt;ADMM&lt;/h3&gt;&lt;h4 id=&quot;拉格朗日变换&quot;&gt;&lt;a href=&quot;#拉格朗日变换&quot; class=&quot;headerlink&quot; title=&quot;拉格朗日变换&quot;&gt;&lt;/a&gt;拉格朗日变换&lt;/h4&gt;&lt;p&gt;将Constraint结合拉格朗日乘子放在Objective function里面。&lt;br&gt;e.g $min\ f(x) \ s.t. Ax=b$&lt;br&gt;拉格朗日形式：$L(x,\lambda)=f(x)+\lambda (Ax-b)$&lt;br&gt;对于含有不等式约束的情况，结合KKT条件，$h(x)=0, \lambda&amp;gt;=0, \lambda*g(x)=0, g(x)&amp;lt;=0 $, 其中h是等式约束，g是不等式约束，$\lambda$是不等式乘子&lt;/p&gt;
&lt;p&gt;KKT条件：对于问题 $L(x,\lambda) = f(x)+\lambda g(x)$&lt;br&gt;满足 &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$\Delta_x h(x,\lambda)=0 $&lt;/li&gt;
&lt;li&gt;$\lambda&amp;gt;=0$&lt;/li&gt;
&lt;li&gt;$\lambda *g(x)=0$&lt;/li&gt;
&lt;li&gt;$g(x)&amp;lt;=0$&lt;/li&gt;
&lt;li&gt;$\Delta_{xx} L(x,\lambda)$ is PSD&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;对偶问题&quot;&gt;&lt;a href=&quot;#对偶问题&quot; class=&quot;headerlink&quot; title=&quot;对偶问题&quot;&gt;&lt;/a&gt;对偶问题&lt;/h4&gt;&lt;p&gt;对于原问题$L(x,\lambda)=f(x)+\lambda(Ax-b)$&lt;br&gt;对偶形式为：$g(\lambda)= inf_x(L(x,\lambda)) = -f^*(-A^T\lambda)-b^T\lambda)$,其中inf为确认下界（infimum)&lt;br&gt;对偶问题： $max\  g(\lambda)$&lt;br&gt;对偶上升法： $x^{k+1} = argmin_x L(x,\lambda^k)$&lt;/p&gt;
&lt;p&gt;变量更新：$\lambda^{k+1}=\lambda^k +\alpha^k(Ax^{k+1}-b)$&lt;br&gt;对偶分解法：将目标函数分解成多个子函数 $f(x)=\Sigma_{i=1}^Nf_i(x_i)$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;增广拉格朗日&lt;/strong&gt;，为了增加Dual Ascent的鲁棒性，加入松弛函数&lt;br&gt;$$L_p(x,\lambda)=f(x)+\lambda^T(Ax-b)+(\rho/2)||Ax-b||_2^2$$&lt;/p&gt;
&lt;h4 id=&quot;ADMM-1&quot;&gt;&lt;a href=&quot;#ADMM-1&quot; class=&quot;headerlink&quot; title=&quot;ADMM&quot;&gt;&lt;/a&gt;ADMM&lt;/h4&gt;&lt;p&gt;ADMM旨在将对偶上升可分解性和乘子法上界收敛属性融合在一起的算法；&lt;br&gt;优化问题：$$ min\ f(x)+g(z) \ \ s.t. \ Ax+Bz=c $$&lt;br&gt;得到增广拉格朗日形式：$ L_\rho(x,z,\lambda)=f(x)+g(z)+y^T(Ax+Bz-c)+(\rho/2)||Ax+Bz-c||_2^2 $&lt;/p&gt;
&lt;p&gt;迭代方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$ x^{k+1} = argmin_x L_p (x,z^k,\lambda^k) $&lt;/li&gt;
&lt;li&gt;$ z^{k+1} = argmin_z L_p (x^{k+1},z,\lambda^k) $&lt;/li&gt;
&lt;li&gt;$\lambda^{k+1} = \lambda^k + \rho(Ax^{k+1}+Bz^{k+1}-c) $&lt;br&gt;$\rho &amp;gt;0$,停止准则：对偶残差小于某个极小值$\epsilon$&lt;br&gt;收敛速度：对于一个高的精度要求收敛多次，但可以融合其他算法快速产生高精度&lt;br&gt;对于凸优化问题，KKT条件是对偶问题有相同解的保证。非凸的问题会存在Dual Gap.&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;老板的CV课程，在期末前做一下相关笔记总结&lt;/p&gt;
&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;h4 
    
    </summary>
    
      <category term="Read" scheme="https://csrjtan.github.io/categories/Read/"/>
    
    
      <category term="VisualComputing" scheme="https://csrjtan.github.io/tags/VisualComputing/"/>
    
  </entry>
  
  <entry>
    <title>CDM_Review</title>
    <link href="https://csrjtan.github.io/2017/03/29/CDM-Review/"/>
    <id>https://csrjtan.github.io/2017/03/29/CDM-Review/</id>
    <published>2017-03-29T01:50:05.000Z</published>
    <updated>2017-03-29T04:44:40.000Z</updated>
    
    <content type="html">&lt;p&gt;今天来总结一下Color Demosaicking（CDM）里面的重要论文和方法。希望能囊括AP, AHD, SA, LDI-NAT, DLMMSE, LSSC, GBTF, RI等方法&lt;/p&gt;
&lt;h4 id=&quot;比较旧的：AP-AHD-SA等&quot;&gt;&lt;a href=&quot;#比较旧的：AP-AHD-SA等&quot; class=&quot;headerlink&quot; title=&quot;比较旧的：AP, AHD, SA等&quot;&gt;&lt;/a&gt;比较旧的：AP, AHD, SA等&lt;/h4&gt;&lt;p&gt;AP给出两个图像规律统计假设：1.自然图像在R,G,B通道间有较大的相关性（inter-color correlations) 2.G通道的采样率比R,B高一倍。则G通道的细节信息更丰富。它的方法包括两步：1.用了高低通滤波，然后构建inter-color恢复像素的公式 2.将结果投影到observed和label constrants sets上，进行fine-tune.（这些后来都有更好的方法）&lt;br&gt;Comment: AP这个方法效果已经不佳，但是它统计出来的inter-color correlation很重要&lt;/p&gt;
&lt;p&gt;SA让G和RB通道的像素估计进行一个交替循环地求解，类似于近似逼近的思想。迭代式求解涉及三个问题：1.从何开始（初始化方法） 2.该算法收敛吗（论文用AP的constrains set论证) 3.什么时候结束(更新不再提高，或到一个较少值)&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/SA_1.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;Comment: SA这个方法主要说明了一个Iterative求解CDM问题的可行性，但iterative问题需要说明清楚上述的三个问题。&lt;/p&gt;
&lt;p&gt;AHD这篇文章2005年提出了homogeneity概念，有效结合梯度较小的变化方向进行有效的像素估计，最后结合adaptive中值滤波的方法去除一下artifacts。效果比之前好，而且还快。&lt;/p&gt;
&lt;h4 id=&quot;接下来说一下速度比较慢，效果比较好的：DLMMSE-LDI-NAT-LSSC-Dict-Learning&quot;&gt;&lt;a href=&quot;#接下来说一下速度比较慢，效果比较好的：DLMMSE-LDI-NAT-LSSC-Dict-Learning&quot; class=&quot;headerlink&quot; title=&quot;接下来说一下速度比较慢，效果比较好的：DLMMSE, LDI-NAT, LSSC, Dict Learning&quot;&gt;&lt;/a&gt;接下来说一下速度比较慢，效果比较好的：DLMMSE, LDI-NAT, LSSC, Dict Learning&lt;/h4&gt;&lt;p&gt;DLMMSE: 基于G和R/B通道的primal difference signals是low pass的，提出了基于directional minimum mean square-error estimation的方法，这里用到了horizon和vertical两个方向。先恢复G通道，然后用G恢复R/B通道。&lt;br&gt;论文首先给出统计表，说明GR和GB的相关性比RB的强，所以用G-R和G-B作为通道相关性的信号，然后估计真实值与观察值的误差。为了方便求解，而且假设两个信号demosaick noise是i.i.d gaussian，则LMMSE的公式可以简化为&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/DLMMSE_1.png&quot; alt=&quot;&quot;&gt; 其中x是观察值，mu_x是x的均值，sigma为方差，y为估计值。&lt;/p&gt;
&lt;p&gt;LDI-NAT的方法在之前的博文说过，这里总结一下，相比DLMMSE，LDI-NAT用LDI做一个初始化方法，然后结合non-local similarity的方法，构建矩阵进行SVD去噪，从而达到去马赛克噪声的效果。具体数学部分挺多的，请看原文或者之前博文。&lt;/p&gt;
&lt;p&gt;LSSC是09年提出的nonlocal+dictionary learning的美妙融合，成为了领域的milestone，当时做image restoration是效果最好的。先学字典，然后稀疏编码求解。这个字典的学习是精髓，不同于BM3D直接使用小波字典，这里作者用了L1,2 norm来使得同样的信号尽量获得同样的编码，用group sparsity从而使得字典更紧凑。&lt;/p&gt;
&lt;p&gt;Regularization-based: 由于CDM是一个ill-posed problem,所以一般人们习惯于加入正则项来约束退化模型，从而得到原始的估计信号，这就使得正则项对于整个问题的重要性不言而喻了。这里说一篇《cdm using inter-channel correlation and nonlocal self-similarity》的TIP文章，作者提出了两个重要的term来做CDM restoration问题。首先是TV-term和inter-color channel的结合，在difference map上做tv效果会比单独TV更佳。 然后是nonlocal matrix的low rank constraint，由于高频纹理复杂以及噪声影响，这个nonlocal matrix可能不是低秩的，这里用一个低秩矩阵加上Outliers矩阵来近似，意思是总能来nonlocal matrix附近找到一个低秩矩阵满足低秩，从而将假设放宽了一点。最后优化这两个正则项。（当然这是基于MLRI的初始化之后再做的demosaicking denoise),接下来都是凸优化的数学问题求解了。&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/ISM_1.png&quot; alt=&quot;最后的优化问题&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;最后是又快又好的插值方法：GBTF，-RI-based，-CNN-based&quot;&gt;&lt;a href=&quot;#最后是又快又好的插值方法：GBTF，-RI-based，-CNN-based&quot; class=&quot;headerlink&quot; title=&quot;最后是又快又好的插值方法：GBTF， RI-based， CNN-based&quot;&gt;&lt;/a&gt;最后是又快又好的插值方法：GBTF， RI-based， CNN-based&lt;/h4&gt;&lt;p&gt;GBTF的论文可以理解为更细致的adaptive插值方法，先做一个LCC1的初始化，然后类似Total Variance的方法，构建一个difference map.在这个difference map上面做四个方法的加权插值，最后将这个estimate difference加回初始化图像，得到最终结果。特别地，对于R,B通道，提出用Laplacian filter加权拟合效果更佳。（这也是后来MLRI的思想）&lt;/p&gt;
&lt;p&gt;RI-based methods:&lt;br&gt;&lt;img src=&quot;http://7xl4js.com1.z0.glb.clouddn.com/RI_1.png&quot; alt=&quot;RI流程&quot;&gt;&lt;br&gt;RI是最近比较热门的方法，传统流程是在估计G通道之后，用R-G的difference做R图的恢复估计。现在RI是不直接在R-G difference map上面做，而是让G做引导图像，R做被滤波图像，得到tentative R,我们用tentative R - R 的difference(residual map)做插值恢复。最后作者用residual map和difference map对比一下，说明了residual map的像素梯度变化更缓和，有利于梯度插值，减少了插值误差，所以work.&lt;/p&gt;
&lt;p&gt;之后延伸了MLRI：bilinear interpolation perform better for minimum laplacian energies. 在G和R通道上分别做sparse laplacian filter的卷积操作，其余跟RI一样。我的理解是，做完这个laplacian filter之后，residual image变得更加smooth,所以效果又提升了。&lt;/p&gt;
&lt;p&gt;IRI： 将Iterative和RI结合，交替做G和R/B的恢复&lt;br&gt;ARI: 将MLRI和IRI加权融合，因为有时候MLRI处理不佳，有时候IRI对对于强相关区域处理不佳，所以ADAPTIVELY结合两者，再做加权平均。&lt;/p&gt;
&lt;p&gt;Deep JDD: 将CDM和DNS一起做，它的网络没有用初始化方法，而是rearrange CFA,加入一个噪声参数层，end-to-end train,用了大量的数据，并且用目前的criterion来提取Hard-case建立了复杂库，并用这些库对网络进行fine-tune。最后得到较佳的JDD结果。&lt;br&gt;个人理解：由于没有初始化方法，所以需要大量的数据来学习CDM的初始化，网络需要学习的内容复杂（针对自己的实验，如果没有初始化效果会十分不佳），专注于hard-case的CDM可能会导致平滑区域的CDM效果不佳，其实不太有必要（我没有hard case效果还是不错,这也是它的网络在Kodak上面表现不佳的原因). 其实用CNN做JDD是十分好用的，但目前还存在的问题大概是：1.在处理CDM和DNS的流程上应该如何较佳（张老师认为DNS-&amp;gt;CDM会更好，而目前CFA DNS效果不佳，导致其后的CDM也不太好） 2.如何将CNN-JDD做得更快更好，拟合真实噪声的分布&lt;/p&gt;
&lt;p&gt;CNN-based的CDM，暂时我自己的网络用20层，64的kernel就已经把CDM效果做爆了，甚至比JDD要好。初始化方法是很有必要的，sequence end-to-end效果已经很好了，但这里面G channel细节信息更多error小，R/B channel细节信息较少，所以error大；如何用G CHANNEL来GUIDANCE成为问题。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;今天来总结一下Color Demosaicking（CDM）里面的重要论文和方法。希望能囊括AP, AHD, SA, LDI-NAT, DLMMSE, LSSC, GBTF, RI等方法&lt;/p&gt;
&lt;h4 id=&quot;比较旧的：AP-AHD-SA等&quot;&gt;&lt;a href=&quot;#比较旧的
    
    </summary>
    
      <category term="Tech" scheme="https://csrjtan.github.io/categories/Tech/"/>
    
    
      <category term="reivew CDM" scheme="https://csrjtan.github.io/tags/reivew-CDM/"/>
    
  </entry>
  
  <entry>
    <title>雅思笔记总结</title>
    <link href="https://csrjtan.github.io/2017/03/27/%E9%9B%85%E6%80%9D%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93/"/>
    <id>https://csrjtan.github.io/2017/03/27/雅思笔记总结/</id>
    <published>2017-03-27T09:29:17.000Z</published>
    <updated>2017-03-28T14:49:22.000Z</updated>
    
    <content type="html">&lt;p&gt;还有1小时上Ethics，无聊之际将旧有的笔记本总结一下，然后‘清理’吧&lt;/p&gt;
&lt;h3 id=&quot;阅读真经&quot;&gt;&lt;a href=&quot;#阅读真经&quot; class=&quot;headerlink&quot; title=&quot;阅读真经&quot;&gt;&lt;/a&gt;阅读真经&lt;/h3&gt;&lt;figure class=&quot;highlight ada&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;阅读先看题，定位快寻觅&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;两种题后做，优先细节选&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;同义多替换，单词有灵犀&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;填词有规律，前后找痕迹&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;并列需查重，生词不用疑&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;难度为中等，变幻四种体&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;填表填图题，一见笑眯眯&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;顺藤能摸瓜，按图可索骥&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;答案常集中，原始送分题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;段落选标题，连锁不简单&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;段中找亮点，中心藏后边&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;判断实不难，真假未提及&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;末题少驳斥，首题少NG&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;我有七种意，天下剑桥题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;多选找并列，单选是&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;如遇选标题，末段加大意&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;匹配乱序多，定位找同义&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;段落含信息，小心有NB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;莫夸境界高，无招胜有招&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;三剑已合璧，笑看雅思谜&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;这是刘洪波雅思阅读真经，我感觉当年能阅读7.5这是对我整个雅思考试来说帮助最大的，所以每逢想起雅思就是这段经文了。同学们也要好好“查经”，他总结得特别好。&lt;/p&gt;
&lt;h4 id=&quot;英语语法&quot;&gt;&lt;a href=&quot;#英语语法&quot; class=&quot;headerlink&quot; title=&quot;英语语法&quot;&gt;&lt;/a&gt;英语语法&lt;/h4&gt;&lt;p&gt;这里有语法树的&lt;a href=&quot;http://www.cnblogs.com/memset/archive/2013/03/26/2981778.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;英语语法&lt;/a&gt;。分为词法和语法， 词法包括名词、代词、数词、冠词、动词、介词、连词、形容词、副词；其中动词包括谓语动词和非谓语动词，谓语动词包括情态动词，时态，语态（主动，被动）和虚拟语气，非谓语动词包括不定式，现在/过去分词以及动名词。&lt;/p&gt;
&lt;p&gt;然后是语法，分为一般规则和特殊规则。 一般的包括369，三类句子：简单句，并列句和复合句（定语/状语/名词性从句），六种简单句型，九种句子成分。 特殊规则又包括强调，倒装，语序，主谓一致，引语，平行和比较。&lt;/p&gt;
&lt;h4 id=&quot;丰富写作&quot;&gt;&lt;a href=&quot;#丰富写作&quot; class=&quot;headerlink&quot; title=&quot;丰富写作&quot;&gt;&lt;/a&gt;丰富写作&lt;/h4&gt;&lt;p&gt;句式：句首状语提前，句上植入短语，现在分词和过去分词，强调句，虚拟语气，-ly结尾的副词，主被动交替和平行结构&lt;/p&gt;
&lt;p&gt;连词：因：as, due to, owing to 果：thus, therefore, so, as a result 目的：thus+verbing 举例：for instance, such, this is confirmed by, the example of 对比：while, whereas, by contrast, unlike, one of the main differences between … and .. is 类比：similarly,  like …, 让步：in spite of, although, even if, even though, … as sb./sth. may be/seem … 假设：if…,(then) … 修饰定从： that, who, which, why(reason/reasons)&lt;/p&gt;
&lt;p&gt;限定范围：apart from, as well as, rather than, instead of&lt;br&gt;Admittedly,… .Nevertheless, …&lt;br&gt;e.g. Some experts believe that it is better for children to egin learning a foreign language at primary school rather than secondary school.&lt;/p&gt;
&lt;p&gt;下定义：means that, which means that, which is essentially&lt;/p&gt;
&lt;p&gt;写作常用短语搭配：achieve one’s full potential, work-life balance, acquire knowledge, gain better understand, 坚持做adhere/stick to, hold on, boosting profits, deepen understanding of, combat/address/tackle a problem&lt;/p&gt;
&lt;h4 id=&quot;经典句型&quot;&gt;&lt;a href=&quot;#经典句型&quot; class=&quot;headerlink&quot; title=&quot;经典句型&quot;&gt;&lt;/a&gt;经典句型&lt;/h4&gt;&lt;p&gt;1.According to a recent survey, millions people die each year from dieases linked to smoking&lt;br&gt;2.The last surveys show that quite a few children hae unpleasant association to homework.&lt;br&gt;&lt;a href=&quot;http://3.No&quot; class=&quot;test test-url&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;3.No&lt;/a&gt; invention has received more praise and abuse than Internet&lt;br&gt;4.People seem to fail to take into account the fact that education does not end with graduation.&lt;br&gt;5.An increasing number of people are beginning to realize that education is not complete with graduation.&lt;br&gt;6.When it comes to education, the majority of people believe that education is a lifetime study.&lt;br&gt;7.Many experts pont out that physical exercise contributes directly to a person’s physical fitness.&lt;br&gt;8.Proper measures must be taken to limit the number of foreign tourists and the great efforts should be made to protect local environment and history form the harmful effects of international tourism.&lt;br&gt;9.An increasing number of experts believe that migrants will exert positive effects on construction of city. However, this oppinion is now being questioned by more and more city residents, who complain that the migrants have bought many serious problems like crime and prostitution.&lt;br&gt;10.Many city residents complain that it’s so few buses in their city that they have to spend much more time waiting for a bus, which is usually crowed with a large number of passengers.&lt;br&gt;11.There is no denying the fact that air pollution is an extremely serious problem: the city authorities should take strong measures to deal with it.&lt;br&gt;12.An investigation shows that female workers tend to have a favorable attitude toward retirement.&lt;br&gt;13.A proper part-time job does not occupy students’ too much time. In fact, it is unhealthy for them to spend all of time on their study. As an old saying goes: All work and no play makes Jack a dull boy.&lt;br&gt;14.Any government, which is blind to this point, may pay a heavy price.&lt;br&gt;15.Nowadays, many students always go into raptures at the mere mention of the coming life of high school.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;还有1小时上Ethics，无聊之际将旧有的笔记本总结一下，然后‘清理’吧&lt;/p&gt;
&lt;h3 id=&quot;阅读真经&quot;&gt;&lt;a href=&quot;#阅读真经&quot; class=&quot;headerlink&quot; title=&quot;阅读真经&quot;&gt;&lt;/a&gt;阅读真经&lt;/h3&gt;&lt;figure class=&quot;highlight ada&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;阅读先看题，定位快寻觅&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;两种题后做，优先细节选&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;同义多替换，单词有灵犀&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;填词有规律，前后找痕迹&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;并列需查重，生词不用疑&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;难度为中等，变幻四种体&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;填表填图题，一见笑眯眯&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;顺藤能摸瓜，按图可索骥&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;答案常集中，原始送分题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;段落选标题，连锁不简单&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;段中找亮点，中心藏后边&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;判断实不难，真假未提及&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;末题少驳斥，首题少NG&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;我有七种意，天下剑桥题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;多选找并列，单选是&lt;span class=&quot;literal&quot;&gt;True&lt;/span&gt;题&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;如遇选标题，末段加大意&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;匹配乱序多，定位找同义&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;段落含信息，小心有NB&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;莫夸境界高，无招胜有招&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;三剑已合璧，笑看雅思谜&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="Life" scheme="https://csrjtan.github.io/categories/Life/"/>
    
    
      <category term="IELTS" scheme="https://csrjtan.github.io/tags/IELTS/"/>
    
  </entry>
  
  <entry>
    <title>关于学习方法</title>
    <link href="https://csrjtan.github.io/2017/03/16/%E5%85%B3%E4%BA%8E%E5%AD%A6%E4%B9%A0/"/>
    <id>https://csrjtan.github.io/2017/03/16/关于学习/</id>
    <published>2017-03-16T03:56:26.000Z</published>
    <updated>2017-03-16T05:03:21.000Z</updated>
    
    <content type="html">&lt;p&gt;从WikiHow上面看到的生活经验，其实wikiHow上面的内容和方法论都很好，只是知易行难。&lt;/p&gt;
&lt;h3 id=&quot;如何成为学霸&quot;&gt;&lt;a href=&quot;#如何成为学霸&quot; class=&quot;headerlink&quot; title=&quot;如何成为学霸&quot;&gt;&lt;/a&gt;如何成为学霸&lt;/h3&gt;&lt;h4 id=&quot;保持良好的学习状态&quot;&gt;&lt;a href=&quot;#保持良好的学习状态&quot; class=&quot;headerlink&quot; title=&quot;保持良好的学习状态&quot;&gt;&lt;/a&gt;保持良好的学习状态&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;无论大脑还是身体，都需要保持最高效的状态&lt;/li&gt;
&lt;li&gt;充足的睡眠休息，外加适量的运动，最好是早睡早起&lt;/li&gt;
&lt;li&gt;健康的饮食规律，少吃多油多脂高糖的垃圾食品，多吃健身餐&lt;/li&gt;
&lt;li&gt;多喝水，保持充分的水分才能使得大脑良好地工作&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;找到适合自己的学习方法&quot;&gt;&lt;a href=&quot;#找到适合自己的学习方法&quot; class=&quot;headerlink&quot; title=&quot;找到适合自己的学习方法&quot;&gt;&lt;/a&gt;找到适合自己的学习方法&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;视觉学习者：通过图表、想象来帮助记忆&lt;/li&gt;
&lt;li&gt;听觉学习者：轻音乐帮助记忆，多听课，通过语音学习&lt;/li&gt;
&lt;li&gt;运动学习者：喜欢边学习边做动作，走来走去的，可以尝试橡皮泥&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;认真听讲&quot;&gt;&lt;a href=&quot;#认真听讲&quot; class=&quot;headerlink&quot; title=&quot;认真听讲&quot;&gt;&lt;/a&gt;认真听讲&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;让自己在前排听讲&lt;/li&gt;
&lt;li&gt;积极认真回答问题&lt;/li&gt;
&lt;li&gt;遇到问题与感兴趣的点举手提问&lt;/li&gt;
&lt;li&gt;学习记笔记（后面详述）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;提前认真完成作业&quot;&gt;&lt;a href=&quot;#提前认真完成作业&quot; class=&quot;headerlink&quot; title=&quot;提前认真完成作业&quot;&gt;&lt;/a&gt;提前认真完成作业&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;遇到难题与同学讨论&lt;/li&gt;
&lt;li&gt;可以求助老师与助教&lt;/li&gt;
&lt;li&gt;寻找安静专注的学习环境（图书馆，书房等）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;通过其它方式补充课堂的学习内容&quot;&gt;&lt;a href=&quot;#通过其它方式补充课堂的学习内容&quot; class=&quot;headerlink&quot; title=&quot;通过其它方式补充课堂的学习内容&quot;&gt;&lt;/a&gt;通过其它方式补充课堂的学习内容&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;兴趣是最好的老师，跟随自己的兴趣&lt;/li&gt;
&lt;li&gt;阅读相关的兴趣读物&lt;/li&gt;
&lt;li&gt;寻找该知识的实用性场景，学以致用&lt;/li&gt;
&lt;li&gt;例如在学习英语，可以通过影片纪录片来加强锻炼&lt;/li&gt;
&lt;li&gt;放假期间，适当地进行知识回顾总结，以及预习下一阶段的课程&lt;/li&gt;
&lt;li&gt;在备考时，提早开始复习（难度越大，复习越早）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;学会做人&quot;&gt;&lt;a href=&quot;#学会做人&quot; class=&quot;headerlink&quot; title=&quot;学会做人&quot;&gt;&lt;/a&gt;学会做人&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;懂得在别人做得好的时候，鼓励表扬他人，不要刻薄取笑&lt;/li&gt;
&lt;li&gt;助人为乐，帮助他人解决问题，分享知识，分享学习笔记&lt;/li&gt;
&lt;li&gt;尊重他人，多聆听别人的观点，学会理解&lt;/li&gt;
&lt;li&gt;保持冷静，坚持自我&lt;/li&gt;
&lt;li&gt;培养幽默感，保持学习的热情和积极乐观态度&lt;/li&gt;
&lt;li&gt;做自己，做真正让自己开心充实的事情，与人分享热爱的事情，与能让你成长的人交朋友，不要过分在意他人对你的看法&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;关于记笔记&quot;&gt;&lt;a href=&quot;#关于记笔记&quot; class=&quot;headerlink&quot; title=&quot;关于记笔记&quot;&gt;&lt;/a&gt;关于记笔记&lt;/h3&gt;&lt;p&gt;1.按学科特点，课程形式来记笔记，如讲座要求又快又好&lt;br&gt;2.记住自己的目标，留意你重视的信息，快速接受。如果是写作论文，需要关注论文的大纲，写下主旨性和关键性的想法&lt;br&gt;3.笔记方便思考记忆，加深了解信息，结构化思考知识&lt;br&gt;4.听讲为重，转述要点，学会概述&lt;br&gt;5.记下概念和术语，与正文分开&lt;br&gt;6.学会简写&lt;/p&gt;
&lt;h4 id=&quot;关于读书笔记&quot;&gt;&lt;a href=&quot;#关于读书笔记&quot; class=&quot;headerlink&quot; title=&quot;关于读书笔记&quot;&gt;&lt;/a&gt;关于读书笔记&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;为术语下定义，可以记录页码，帮助回到文中理解&lt;/li&gt;
&lt;li&gt;列出重要概念，帮助简化复杂的内容&lt;/li&gt;
&lt;li&gt;为纲要天上内容，写下学习目的的摄像，看到相关信息并记下页码&lt;/li&gt;
&lt;li&gt;标上不同的颜色，帮助突出重点，组织笔记结构&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;从WikiHow上面看到的生活经验，其实wikiHow上面的内容和方法论都很好，只是知易行难。&lt;/p&gt;
&lt;h3 id=&quot;如何成为学霸&quot;&gt;&lt;a href=&quot;#如何成为学霸&quot; class=&quot;headerlink&quot; title=&quot;如何成为学霸&quot;&gt;&lt;/a&gt;如何成为学霸&lt;/h3&gt;&lt;h
    
    </summary>
    
      <category term="Life" scheme="https://csrjtan.github.io/categories/Life/"/>
    
    
      <category term="高效 学习" scheme="https://csrjtan.github.io/tags/%E9%AB%98%E6%95%88-%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
