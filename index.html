<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  
  <title>CSRJTAN</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  
    <meta name="author" content="CsrjTan">
  
  
  <meta name="description" content="blog csrjtan tanrunj">
<meta property="og:type" content="website">
<meta property="og:title" content="CSRJTAN">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="CSRJTAN">
<meta property="og:description" content="blog csrjtan tanrunj">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CSRJTAN">
<meta name="twitter:description" content="blog csrjtan tanrunj">
  
  
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
  
<script type="text/javascript">

var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?52f23db710086a078740fd3208bbdacc";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();


</script>

</head>

<body>
  <div class="wrapper">
    <header id="header">
  <div class="title">
    <h1><a href="/">CSRJTAN</a></h1>
    <p><a href="/">Keep Moving</a></p>
  </div>
  <nav class="nav">
    <ul>
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/archives">Archives</a></li>
      
        <li><a href="/about">About</a></li>
      
      
    </ul>
    <div class="clearfix"></div>
  </nav>
  <div class="clearfix"></div>
</header>
    <div class="content">




  
    <article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/2015/08/16/paper-research-01/">
  <time datetime="2015-08-16T13:12:12.000Z">
    2015-08-16
  </time>
</a>
    
    
  
    <h1 class="title"><a href="/2015/08/16/paper-research-01/">Paper_Reading 《Rapid Object Detection using a Boosted Cascade of Simple Features》</a></h1>
  

  </header>
  
  <div class="entry">
    
      <p><a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=990517" target="_blank" rel="external">Paper Link</a></p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script></p>
<h3 id="Author:Paul_Viola,Michael_Jones">Author:Paul Viola,Michael Jones</h3><blockquote>
<h3 id="Key_Contributions:">Key Contributions:</h3><h3 id="1-Integral_Image">1.Integral Image</h3><h3 id="2-Learning_algorithm_based_on_AdaBoost">2.Learning algorithm based on AdaBoost</h3><h3 id="3-Combine_Classifiers_in_Cascade">3.Combine Classifiers in Cascade</h3></blockquote>
<h3 id="Methods:">Methods:</h3><ul>
<li><p>Represent and classify images based on simple features rather than pixels directly(operates <strong>faster</strong> and easily encode <strong>ad-hoc</strong> domain knowledge)</p>
</li>
<li><p><strong>Three</strong> kinds of simple features are used in the paper</p>
<ol>
<li>Two-Rectangles features (A and B)</li>
<li>Three-Rectangles features (C)</li>
<li><p>Four-Rectangles features (D)<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/sceneryfeatures.jpg" alt="Three-types-of-Features"></p>
<p>The feature value calculation:<br>$$\sum{pixel\ values\ in\ white}-\sum{pixel\ values\ in\ gray}$$</p>
</li>
</ol>
</li>
<li><p><strong>Contributions 1:Integral Image</strong><br><img src="http://7xl4js.com1.z0.glb.clouddn.com/scenery3.jpg" alt=""><br><img src="http://7xl4js.com1.z0.glb.clouddn.com/scenery1.jpg" alt=""></p>
</li>
<li><p>Contributions 2:Learning Algorithm based on AdaBoost</p>
<blockquote>
<p><strong>The advantages of AdaBoost:</strong><br>1.Used for <strong>feature selection</strong> and <strong>classifier training</strong><br>2.Selecting small set of <strong>good features</strong> from large feature set<br>3.Used a set of <strong>weak learners</strong> to form a strong one<br>4.Guarantees the training error of strong classifier very <strong>low</strong></p>
</blockquote>
<p><strong>The Pesudo of Adaboost:</strong><br><img src="/img/pesudo.png" alt="The pesudo"></p>
</li>
<li><p>Contributions 3:Combine Classifiers in Cascade</p>
<ul>
<li>Building cascade of classifiers(Increase Performance &amp; Reduce computation)</li>
<li>Simpler classifiers apply early to <strong>reject majority</strong> of sub windows and apply complex classifiers to achieve low false positive</li>
<li>Subsequent classifiers are trained using examples,which pass through all the previous stages<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/scenery4.JPG" alt="Cascade Model"></li>
</ul>
</li>
<li><p>How to use</p>
<ol>
<li>User selects maximun FPR(False Prediction Rate) and minimun acceptable DR(Detection Rate) per each stage</li>
<li>User selects target</li>
<li>Each stage is trained by adding features until the target DR and FPRs are met</li>
<li>Stages are added until the overall target for DR and FPR are met</li>
</ol>
</li>
<li><p>Further optimization</p>
<ol>
<li>Number of classifier stages</li>
<li>Number of features in each stage</li>
<li>Threshold of each stage</li>
<li>Minimun number of features that achieved accuracy</li>
</ol>
</li>
<li><p>Conclusion</p>
<ol>
<li>Solution achieves the goal of real time object detection</li>
<li>Conjunction of simple rectangle features and integral image gives a efficient feature representation</li>
<li>AdaBoost is used for the feature selection and classifier training</li>
<li>Cascade of classifiers allows to quickly discard background regions and concentrate more on ojbect-like regions</li>
</ol>
</li>
<li><p>Approximately Performance<br> Accuracy:Front-Face around 68.8%,Profile around 33%<br> Time:every picture with 67 millisecond</p>
</li>
</ul>

    
  </div>
  <footer class="end-sep">
    
      
      
    
    <div class="clearfix"></div>
  </footer>
</article>






  
    <article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/2015/08/16/object-detection-research/">
  <time datetime="2015-08-16T09:42:10.000Z">
    2015-08-16
  </time>
</a>
    
    
  
    <h1 class="title"><a href="/2015/08/16/object-detection-research/">Research_For_UAVs</a></h1>
  

  </header>
  
  <div class="entry">
    
      <pre><code>目的：调研无人机网络项目的相关资料。
TOPICS: Efficient methods for object detection,object recognition and event/scene understanding,
including dangerous objects/events like fire and heavy smoke
要求：2015-8-18下午前，英文整理文档，简要文字加上直观图片说明相关领域内代表性的方法以及最好的方法，包含至少15篇参考文献。
</code></pre><h1 id="OBJECT_DETECTION_&amp;_RECOGNITION">OBJECT DETECTION &amp; RECOGNITION</h1><p> <strong>1.HISTORY&amp;OVERVIEW</strong> <a href="http://www.cs.unc.edu/~lazebnik/spring10/lec16_recognition_intro.pdf" target="_blank" rel="external">[1]</a> <a href="http://www.researchgate.net/publication/257484936_50_Years_of_object_recognition_Directions_forward" target="_blank" rel="external">[2]</a></p>
<ul>
<li><p>Targets:There are about 10,000 to 30,000 visual object categories. Including Scene categorization(city, outdoor), Image-level annotaion(are there people), Object detection(where are the people) and Image parsing(people building).</p>
<p>P.Perona[3] discerns <strong>five levels</strong> of tasks of increasing difficulty in the <strong>recognition problem</strong>:<br>1.Verification: Is a particular item present in an image patch?<br>2.Detection and Localization: Given a complex image, decide if a particular exemplar object is located some-where in this image, and provide accurate location information on this object.<br>3.Classification: Given an image patch, decide which of the multiple possible categories are present in that patch.<br>4.Naming: Given a large complex image (instead of an image patch as in the classification problem) determine the location and labels of the objects present in that image.<br>5.Description: Given a complex image, name all the objects present in the image, and describe the actions and re-lationships of the various objects within the context of this image. As the author indicates, this is also sometimes referred to as scene understanding.</p>
</li>
<li><p>The <strong>components</strong> used in a typical object recognition system:The feature extraction, followed by feature grouping, followed by object hypothesis generation, followed by an object verification stage.But nowadays methods have <strong>blurred</strong> the distinction between the mentioned component.<br><img src="/img/typical_recognition_system.png" alt="Classical Recognition System"></p>
</li>
<li><p><strong>Timeline</strong> of recognition</p>
<ul>
<li>Late 1980s:Alignment,Geometric Primitives</li>
<li>Early 1990s:Invariants,Appearance-based Methods</li>
<li>Mid-late 1990s:Sliding Windows Approaches</li>
<li>Late 1990s:Feature-based Methods</li>
<li>Early 2000s:Parts-and-shape Models</li>
<li>2003-late 2000s:Bags of Features</li>
<li>Present Trends:Machine Learning,Deep Learning,Combination of local and global Methods,Modeling Context,Emphasis on “Image Parsing”<br>(you can see the detail of methods in the <a href="http://www.cs.unc.edu/~lazebnik/spring10/lec16_recognition_intro.pdf" target="_blank" rel="external">Slides</a>)</li>
</ul>
<p><strong>2.Efficient Methods &amp; Relative Papers</strong></p>
</li>
<li><h3 id="Alignment_&amp;_Geometric_Primitives">Alignment &amp; Geometric Primitives</h3><p> <strong>1.Alignment:</strong>Transformation between pairs of features matches in two images<br><img src="/img/alignment.png" alt="Transformation"><br>e.g.《Object Recognition Using Alignment》<a href="http://www.cse.unr.edu/~bebis/CS773C/ObjectRecognition/Papers/Huttenlocher87.pdf" target="_blank" rel="external">[4]</a> based on the assumption and the method that the position, orientation and scale of an object in three-space can be determined from three pairs of corresponding model and image points.</p>
<p> <strong>2.Geometric Primitives:</strong>Decribed model-based system with <strong>Volumn Models</strong><br><img src="/img/geomeric_primitive.png" alt="Volumn Models"><br><img src="/img/geometric.png" alt="Model-Based"><br>e.g.《Symbolic reasoning among 3-D models and 2-D images》<a href="http://www.sciencedirect.com/science/article/pii/000437028190028X" target="_blank" rel="external">[5]</a> Describe <strong>model-based</strong> systems in models,prediction of image features,description of image features and interpretation which relates image features to models.</p>
</li>
<li><h3 id="Invariants_&amp;_Appearance-based">Invariants &amp; Appearance-based</h3><p> <strong>1.Geometric invariants:</strong>Used to probide an efficient indexing mechanism for object recognition system.<br> e.g.《Geometric hashing: an overview》<a href="http://www.computer.org/csdl/mags/cs/1997/04/c4010.pdf" target="_blank" rel="external">[6]</a> Typical deformations discussed in the literature include 2D translations,rotations and scalings.</p>
<p> <strong>Limits</strong>:The above method only suit for <strong>monocular</strong> viewpoint invariants.</p>
<p> <strong>2.Appearance-based:</strong>Including Eigenfaces,Color Histograms and appearance manifolds.<br> e.g.《Face Recognition Using Eigenfaces 》<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=139758" target="_blank" rel="external">[7]</a> treats face recognition as a two-dimensional recognition problem and makes that the face images are projected onto a <strong>feature space</strong> which best encodes the variation among known face images.(<a href="http://blog.csdn.net/feirose/article/details/39552887" target="_blank" rel="external">实现原理</a>)</p>
<p> e.g.《Color Indexing》<a href="http://link.springer.com/article/10.1007/BF00130487" target="_blank" rel="external">[8]</a> demonstrates that <strong>color histograms</strong> of multicolored objects provide a robust,efficient cue for indexing into a large database of models</p>
<p> e.g. 《Visual learning and recognition of 3d objects from appearance》<a href="http://link.springer.com/article/10.1007/BF01421486" target="_blank" rel="external">[9]</a> used the <strong>manifolds</strong> for object detection.<br> <img src="/img/manifold.png" alt="manifold"><br> <strong>Limits</strong>:<br> 1.Require global registration of patterns<br> 2.Not robust to clutter,occlusion,geometric transformations</p>
</li>
<li><h3 id="Sliding_Window_Approaches">Sliding Window Approaches</h3><p> e.g. 《Rapid Object Detection using a Boosted Cascade of Simple Features》<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=990517" target="_blank" rel="external">[10]</a> It is <strong>prominent</strong> and milestone in face detection，more than 11500 citations and widely used solution for the real-time Object Detection.The very detailed of the method can click on <a href="~/2015/08/16/paper-research-01/">this</a> (Strongly Recommend)<br> <strong>Limits</strong>:Can not handle clutter and occlusion well</p>
</li>
<li><h3 id="Feature-based_Methods">Feature-based Methods</h3><p> e.g. 《Distinctive Image Features from Scale-Invariant Keypoints》<a href="http://download.springer.com/static/pdf/941/art%253A10.1023%252FB%253AVISI.0000029664.99615.94.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Farticle%2F10.1023%2FB%3AVISI.0000029664.99615.94&amp;token2=exp=1439832722~acl=%2Fstatic%2Fpdf%2F941%2Fart%25253A10.1023%25252FB%25253AVISI.0000029664.99615.94.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Farticle%252F10.1023%252FB%253AVISI.0000029664.99615.94*~hmac=8324543a7075217178c5cd6bc912ca31a21f7476c9e9c3037381dad9019bc3fb" target="_blank" rel="external">[11]</a> the sift feature by Lowe,object detection via the feature points matching.The keypoints have been shown to be invariant to image rotation and scale and robust across a substantial range of affine distortion,addition of noise, and change in illumination.<br> <img src="/img/sift.png" alt="SIFT Feature"><br> <strong>Limits</strong>:Can not real-time with large computation</p>
</li>
<li><h3 id="Part-based_Methods"><a href="http://cs.nyu.edu/~fergus/teaching/vision_2012/11_parts_models.pdf" target="_blank" rel="external">Part-based Methods</a></h3><p><img src="/img/part_model.png" alt="Part-based Model"></p>
<ul>
<li>Object as a set of parts</li>
<li>Relative locations between parts</li>
<li>Appearance of part<br>e.g. 《Object Detection with Discriminatively Trained Part Based Model》<a href="http://lear.inrialpes.fr/~oneata/reading_group/dpm.pdf" target="_blank" rel="external">[12]</a> use Hog Features,Part Model and Latent SVM to work.<br><img src="/img/object_hypothesis.png" alt="Object hypohesis with component part"><br><img src="/img/dpm.png" alt="Detected with part-based method"></li>
</ul>
</li>
</ul>
<ul>
<li><h3 id="Bag-of-features_Models">Bag-of-features Models</h3><p><img src="/img/bag_of_words.png" alt="Bag of words"><br>e.g. 《Local features and kernels for classification of texture<br>and object categories: A comprehensive study》<a href="http://lear.inrialpes.fr/pubs/2007/ZMLS07/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf" target="_blank" rel="external">[13]</a> achieved very impressive result in the <a href="http://host.robots.ox.ac.uk/pascal/VOC/" target="_blank" rel="external">PASCAL Visual Object Classes Challenge</a></p>
<p><strong>Limits</strong>:Ignore the spatial relationships among the patches</p>
</li>
<li><h3 id="Neural-network_models">Neural-network models</h3><p>e.g. 《ImageNet Classification with Deep Convolutional<br>Neural Networks》<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="external">[14]</a><br><img src="/img/CNN.png" alt="Convolution Neutral Network"></p>
<p>e.g. 《Rich feature hierarchies for accurate object detection and semantic segmentation》<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6909475" target="_blank" rel="external">[15]</a><br><img src="/img/RCNN.png" alt="RCNN,some relevant methods:fast RCNN,faster RCNN,SPP"></p>
</li>
<li><h3 id="Scene/Event_Recognition">Scene/Event Recognition</h3><p><strong>Scene</strong>: 《Modeling the shape of the scene: a holistic representation of the spatial envelope》<a href="http://people.csail.mit.edu/torralba/code/spatialenvelope/" target="_blank" rel="external">[16]</a> performs good at scene recognition.<br><strong>Event</strong>: 《Video-based event recognition:activity representation and probabilistic recognition methods》<a href="http://ac.els-cdn.com/S1077314204000712/1-s2.0-S1077314204000712-main.pdf?_tid=bf1117ce-4572-11e5-9fbb-00000aab0f27&amp;acdnat=1439879663_064adeae1298edd050e4715f458da8cb" target="_blank" rel="external">[17]</a><br><img src="/img/event_recog.png" alt="Event Recognition System"></p>
</li>
</ul>
<p> <strong>3.Applications for nowadays</strong></p>
<p>  <img src="/img/word_recog.png" alt="Reading license plates,zip codes,checks "></p>
<p>  <img src="/img/finger_recog.png" alt="Fingerprint recognition"></p>
<p>  <img src="/img/face_recog.jpeg" alt="Face detection"></p>
<p>  <img src="/img/cover_recog.png" alt="Recognition of flat textured objects(Covers)"></p>
<p><strong>4.References</strong><br>[1] Fei-Fei Li, Rob Fergus, Antonio Torralba, and Jean Ponce. “Object Recognition:History and Overview.” CS.UNC.EDU , 2011<br>[2] Andreopoulos, Alexander, and John K. Tsotsos. “50 Years of object recognition: Directions forward.” Computer Vision and Image Understanding 117.8 (2013): 827-891.<br>[3] P. Perona, “Object Categorization: Computer and Human Perspectives, chap.” Visual Recognition circa 2008, Cambridge University Press,<br>55–68, 2009.<br>[4] Huttenlocher, Daniel P., and Shimon Ullman. “Object recognition using alignment.” Proc. ICCV. Vol. 87. 1987.<br>[5] Brooks, Rodney A. “Symbolic reasoning among 3-D models and 2-D images.” Artificial intelligence 17.1 (1981): 285-348.<br>[6] Wolfson, Haim J., and Isidore Rigoutsos. “Geometric hashing: An overview.” Computing in Science &amp; Engineering 4 (1997): 10-21.<br>[7] Turk, Matthew, and Alex P. Pentland. “Face recognition using eigenfaces.” Computer Vision and Pattern Recognition, 1991. Proceedings CVPR’91., IEEE Computer Society Conference on. IEEE, 1991.<br>[8] Swain, Michael J., and Dana H. Ballard. “Color indexing.” International journal of computer vision 7.1 (1991): 11-32.<br>[9] Murase, Hiroshi, and Shree K. Nayar. “Visual learning and recognition of 3-D objects from appearance.” International journal of computer vision 14.1 (1995): 5-24.<br>[10] Viola, Paul, and Michael Jones. “Rapid object detection using a boosted cascade of simple features.” Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on. Vol. 1. IEEE, 2001.<br>[11] Lowe, David G. “Distinctive image features from scale-invariant keypoints.” International journal of computer vision 60.2 (2004): 91-110.<br>[12] Felzenszwalb, Pedro F., et al. “Object detection with discriminatively trained part-based models.” Pattern Analysis and Machine Intelligence, IEEE Transactions on 32.9 (2010): 1627-1645.<br>[13] Zhang, Jianguo, et al. “Local features and kernels for classification of texture and object categories: A comprehensive study.” International journal of computer vision 73.2 (2007): 213-238.<br>[14] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. “Imagenet classification with deep convolutional neural networks.” Advances in neural information processing systems. 2012.<br>[15] Girshick, Ross, et al. “Rich feature hierarchies for accurate object detection and semantic segmentation.” Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. IEEE, 2014.<br>[16] Oliva, Aude, and Antonio Torralba. “Modeling the shape of the scene: A holistic representation of the spatial envelope.” International journal of computer vision 42.3 (2001): 145-175.<br>[17] Hongeng, Somboon, Ram Nevatia, and Francois Bremond. “Video-based event recognition: activity representation and probabilistic recognition methods.” Computer Vision and Image Understanding 96.2 (2004): 129-162.</p>

    
  </div>
  <footer class="end-sep">
    
      
      
    
    <div class="clearfix"></div>
  </footer>
</article>






  
    <article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/2015/08/16/paper-reading-20150816/">
  <time datetime="2015-08-16T07:26:29.000Z">
    2015-08-16
  </time>
</a>
    
    
  
    <h1 class="title"><a href="/2015/08/16/paper-reading-20150816/">论文阅读《Enhanced Computer Vision with Microsoft Kinect Sensor:A Review》</a></h1>
  

  </header>
  
  <div class="entry">
    
      <p>作者：Jungong Han,Ling Shao</p>
<h3 id="这个论文主要简介一些基于Kinect的计算机视觉算法和应用，涵盖了包括深度信息的预处理，Kinect的精确标定；物体跟踪和识别；人类活动分析和手势分析以及室内3D匹配。">这个论文主要简介一些基于Kinect的计算机视觉算法和应用，涵盖了包括深度信息的预处理，Kinect的精确标定；物体跟踪和识别；人类活动分析和手势分析以及室内3D匹配。</h3>
    
  </div>
  <footer class="end-sep">
    
      
      
    
    <div class="clearfix"></div>
  </footer>
</article>






  
    <article class="post">
  <header>
    
      <div class="icon"></div>
      <a href="/2015/08/12/birth/">
  <time datetime="2015-08-12T12:15:30.000Z">
    2015-08-12
  </time>
</a>
    
    
  
    <h1 class="title"><a href="/2015/08/12/birth/">写在23岁生日前夕</a></h1>
  

  </header>
  
  <div class="entry">
    
      <blockquote>
<p>祝渐行渐远的自己，生日安好</p>
</blockquote>
<h3 id="&nbsp;&nbsp;&nbsp;&nbsp;成长一岁，对自己要有新的要求，不想公众写太多生活，建立这个博客希望可以帮助自己总结学习，在工作和学习的路上踏踏实实。">&nbsp;&nbsp;&nbsp;&nbsp;成长一岁，对自己要有新的要求，不想公众写太多生活，建立这个博客希望可以帮助自己总结学习，在工作和学习的路上踏踏实实。</h3><h2 id="新的一岁，新的要求：">新的一岁，新的要求：</h2><ul>
<li>工作上，学术和编程能力的提升</li>
<li>生活上，爱家人，爱生活，爱伴侣</li>
<li>坚持读，坚持学，坚持写，坚持</li>
</ul>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">  &#12298;&#25104;&#38271;&#30340;&#22825;&#31354;&#12299;&#10;&#25105;&#27785;&#28024;&#22312;&#33258;&#24049;&#30340;&#19990;&#30028;&#37324;&#10;&#20889;&#30528;&#26080;&#20851;&#26159;&#38750;&#30340;&#27468;&#35875;&#10;&#28857;&#34013;&#30340;&#31508;&#35302;&#10;&#21010;&#36807;&#20102;&#24180;&#36731;&#30340;&#22825;&#31354;&#10;&#19968;&#21482;&#39134;&#40479;&#24102;&#36208;&#25105;&#30340;&#38738;&#26149;&#10;&#36824;&#25105;&#65292;&#23681;&#26376;&#27785;&#28096;&#30340;&#24125;&#23376;&#10;&#36731;&#22768;&#35828;&#36947;&#10;&#24180;&#36731;&#24635;&#19981;&#26159;&#27704;&#36828;&#30340;&#20511;&#21475;</span><br></pre></td></tr></table></figure>
<p><img src="/img/birth_cake.png" alt="cake"></p>

    
  </div>
  <footer class="end-sep">
    
      
      
    
    <div class="clearfix"></div>
  </footer>
</article>






  

  <nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav>

</div>
  </div>
  <footer id="footer">

<div class="copyright">
  
  &copy; 2015 <a href="/">CsrjTan</a>
  
</div>
<div class="theme-copyright">
  Theme by <a href="https://github.com/orderedlist" target="_blank">orderedlist</a>
   | 
  Redesign by <a href="http://heroicyang.com/" target="_blank">Heroic Yang</a>
</div>
<div class="clearfix"></div>

<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>
        
</footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8/jquery.min.js"></script>
<script src="/js/scale.fix.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
  var disqus_shortname = 'blog2csrjtan';

  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  }());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
  (function($){
    $('.fancybox').fancybox();
  })(jQuery);
</script>

</body>
</html>