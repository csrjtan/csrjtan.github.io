<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="CSRJTAN" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="blog csrjtan tanrunj">
<meta property="og:type" content="website">
<meta property="og:title" content="CSRJTAN">
<meta property="og:url" content="https://csrjtan.github.io/index.html">
<meta property="og:site_name" content="CSRJTAN">
<meta property="og:description" content="blog csrjtan tanrunj">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CSRJTAN">
<meta name="twitter:description" content="blog csrjtan tanrunj">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '我是博主'
    }
  };
</script>

  <title> CSRJTAN </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">CSRJTAN</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">Keep Moving</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tech">
          <a href="/categories/Tech" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-gavel"></i> <br />
            
            技术
          </a>
        </li>
      
        
        <li class="menu-item menu-item-read">
          <a href="/categories/Read" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-pencil"></i> <br />
            
            笔记
          </a>
        </li>
      
        
        <li class="menu-item menu-item-life">
          <a href="/categories/Life" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            生活
          </a>
        </li>
      
        
        <li class="menu-item menu-item-books">
          <a href="/2016/06/01/books/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-book"></i> <br />
            
            书单
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/15/paper-reading-20170415/" itemprop="url">
                  Convolutional Neural Pyramid for Image Processing
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-15T18:07:12+08:00" content="2017-04-15">
              2017-04-15
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/15/paper-reading-20170415/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/15/paper-reading-20170415/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Jia jiaya组xiaoyong shen的CVPR17文章，主要通过金字塔卷积的方式来快速增加可视野；区别于传统的通过大kernel和增加层数的方法，这样增加可视野可以不至于导致大量的参数和运算的引入。</p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>我们提出重要的卷积神经金字塔的框架用于low-level的vision和图像处理问题。重要发现表明，很多应用挖掘结构性信息需要大的感受野；而单纯堆叠卷积层或者用大的卷积核会带来计算量的巨大消耗。我们的金字塔结构可以快速增大感受野而不牺牲运算有效性。额外的增益包括了自适应金字塔深度和步骤性上采样使得对于VGA-SIZE的图像做到实时。这种方法可以应用于一系列的应用包括深度图恢复、图像补全和去噪、边缘增强等。</p>
<h4 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/paper_20170415_01.png" alt=""><br>这个金字塔结构主要包括特征提取、匹配映射和重建三个基本步骤，特征提取还是正常的卷积，在L0时不能使用任何pooling相关的操作（会丢失信息）;下采样的操作可以使用步长为2的卷积或者max pooling,发现max pooling较好；匹配过程的输出都是56 kernel的feature map方便之后重建，另外level越大，feature map size越小，增加的运算量也小，使得depth adaptive；上采样直接使用了deconvolution layer；重建的时候可以使用pixel-wise sum或者concatenate,发现用sum较好；最后加两层卷积来生成对应数量通道的desire output.</p>
<h4 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h4><p>比较了不同深度的金字塔结构带来的运算和效果，5 level可以达到511*511的感受野，这是指数上升的，但内存和运算量都是越深增加得越慢，而且证明只使用一层金字塔结构就可以达到很不错的效果了。</p>
<p>至于网络的损失函数在使用像素L2同时，也使用了梯度图像的L2，前者确保PSNR，后者确保图像足够sharp。</p>
<p>总结：这个论文结合了传统的multi-scale或者金字塔的多尺度，这些都是肯定可用有效的结构信息，所以不难想到能提高，主要前几层下采样的feature map开销还是有的；相当来说把很深很瘦的网络，拉宽变浅，也变得更紧致了。<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/paper_20170415_02.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/13/VisualComputing-4/" itemprop="url">
                  VisualComputing_4
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-13T20:44:23+08:00" content="2017-04-13">
              2017-04-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Read/" itemprop="url" rel="index">
                    <span itemprop="name">Read</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/13/VisualComputing-4/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/13/VisualComputing-4/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天记录一下第六节课程，主要是LOW RANK的技术</p>
<h3 id="LOW-RANK-MINIMIZATION"><a href="#LOW-RANK-MINIMIZATION" class="headerlink" title="LOW RANK MINIMIZATION"></a>LOW RANK MINIMIZATION</h3><p>低秩分解（Low-rank Matrix Factorization)<br>Motivation: Visual Data often has an intrinsic low-rank structure<br>例如：FACE IMAGES, SURVEILLANCE VIDEO, MULTISPECTRAL IMAGE,这些数据都是高度冗余的(highly redundancy)，所以我们可以使用LOW RANK技术来降维，甚至数据复原和分类等</p>
<p>$$Y = X + E$$<br>Y是数据样本拉成向量后，堆叠成为的矩阵；X是隐含的低秩结构矩阵；E是Residual Matrix</p>
<p>我们可以这样建模低秩矩阵X，$X \in R^{d*r}$,d为数据的维度，n为样本的数量；构建Basis Matrix $U \in R^{d*r}$，其中$r&lt;&lt;d,n$,这是矩阵的秩;系数矩阵$V \in R^{n*r}$;<br>$X = U * V^T$, $Y = UV^T+E$</p>
<p>如何构建近似的低秩矩阵，如何估计E？</p>
<ul>
<li>最佳近似估计，依赖于对residual(noise)的分布估计：1.iid GAUSSIAN； 2.iid LAPLACIAN 3.MIXTURE OF GAUSSIAN 4.MORE COMPLEX NOISE</li>
</ul>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_01.png" alt="L2-LRMF"><br>根据MLE得到L2的保真项其实就是对应”误差分布为独立同分布的高斯模型“的假设</p>
<p>其中对于X的分解可以直接用SVD：$X = USV^T$</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_02.png" alt="L1-LRMF"><br>同理，L1的LRMF对应”误差分布为独立同分布的拉普拉斯模型“的假设</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_03.png" alt="L1-L2 LRMF"><br>L1的模型具有长尾效应，更适应于outliers和heavy noises的情况。</p>
<p>第三种是之前两种的混合噪声模型：$Y=UV^T+E+N$，一般使用variational bayes方法来求解此类问题。</p>
<p>最后是复杂噪声模型：Mog-LRMF(ICCV-2013), DP-GMM(CVPR,2015), MoEP-LRMF(ICCV,2015; TIP,2016)</p>
<h4 id="LRMF-with-missing-elements"><a href="#LRMF-with-missing-elements" class="headerlink" title="LRMF with missing elements"></a>LRMF with missing elements</h4><p>Y可以是不完整矩阵，可以引入一个二元矩阵W：<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_04.png" alt="Missing Element LRMF"></p>
<p>对于F-norm的做法：<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_05.png" alt="F-NORM LRMF"></p>
<p>对于L1-norm的做法：<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_06.png" alt="L1-NORM LRMF"></p>
<p>优缺点：</p>
<ul>
<li>矩阵的阶需要预定义</li>
<li>清晰地表达子空间和系数关系</li>
<li>容易嵌入对子空间的先验</li>
<li>不是凸优化问题</li>
</ul>
<h3 id="Weighted-Nuclear-Norm-Minimization-WNNM"><a href="#Weighted-Nuclear-Norm-Minimization-WNNM" class="headerlink" title="Weighted Nuclear Norm Minimization(WNNM)"></a>Weighted Nuclear Norm Minimization(WNNM)</h3><p>针对矩阵的秩的正则化$Rank(X) = \Sigma||\sigma_i(X)||_0$</p>
<p>核范数Nuclear Norm: $||X||_* = \Sigma||\sigma_i(X)||_1$</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_07.png" alt="Nuclear-NORM Minimization"><br>优点：</p>
<ul>
<li>Tightest Convex Envelop of rank minimization</li>
<li>Closed form solution<br>缺点：</li>
<li>对于所有的奇异值给以同样的权值，忽略了它们间不同的权值作用</li>
</ul>
<p>WNNM就是对此Formulation里面的奇异值作加权，但如此一来WNNM是非凸，sub-gradient方法不能用来分析它的优化过程。</p>
<p>以下的定理和引理确保了WNNM的优化可行性。<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_08.png" alt="Optimization"><br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170415_09.png" alt="Corollary"></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/13/精进-2/" itemprop="url">
                  精进_2
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-13T10:14:01+08:00" content="2017-04-13">
              2017-04-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Read/" itemprop="url" rel="index">
                    <span itemprop="name">Read</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/13/精进-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/13/精进-2/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>接着上一节读书笔记，讲完时间和选择之后，讨论一下如何全面地选择和执行行动</p>
<h3 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h3><h4 id="克服选择弱势"><a href="#克服选择弱势" class="headerlink" title="克服选择弱势"></a>克服选择弱势</h4><p>精细化：1.重新定义问题 2.因素穷举 3.因素赋权 4.列表比较 （但在主观意识强和牵涉面广的情况下不适用）</p>
<p>因素穷举在工作选择的例子上：考虑冒险、权威、竞争、创造性、弹性时间、助人、收入、独立、影响他人、智力刺激和领导，户外工作、说服、劳动、声望、公共关注接触、认可度、研究性、季节性、旅行和变动性，以及工作强度、团队氛围、考评制度、晋升空间和工作环境、艺术性等因素</p>
<h4 id="人生的构造是可以校正，做出建设性改变"><a href="#人生的构造是可以校正，做出建设性改变" class="headerlink" title="人生的构造是可以校正，做出建设性改变"></a>人生的构造是可以校正，做出建设性改变</h4><blockquote>
<p>深刻的经历和体验会被永久地保留下来，成为人生中无法改变的印痕</p>
</blockquote>
<p>Jeannie Suk《我想看到的世界》，反复鼓励年轻人“去发现和追求自己所热爱的东西”，不要只是追寻“某种预设期待的轨迹”。从芭蕾舞-&gt;文学博士-&gt;法学博士</p>
<p>”规则遵循理论“：人作出决定时，往往基于自己的身份，依循自己身份所应遵守的规则来判断。会产生”我们应该做什么“，而不是”我们想要做什么“；会想”我们只能做什么“，而不是”我们擅长做什么“；会纠结在”我现在已经是谁“，而不是”我未来可以是谁“；</p>
<p>校正假设、重新选择的过程被称为”建设性的改变“，这并不意味着重头再来，曾经的想法、选择、努力一定会在我们的人生中留下深刻的印记。</p>
<h4 id="小节总结"><a href="#小节总结" class="headerlink" title="小节总结"></a>小节总结</h4><ul>
<li>所谓选择，就是要权衡好本末轻重，清楚自己人生中到底想要什么、追求什么。</li>
<li>为自己设定更高的目标，就会发现更多更好的选项，做出更加完美的决定。</li>
<li>过去的经历、习惯和思维惯性，常在完美思考时自动植入”隐含假设“，让我们意识不到更多的”可能选项“</li>
<li>如果有太多的可选项，应该把选择对象分解为不同的维度，然后对可选项从不同的维度做出评估。</li>
<li>在做涉及情感、喜好等主观性特别强的选择时，最好的方法是聆听内心的声音。</li>
<li>不管做了哪个选择，你的某些东西永远不会改变，最终带着你走向目的地的，可能并不是某一个选择，而是那些你不会改变的东西。</li>
</ul>
<h3 id="如何行动"><a href="#如何行动" class="headerlink" title="如何行动"></a>如何行动</h3><h4 id="最有效的就是即刻行动"><a href="#最有效的就是即刻行动" class="headerlink" title="最有效的就是即刻行动"></a>最有效的就是即刻行动</h4><p>开始并完成一件事，比做好它更重要。只要开始了，就有机会做好，而且会变得越来越容易做好。</p>
<blockquote>
<p>逃避拖延带来的心理成本比去努力做好这一件事更累。</p>
</blockquote>
<p>1.把必须要做的小事要处理掉<br>2.对要做的事情做计划<br>3.实行最小化可行产品 </p>
<p>产品的定义：1.不是过程，而是结果 2.不是堆积，而是结构性的整合 3.能被别人检验使用的 4.能够独立地产生正向价值和影响的 5.同时它也是一种媒介，传递价值，传递你的才能 </p>
<p>传统的教育提醒我们”做准备“，然而过多的准备并没有直接”精益创业“来得直接</p>
<p>在切换任务的同时，也需要注意”转换消耗“带来的损失：在转换时，我们需要承受认知惯性和认知重构的代价<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/read_20170413_01.png" alt=""><br>大部分的事情，真正有用和结构性的思考只在其中小部分的复杂问题，当把这些最难的部分解决之后，事情也就完成了大半，其余都是些打扫、完善、铺成的工作，作者把一件事情的思维比喻成三文治，我们做一件事之前，先把最关键的难题想明白了，其余的事情就水到渠成了。</p>
<h4 id="前瞻性和总结性"><a href="#前瞻性和总结性" class="headerlink" title="前瞻性和总结性"></a>前瞻性和总结性</h4><p>对于即将执行的行动或者已经完成的行动，我们需要及时地进行前瞻性和总结性的分析，这使得我们在行动中不断地反省和进步；</p>
<p>因为文字和媒体并不能承载和表达所有的知识，一些实践类的知识涵盖过多较深的细节，而这些细节可能并没有办法被抽象地表达出来的；这就需要直接动手，积极反思。</p>
<p>如何反思？ 从以下的方面思考：1.信息：哪些是关键信息、从哪获得 2.预期：什么造成预期和事实的偏差 3.结果：怎样评价和描述结果 4.进度：什么影响了进度，过快还是过慢 5.工具：哪些有用的工具，如何使其发挥更好功效 6.情绪：我的情绪是什么引发的，如何有意识地调整 7.阻碍：做事过程暴露什么缺点，遇到哪些批评 8.意义：这件事对于我的意义，对于社会的意义<br>反思要主要三个关键：保证及时性、梳理事情的反应链、关注意外现象</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>当一件事情，不知道怎么做的时候，就直接开始做。只要开始了第一步，就会有第二、第三步。</li>
<li>克服”过度准备“的惯性，向前一步，把未完成的事情完成</li>
<li>乐于接受反面意见，有勇气否定并重新构造自己的产品</li>
<li>多线程工作，首先需要一段专注不受干扰的时间，完成工作中最核心部分的思考。</li>
<li>集中处理同质性的工作，可以减少不同质工作间的转换消耗。</li>
<li>从理论出发不一定能指导实践，只有在实践中通过反思积累的知识才能指导实践</li>
<li>行动后要及时反思，并梳理这件事情的”反应链“，特别关注其中发生的意外现象</li>
</ul>
<h4 id="小节实践练习"><a href="#小节实践练习" class="headerlink" title="小节实践练习"></a>小节实践练习</h4><p>哪些小事，由于拖延而带来更大的负担，请在一个月内立刻完成这些事：1.整理生活和工作环境 2.整理笔记本信息 3.开始去做要事：配置环境，着手写论文，改代码等</p>
<p>最小化可行产品：编写TIP论文，最核心的部分是：核心结构的编写、CNN-CDM、CNN-JDD的实验比较，完成这个产品可以分为：1.编写框架结构 2.编写文段 3.设计实验 4.制作图表 5.完善各部分， 将成果公布并收集反馈意见，根据建议修正产品</p>
<p>在行动中反思：最近发生最大的一件事是ICME ORALS的论文，实验在很早就开始了，但人生第一篇论文一直砍不下来，跑了很多对比实验和参数，耗费了大部分的时间，关键的贡献都在其中1~2天内思考并完成了；得到启示：遇到问题要正面思考，不要拖延和回避，并积极请教，有经验的人确实能指导很大；意外：本应该如意的结果却在实验中体验不出来，在科研实验过程要严谨记录、尽量使工作具有连贯性，避免朝三暮四。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/12/paper-reading-20170412/" itemprop="url">
                  A Holistic Approach to Cross-Channel Image Noise Modeling and its Application to Image Denoising
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-12T21:04:11+08:00" content="2017-04-12">
              2017-04-12
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/12/paper-reading-20170412/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/12/paper-reading-20170412/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这是CVPR16的一篇Orals，主要的工作是Argues RGB噪声经过In-camera imaging之后，不再具有channel-independent的特性；提出用多元高斯分布来拟合RGB dependent noise，并提出了一个NN模型来估计Patch based的多元高斯模型的参数</p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>建模和分析噪声是一个基础的任务。传统地，噪声分布被建模成通道独立的；在RAW图上，这是可以接受的，但经过相机成像过程处理之后（gamma,tone-mapping,JPEG压缩），噪声分布变得具有通道相关性；这篇文章通过像素分析每个步骤上的分布以及协方差矩阵来描述了这一种通道相关的关系，并用多元高斯分布模型来建模估计噪声，最后提出了训练MLP的方法来估计模型的参数，从而达到噪声分布。实验证明该方法的噪声估计更精确，而且结合BNLM达到比传统BNLM和BM3D都好的去噪结果。</p>
<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>两点贡献：1.提出观察RGB经过camera imaging之后会产生channel dependent的噪声 2.提出3D RGB空间来观察Patch based noise，然后训练MLP模型来预测噪声参数</p>
<h4 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h4><p>最早的噪声估计是channel-independent Gaussian model,因为简单而且在camera imaging前，RGB的channel noise确实相关性比较低；后来Foi et al.[Practical poissonian-gaussian noise modeling and fitting for single-image raw-data.]提出了Poisonian-Gaussian Noise；之后Granados结合temporal和spatial noise来重构HDR图片噪声；Hwang et al.提出用Skellam distribution来表示噪声分布；</p>
<p>最近比较Robust的有Noise Level Function(NLF) [Statistical calibration of ccd imaging process],效果还不错。</p>
<h4 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h4><p>首先，作者列出在camera imaging过程中，导致R/G/B的Skellam分布变化；<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/paper_read_20170412_01.png" alt=""><br>该图列出了在camera imaging前后（RAW,JPEG)的channel covariance发生巨大的变化，所以noise变得channel dependent;</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/paper_read_20170412_02.png" alt=""><br>接着，从QQ-Plot来观察图像块（一般而言，分位图用于识别两个数据集的分布或者看它们是否同属于同一分布),从统计分布直观可得，噪声可以用多元高斯分布来建模估计：</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/paper_read_20170412_03.png" alt=""></p>
<h4 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h4><p>作者使用MLP来学习估计patch based多元噪声估计模型的参数，Ground Truth数据是通过时域求均值得到的noise-free image。用了L2的Loss function，再在准确的噪声估计基础上，使用BNLM[Bayesian non-local mean filter],效果比原来NBLM和BM3D都好。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/12/精进-1/" itemprop="url">
                  精进_1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-12T13:58:25+08:00" content="2017-04-12">
              2017-04-12
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Read/" itemprop="url" rel="index">
                    <span itemprop="name">Read</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/12/精进-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/12/精进-1/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>再次读到采铜写的《精进：如何成为一个厉害的人》，诚然，每个人都希望自己能够成为一个厉害的人，也希望自己能够精进，获得某种锻炼和技能，这是一本个人心灵成长的书籍。如同任何鸡汤的书一样，理论和知识的理解并不困难，只要用一种轻松或者让人能理解的方式去写出来，但每一件事情的思考到落实却需要许多的毅力来执行；尤其当其成为习惯与持之以恒的行动时，我们才能看到真正的转变，这就需要我们不断地操练和提醒，积极地反馈自我。</p>
<h3 id="序言：用勇敢的方式去生活"><a href="#序言：用勇敢的方式去生活" class="headerlink" title="序言：用勇敢的方式去生活"></a>序言：用勇敢的方式去生活</h3><blockquote>
<p>生活就像一面多棱镜，它有不止一个镜面，相应地，也有不止一种可观察和理解的视角</p>
</blockquote>
<p>这也透露出生活具有的多元性和丰富性，正是因为这，也才使得人生是那么的丰富多彩，充满了意义。</p>
<p>本书从人生重要的七个维度展开：时间、选择、行动、学习、思维、才能和成功来论述理想中符合自我的生活和人生。时间是前提与坐标；选择使我们认清自我以及在世界中的位置；行动则是真正生命力的象征，也是解决问题的能力；学习则是一生的修为与锻炼；思考是伟大而有价值的，需要我们来发现其价值与意义；成功的定义应该是坚持做一个你所喜欢的自己；<br>全书追求的一个目标是：思考如何才能获得丰盈、独特、完整和自足的人生，摆脱内心的禁锢，勇敢开阔地去生活。</p>
<p>我的见解：思考生活和思考人生是一个永无止境的课题，此中是毫无答案却是意义非凡，每一次的思考哲学也是跟“自我”的对话，当然这是一个耗费精力的过程，应该张弛有度。过于频繁一般多因生活的不如意而导致“人生是虚空，没有意义”的消极观点，但其实生活是充满意义的，只是它在你的眼中、你的世界彰显出来的意义不一；有人说人生的意义，自己对于生活、世界的意义一般是在青春期或中年时期才会变得那样的频繁和重要；因为小孩子对未来充满了希望，他们总是希望等待自己的长大来成为希望的人，从不去担忧着生活；而老年人经历了一切回归于生活的时候，他们已经确认自己在世界和人生里面的定位，不会再去思索太多，只需按着自己的步伐享受拥有的生活。<br>我相信每一个人都对自我充满了期待和梦想，只是有些时候我们因为挫败而丢掉了对自己的期许或者一时被遮蔽了梦想，才重新去探索如果实现不了这个事情，我的人生的意义又从何觅起，这是因为自己的自卑、懒惰或者人性的弱点而导致自己缺乏了生命力；希望每一位消极或者抑郁的人都能振作起来，了解到生命本身就是宝贵的，更毋庸说生活带来的意义，我们确实应该郑重地对待生命的宝贵和时间的宝贵。</p>
<h3 id="关于时间与选择"><a href="#关于时间与选择" class="headerlink" title="关于时间与选择"></a>关于时间与选择</h3><h4 id="对待时间的态度"><a href="#对待时间的态度" class="headerlink" title="对待时间的态度"></a>对待时间的态度</h4><blockquote>
<p>一个人如何对待他的时间，决定了他可以成为什么样的人</p>
</blockquote>
<p>对待时间应用的态度是：郑重！ 具体来说是，不敷衍、不迟疑、不摇摆，认真地聚焦当下的事情，自觉而专注地投入其中</p>
<p>斯坦福心理学家Philip Zimbardo从时间视角划分了不同的心态：积极过去（感恩）、消极过去（抑郁）、享乐主义（幸福）、宿命论（消极）、未来视角（积极）；而我们的生活应该在积极过去、享乐主义与未来视角中取得平衡，按着自我的需要和场景切换。<br>为了让自己更好地去做”正确“的事情，我们可以：</p>
<ul>
<li>让远期未来目标具体化、情景化和使其可实施</li>
<li>降低”无用行为“的便利性，主动挑战难度</li>
</ul>
<p>合理地利用时间=选择去做”正确“的事情，但由于选择和诱惑的增多，现代人面临选择无能（不容易判断)和执行无能（拖延症），这里作者提出一个守则：少做短半衰期的事情，只要是能积累的长衰期事情就要认真积极地完成。</p>
<p>e.g. 长半衰期的事情有:积累可信知识、训练实践技能、提升审美品位、构建新的思维模式、建立和维持相互信任关系、寻找并获得稀缺资源、反思和总结个人经历、保持与促进健康、探索独创见解与发明、获得高峰体验等等</p>
<p>”长半衰期“的”时间之尺“是一个非常好用的评判标准，经历时间洗礼的”经典“含着接近”事物本质“和”生命本质“的东西。</p>
<blockquote>
<p>《反脆弱》的林迪效应：对于会自然消亡的事物生命每增加一天，预期寿命就会缩短一些，就像人类自己。对于不会自然消亡的事物，生命每增加一天，意味着更长的预期剩余寿命。就像经典著作和对别人的影响。<br>作者提出一种好玩的假设，阅读经典就像把历史的杰出人物加为微信好友，畅游在他们的朋友圈中，你能汲取他们的智慧和精华，会发现他们都是个性鲜明有趣的人；这些杰出的人拥有各自的特点，也存在着让他们杰出的共性：每个人都明白自己独特的特点，并能将其在环境中表露和得到发挥，当中的大部分人是不会受朝代和潮流所影响，他们有自己坚守独特的品质，你能从中认识到各有各伟大的地方。</p>
</blockquote>
<p>我的见解：这让我不禁觉得历史是一个好东西，以前确实忽视了，只从客观事实和教科书去学习历史其实是很low的，当你从人和思考的角度来看，历史鲜活起来的时候，它变得那样的真实、动人和有趣，而你也正身处在历史的潮流中，你又会成为怎样的历史呢？心中有一把”时间之尺“去衡量自己，衡量生活，衡量东西，这就是当你迷茫是，其中一个重要和不变的标准。这与孔夫子的立德（耶稣、儒家、佛教）、立功、立言（著书)有异曲同工之妙。再说一下效益和半衰期的事情，和牛人固然是效益高、半衰期长的事情，但是这种好事需要我们先重复练习做效益低、半衰期长的事情，积累起来之后，在业内才能碰到这种好事，也就是越努力越幸运，所以我们需要提前做好艰苦打基础的心理准备！</p>
<h4 id="快与慢"><a href="#快与慢" class="headerlink" title="快与慢"></a>快与慢</h4><p>回归到生活之中，并非简单地一味求快就是最佳，生活应该张弛有度，快慢适宜。简单来说是，工作要快，生活要慢；毕竟人生的第一桩要事是生活，生活应该是享受、体验和培养生机的过程。</p>
<p>在现代忙碌的生活中，我们可以享受体验的慢事如：坐在公园的长椅观察、夜晚在吊床上看星星、漫无目的地散步、在静寂中看一本书、阳光草坪下小睡片刻、在烛光中洗澡等</p>
<p>另外，要注意求慢的事情有：与家人共度闲暇、欣赏艺术作品、自我反思、思考重大决策、创造性活动的酝酿、为挑战性任务的准备</p>
<p>人在爱好上，在闲暇中放松与满足的程度取决于质量而非长度，进入”心流“的专注模式会让人得到更多深度的体验，而相应地在爱好上获得的成就让你更放松和满足。所以从现在开始，请找到并保持至少一项长期的业余爱好吧。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul>
<li>平衡看待过去、现在和未来，郑重地过好当下，联结过去和未来</li>
<li>用未来视角工作，用享乐主义生活</li>
<li>用时间之尺审视事情，尽可能删减不必要的事情</li>
<li>快慢结合，区分”求快“，”求慢”的事件</li>
<li>提升时间的深度，减少被动休闲的比例，保持至少一项长期的业余爱好</li>
</ul>
<h3 id="如何行动"><a href="#如何行动" class="headerlink" title="如何行动"></a>如何行动</h3><p>成为一个厉害的人，或者精进自我，就需要提出设立高标准的原则，让自己成为高标准的人。</p>
<p>在学生中，高标准的体现包括：1.选择好的课外在线课程 2.选择优秀的国外教材 3.跟优秀的人进行交流 4.选择有挑战性的竞赛</p>
<p>我们需要时刻以最高标准为原则，设定价值尺度，从“目标”、”眼界“和”信念“来划分4种人：盲众、逐利者、理念人和至善之人（史怀哲）</p>
<blockquote>
<p>人不能只为他自己而活。我们必须认知所有的生命都是珍贵的，而我们和所有的生命是结合在一起的。这种认知指引了我们心灵和宇宙的关系。 -史怀哲</p>
</blockquote>
<p>一般遇到困难的时候，都是因为隐性假设在阻碍着我们发展，我们可以冷静合理地分析这些隐性假设，寻找突破现状的新可能。<br>中国社会生活中存在的四个典型假设：赛道假设、低关联假设、僵固型心智、零和博弈</p>
<p>在设立多目标的时候，我们可以尝试目标悬挂，就像国外实行的”开环大学“，让本科学士学位可以在六年内修完，中间与工作和实践结合，更好地学以致用；还有就是能力嫁接，让其他的能力充分发挥，最后进行特性改造，将消费型爱好转化成生产型爱好。</p>
<h3 id="课后习题"><a href="#课后习题" class="headerlink" title="课后习题"></a>课后习题</h3><p>这里我把自己阅读的课后习题答案稍微写一下（相当于揭短，让内心的黑暗接受阳光的洗礼）：<br>最近自己不好的事情，学到了什么？：1.GRE考试失败，从中明白要好好备考，英语是很重要的，虽然GRE的单词生僻枯燥，但若能熬过这一关也证明了自我。 2.论文拖延症：认识到自己的拖延和懒惰，一味地逃避正确的事情，会让自己越来越痛苦，甚至怀疑自己 3.过度娱乐：由于没有太多的驱赶和压力，自己迷失了自我，忘记了初心；尤其当下的视频媒体各方面做得极具吸引力，在国外YOUTUBE资源多网速好，简直一个不小心休息就连看1小时视频，还有其他电视剧、综艺、电影之类的，视频对大脑的刺激实在来得太剧烈，就算没有多巴胺、尼古丁或者可卡因都能上瘾；对于如此自制力的我，估计这辈子都得远离烟酒毒品什么的！希望自己能少看视频，多读文字，看看书。</p>
<p>最近的成就，它对人生的意义： 1.之前写了的雅思总结笔记，把自己的经历和书籍分享给别人，感觉自己帮助了别人，也巩固了经验心得，意义非凡！ 2.完成了ICME的投稿，最近出了ORALS的结果，自己的写作和科研上的探索得到了肯定，能将自己学习到的知识和探索的成果传播出去，让自己的自信又多了一点点了！ 3.之前做的这个博客，虽然没有什么访问量，但它就像一本日记一样，记录着我的生命轨迹，我的喜怒哀乐，虽然经常会忘掉它；但我渐渐发现，不是它（我期待的读者）需要我，是我需要它，所以希望自己能坚持更新，更新自己的心情，更新我的学习和成长。</p>
<p>五年目标：说到底，这个东西每年都写一次，每年都觉得自己并没有离目标更近一点了，这次定一个稍微现实一点，希望能让自己往目标靠得更近一点。 1.找到好的、如意的工作：我希望从事教育和技术结合的工作，我发现自己还是对教育充满了兴趣，可是自己还是没能往前迈出这一步。 2.出一本书，无论是自费还是挣钱，希望自己这一生能留下一点什么，所以自己写作并出版一本书对我来说意义非凡，希望自己能多阅读，多积累！ 3.成家立室，提到这个目标其实有点早，因为本来期待30+才想这个事情，而且这个应该不需要订目标太早吧？还能放进5年计划？这不时机成熟，条件充分，一下子就好了吗？然而现在结婚需要的压力或者时机越来越复杂了，提前一点准备，多挣钱，多看世界，多尝试吧。</p>
<p>每周让自己放松的事情：运动是最大的爱好！包括跑步、爬山、篮球、骑车和健身；然后就是阅读，要多读经典，多读历史；可以珍惜在香港的时间，多听听讲座、展览、美术<br>长期培养的爱好：1.写博客 2.写书或者小说 3.写代码 4.吉他</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/11/VisualComputing-3/" itemprop="url">
                  VisualComputing_3
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-11T20:43:32+08:00" content="2017-04-11">
              2017-04-11
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Read/" itemprop="url" rel="index">
                    <span itemprop="name">Read</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/11/VisualComputing-3/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/11/VisualComputing-3/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这一节讲解如何用Dictionary learning做Classification Task</p>
<h3 id="Sparse-representation-Classificaton"><a href="#Sparse-representation-Classificaton" class="headerlink" title="Sparse representation Classificaton"></a>Sparse representation Classificaton</h3><p>Problem Modeling:<br>$label(y) = argmin_k(r_k)$<br>$where\ \ r_k = ||y-X_k \hat{\alpha_k}||_2$</p>
<p>prons:</p>
<ul>
<li>novel use sparse coding for classification</li>
<li>widely studied, improved and extended</li>
<li>good performance</li>
</ul>
<p>cons:</p>
<ul>
<li>SRC is owed to use of sparse coding which is not accurate</li>
<li>new type of classifier although the sparsity is helpful</li>
<li>不是有效的局部结构性特征</li>
<li>针对遮挡问题，字典过大</li>
</ul>
<p>通过局部特征（Gabor,SIFT)来解决局部特征，用robust coding可以解决遮挡问题的字典过大。<br>LASSO和L1-LASSO最大的区别是数据保真项$e=y-X\alpha$分别服从i.i.d. Gaussian or Laplacian distribution</p>
<p>LASSO: $ min_{\alpha} ||y-X\alpha||_2^2 \ \ \ s.t.\ ||\alpha||_1&lt;=\sigma$</p>
<p>L1-LASSO: $min_{\alpha}||y-X\alpha||_1 \ \ \ s.t.\ ||\alpha||_1&lt;=\sigma$</p>
<h4 id="MLE"><a href="#MLE" class="headerlink" title="MLE"></a>MLE</h4><p>最大似然估计提供了一种给定观察数据来评估模型参数的方法，“模型已定，参数未知”。一个重要的假设：所有的采样都是独立同分布的。<br>假设$x_1,x_2,…,x_n$为独立同分布采样，$\theta$为模型参数，$f$为模型，则产生上述采样可表示为 $$f(x_1,x_2,…,x_n|\theta)= f(x_1|\theta)*f(x_2|\theta)…,f(x_n|\theta)$$</p>
<p>似然的定义:$ L(\theta|x_1,…,x_n)=f(x_1,…,x_n|\theta)= f(x_1|\theta)*f(x_2|\theta)…,f(x_n|\theta) $</p>
<p>最大似然对数: $ \hat{\theta}_{mle} = argmax_{\theta} \ell(\theta|x_1,…,x_n), \ell=\frac{1}{n} lnL$</p>
<p>最大似然估计的步骤：</p>
<ul>
<li>写出似然函数</li>
<li>对似然函数取对数，并整理</li>
<li>求导数</li>
<li>解似然方程</li>
</ul>
<h4 id="MAP"><a href="#MAP" class="headerlink" title="MAP"></a>MAP</h4><p>最大后验估计是根据经验数据对难以观察的量的点估计(Point Estimation)，与MLE类似；不同的是，MLE<strong>融入了估计量的先验分布</strong>在其中，MAP可以看做规则化的MLE。<br>回顾x为采样，$\theta$为模型参数，f为模型，则MLE可以表示为：$$\hat{\theta}_{MLE}(x) = argmax_{\theta} f(x|\theta)$$</p>
<p>对于MAP，现在假设$\theta$的先验分布为g,通过贝叶斯理论，对于$\theta$的后验分布如下：$$\theta \mapsto f(\theta|x) = \frac{f(x|\theta)g(\theta)}{\int_{\theta} f(x|\theta^{*})g(\theta^{*})d\theta^{*}}$$</p>
<p>则MAP的目标为：$$\hat{\theta}_{MAP}(x)=argmax_{\theta} f(\theta|x) = argmax_{\theta} f(x|\theta)g(\theta)$$</p>
<p>可以看出，MAP和MLE最大的区别是MAP加入了模型参数本身的概率分布，或者说MLE的模型参数概率为均匀固定值。</p>
<h3 id="Collaborative-nature-of-SRC"><a href="#Collaborative-nature-of-SRC" class="headerlink" title="Collaborative nature of SRC"></a>Collaborative nature of SRC</h3><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_01.png" alt=""><br>对于正则项，L1为sparse,L2为Collaborative</p>
<p>佳哥的CVPR16文章A Probabilistic Collaborative Representation based Approach<br>for Pattern Classification，主要解释为什么SRC/CRC WORK,具有怎样的特性，结合了proCRC的Modeling，构建出这一分类器比传统分类器要较优；寻找一个common point for joint projection;分类问题相当于在分布空间上的映射。</p>
<h3 id="Discriminative-Dictionary-Learning-DL"><a href="#Discriminative-Dictionary-Learning-DL" class="headerlink" title="Discriminative Dictionary Learning(DL)"></a>Discriminative Dictionary Learning(DL)</h3><p>Motivation:1.学习compacted字典 2.学习discriminative 3.effected</p>
<h4 id="Shared-DL"><a href="#Shared-DL" class="headerlink" title="Shared DL"></a>Shared DL</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_02.png" alt="LC-KSVD"><br>Label Consistent-KSVD目的：学习一个线性变换A来约束了Sparse Code的Ideal形式,这里Q是预定义的理想编码形式，T是约束系数大小的。</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_03.png" alt="LC-KSVD"><br>首先计算Sparse Code，然后WX的结果就是分类类别结果</p>
<p>Support Vector Guided DL(SVGDL), idea:自适应地对coding vector进行参数化。有些编码重要，部分编码相对不重要。</p>
<h4 id="Class-specific-DL"><a href="#Class-specific-DL" class="headerlink" title="Class-specific DL"></a>Class-specific DL</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_04.png" alt="DDL"><br>所谓决策性字典学习就是把负样本也放进学习过程中进行字典训练。</p>
<p>Fisher DDL exploit both representation residual and coding coefficient,引入使用了Fisher Criterion</p>
<h4 id="Dictionary-Pair-Learning"><a href="#Dictionary-Pair-Learning" class="headerlink" title="Dictionary Pair Learning"></a>Dictionary Pair Learning</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_05.png" alt="DDL"><br>同一个Sparse Code,但是针对类别适应的字典，有点像多个2分类的SVM.</p>
<h3 id="Collaborative-representation-for-image-sets"><a href="#Collaborative-representation-for-image-sets" class="headerlink" title="Collaborative representation for image sets"></a>Collaborative representation for image sets</h3><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170412_06.png" alt="ISCR"><br>将Image Classification扩展到Image Set Classification</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/08/VisualComputing-2/" itemprop="url">
                  VisualComputing_2
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-08T15:13:57+08:00" content="2017-04-08">
              2017-04-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Read/" itemprop="url" rel="index">
                    <span itemprop="name">Read</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/08/VisualComputing-2/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/08/VisualComputing-2/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>上一节讲了CV的介绍和Sparse Representation的内容，包括CV的概念、应用和难点；Sparse Representation的formulation, method以及步骤。当然还有为何Sparse Representation can work. 这一节讲一下Dictionary Learning和Representative works</p>
<h3 id="Dictionary-Learning"><a href="#Dictionary-Learning" class="headerlink" title="Dictionary Learning"></a>Dictionary Learning</h3><h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>在稀疏编码之前，需要学习一组过完备的字典，从而使得编码向量是稀疏的。以下分为两种字典，Analytical and Learn;<br>Analytical包括DCT bases, Wavelets, Curvelets…; Learn dictionaries from natural images: K-SVD, Coordinate descent, Online dictionary learning;</p>
<p>为什么需要字典学习？</p>
<ul>
<li>Over-complete learned dictionary often work better than analytically</li>
<li>More adaptive to specific task/data</li>
<li>Less strict constraints on mathematical properties of bases</li>
<li>More flexible to model data</li>
<li>Tend to produce sparser solution</li>
</ul>
<h4 id="L0：K-SVD"><a href="#L0：K-SVD" class="headerlink" title="L0：K-SVD"></a>L0：K-SVD</h4><p>对于L0稀疏的字典学习，我们可以用K-SVD方法近似求解，其中可以看成是K-MEANS的一种扩展<br>字典学习的问题可以Modeling为：<br>$$min_{D,A}||Y-DA||_F^2 \ \ s.t.\ \ ||a_i||_0 &lt;= T_0$$ 其中i为任意正数，$T_0$为稀疏值<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_01.png" alt="K-SVD"><br>如图，对于字典学习：</p>
<ul>
<li>首先是稀疏编码，可以用Matching Pursuit来优化求解；然后用K-SVD方法更新字典。 </li>
<li>然后将DA进行K次分片叠加得到$DA=\sum_{i=1}^K d_i a_i^T$, 这里便是一个可用词典；剥离第K条，寻找新的d,x来更新该条目</li>
<li>最后，只抽取非零的a组成新的矩阵$\Omega$作为系数矩阵，对误差能量矩阵作SVD分解，d取U的第一行，x取$\sum V^T$的乘积第一列</li>
</ul>
<p><strong>总结</strong>K-SVD的思想：K次分片，使得最后学得的字典over-complete; 选用第K个条目更新，每次只更新一个字典atom(one column in fat matrix); 对剥离后的‘空洞’做K-SVD， $E_k = U \sum V^T$, 新的d,a则取里面能量最大的元素， 这是对误差’空洞’的最佳逼近；只抽取非零系数组成新矩阵更新，有助于保持原来字典的稀疏性；</p>
<p>对于L1字典，可以对D和A交替学习：当更新D时，这是Quadratic Programming; 当更新A时，这是LASSO Optimization (ADMM); </p>
<h4 id="Representative-Work"><a href="#Representative-Work" class="headerlink" title="Representative Work"></a>Representative Work</h4><p>Online learning: 考虑新来的样本，直接在原来基础上更新词典的策略以及收敛性</p>
<p>Multi-scale Dictionary learning: 由于complexity increases exponentially with signal dimension,所以一般用较小的patch size; 而multi-scale可以自适应地融合不同scale字典编码<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_02.png" alt="Multi-Scale"></p>
<p>Double Sparsity: 可以针对高层次稀疏特征或者large patch再进行一次dictionary learning, 基于稀疏编码或着高维编码的再一次稀疏表示；<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_03.png" alt="Double Sparsity"></p>
<h3 id="Restoration-Methods"><a href="#Restoration-Methods" class="headerlink" title="Restoration Methods"></a>Restoration Methods</h3><p>Filtering-based methods: Isotropic method, Anisotropic method<br>Transformation methods: Motivation, find new representation where signal and noise can be better separated; Wavelet transform</p>
<h4 id="K-SVD-denoising"><a href="#K-SVD-denoising" class="headerlink" title="K-SVD denoising"></a>K-SVD denoising</h4><p>Basic Idea: 1.train over-complete dictionary 2.adopt trained dictionary to denoise patch in noisy image 3.Utilize the patch to reconstruct<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_04.png" alt="Modeling"><br>Limitations: 1.Solving sparse coding not effective enough 2.L0 is not good choice </p>
<h4 id="BM3D"><a href="#BM3D" class="headerlink" title="BM3D"></a>BM3D</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_05.png" alt="BM3D"><br>BM3D denoising算是业内最为经典的去噪算法了，其中结合了Nonlocal self-similarity和sparsity两个最重要的priors，效果非常不错，速度一般</p>
<p>步骤：首先通过non-local matching找到一组图片块；组成tensor进行维纳滤波，之后进行阈值抑制（这里相当于稀疏去噪）；最后对新的tensor结合原来的tensor再重复做维纳滤波和阈值抑制；得到去噪patches reconstruct到图像即可</p>
<p>优缺点：1.有效挖掘了nonlocal similarity和sparsity 2.在DWT（小波)做协同滤波并不能描述复杂的图像结构</p>
<h4 id="LSSC"><a href="#LSSC" class="headerlink" title="LSSC"></a>LSSC</h4><p><strong>Group Sparsity</strong><br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_06.png" alt="Group SPARSITY"><br>与普通的L1 sparsity不同，Marial提出系数矩阵满足group sparsity的L1，2范数；使得同样的patch，在字典下应该具有统一的稀疏编码，保持元组具有相同稀疏的特性；仔细看12范数的表达形式，j是行，i是列，使得系数尽可能在同一行；</p>
<p>整个流程和BM3D相似，只是在协同滤波和阈值抑制上，改成用group sparsity的字典学习和稀疏编码去噪</p>
<p>Adaptive Sparse Domain Selection： 由于大的词典使得稀疏编码过程非常耗时，而大的词典对于描述图像局部结构又是很有必要；这个方法提出从大字典中选择一个子集可以提速</p>
<p>Piece-wise Linear Estimation (PLE), Motivations:</p>
<ul>
<li>Sparse representation assumes <strong>Laplacian</strong> prior on coefficients, lead to nonlinear sparse coding estimator</li>
<li>Use <strong>Mixture of Gaussians</strong> to approximate Laplacian</li>
<li>Select one appropriate Gaussian Prior to reconstruct</li>
</ul>
<h4 id="Coupled-Dictionary-Learning"><a href="#Coupled-Dictionary-Learning" class="headerlink" title="Coupled Dictionary Learning"></a>Coupled Dictionary Learning</h4><p>Motivations:</p>
<ul>
<li>Used coupled dictionary to model the relationship between degraded image and its corresponding images</li>
<li>Build the corresponding in sparse domain(same code but different dictionary)<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170408_07.png" alt="SRSR"></li>
</ul>
<p>Semi-coupled Dictionary Learning: flexible the relationship between two dictionary, the sparse code with a pre-learned mapping</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/07/VDSR/" itemprop="url">
                  Very Deep Super Resolution
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-07T23:15:59+08:00" content="2017-04-07">
              2017-04-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/07/VDSR/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/07/VDSR/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>这一篇是CVPR16 Kim的VDSR，通过VERY DEEP的简单模型，又快又好地解决了SR问题，成为暂时这个问题上的标杆模型。</p>
<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><p>Our final model uses 20 weight layers. By cascading small filters many times in a deep network structure, contextual infor- mation over large image regions is exploited in an efficient way. With very deep networks, however, convergence speed becomes a critical issue during training. We propose a sim- ple yet effective training procedure. We learn residuals only and use extremely high learning rates (104 times higher than SRCNN [6]) enabled by adjustable gradient clipping.</p>
<h4 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h4><p>Single image super-resolution(SISR):upsampling方法，而后neighbor embedding,如今用CNN； SRCNN的limitation: 1.relies on context of small image regions; 2.only works for single scale； VDSR的主要优点有：1.通过small size kernel but very deep, to obtain a large context(receptive region) 2.Convergence very fast by residual-learning and BN high learning rate 3.Multi-Scale Factor,把多个scale的SR融合进一个网络模型 </p>
<h4 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/paper_20170407_01.png" alt="ARCHITECTURE"><br>20层CONV+BN+RELU，L2 LOSS, HIGH LEARN RATE WITH RESIDUAL LEARNING AND ADJUSTABLE WEIGHT CLIPPING.</p>
<h4 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h4><ol>
<li>THE DEEPER THE BETTER ON PSNR/SSIM</li>
<li>RESIDUAL LEARNING WORKS</li>
<li>MULTI-SCALE MODEL BETTER THAN SINGLE SCALE ON LARGE SCALE</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/07/VisualComputing-1/" itemprop="url">
                  VisualComputing_1
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-07T21:30:44+08:00" content="2017-04-07">
              2017-04-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Read/" itemprop="url" rel="index">
                    <span itemprop="name">Read</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/07/VisualComputing-1/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/07/VisualComputing-1/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>老板的CV课程，在期末前做一下相关笔记总结</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><h4 id="What-is-vision"><a href="#What-is-vision" class="headerlink" title="What is vision?"></a>What is vision?</h4><ul>
<li>Perceive an integration of image data and prior knowledge in brain</li>
<li>A field acquiring, processing, analyzing and understanding visual data</li>
</ul>
<p>Computer Vision &amp; Human Vision?</p>
<ul>
<li>ill-posed problems</li>
<li>mathematical models</li>
<li>discrete vs. continuous</li>
<li>local vs. global optimization</li>
</ul>
<h4 id="What-kinds-of-Topics"><a href="#What-kinds-of-Topics" class="headerlink" title="What kinds of Topics?"></a>What kinds of Topics?</h4><p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_01.png" alt="相关学科"><br>Low Level: Image Denoising, Deblurring, Super-Resolution, photo-sketch synthesis, texture synthesis, optical flow, image matching</p>
<p>Middle Level: image segmentation, motion capture, visual tracking, 3D reconstruction</p>
<p>High Level: object detection, image understanding, video understanding</p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_02.png" alt="具体应用问题"></p>
<p>Related Problems: medical imaging, optical character recognition (OCR), face detection, smile detection, vision-based biometrics, shape capture, automatic driving</p>
<h4 id="Why-image-restoration-challenging"><a href="#Why-image-restoration-challenging" class="headerlink" title="Why image restoration challenging?"></a>Why image restoration challenging?</h4><ul>
<li>Real noise much more complex than additive white Gaussian</li>
<li>Blur is non-uniform and complex to accurately estimate</li>
<li>Space of image local structures is huge, inverse problem highly ill-posed</li>
</ul>
<h3 id="Sparse-Representation-and-Dictionary-Learning-on-Restoration"><a href="#Sparse-Representation-and-Dictionary-Learning-on-Restoration" class="headerlink" title="Sparse Representation and Dictionary Learning on Restoration"></a>Sparse Representation and Dictionary Learning on Restoration</h3><p>Linear system $Ax=b$, if A full rank, $x = A^{-1}b$; if tall matrix(over-determined) than approximate solution by $minimize||Ax-b||_2^2$; if fat matrix(underdetermined), no solution in general and some constraint should be imposed</p>
<p>假设estimation与observer的最小距离是L0,L1,L2或其他：L0，非凸优化； L1，tightest convex relaxation of L0, 稀疏解; L2有闭合Dense解。具体到一个优化问题的等高线逼近时，各个NORM BALL的图形如下。<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_03.png" alt="各个Norm Ball"><br>尽管L1能逼近L0，但有时候L1也会出现非稀疏解，数学上已经证明，满足RIP性质的话，用L1近似L0能确保得到稀疏解。RIP又称有限等距性质,直观解释为从A矩阵中的部分列向量与任意向量x的乘积结果收敛在一个环形邻域，如下图<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_04.png" alt="RIP"></p>
<p><img src="http://7xl4js.com1.z0.glb.clouddn.com/vc_20170407_05.png" alt="直观解释"></p>
<p>图像复原问题</p>
<h4 id="Modeling"><a href="#Modeling" class="headerlink" title="Modeling"></a>Modeling</h4><p>$y=Hx+v$, H:observation matrix, v:noise<br>Keys to solve ill-posed problems:</p>
<ul>
<li>Modeling the degradation process</li>
<li>Good Prior knowledge about the clean image</li>
<li>Good objective function for minimization</li>
</ul>
<p>其中H在denoise是identity matrix; deblurring为blurring matrix; supperresolution是compound matrix of blurring and downsampling matrix; Inpainting是indication matrix of damaged pixels; </p>
<h4 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h4><p>Filter based methods: Gaussian low-pass, PDE-based anisotropic diffusion, Bilateral filtering, Nonlocal means filtering; (local-&gt;non local performance improve greatly)</p>
<p>Transform based methods: Fourier(‘Global, Orthogonal’), Wavelet(‘local, small’), Ridgelet(‘more redundant’), Dictionary Learning(‘over-complete’)</p>
<ul>
<li>Represent x over dictionary D, enforcing the new vector be sparse(robust)</li>
<li>objective model $min_\alpha ||HD\alpha-y||_2^2+\lambda ||\alpha||_1$</li>
</ul>
<h4 id="The-basic-procedure"><a href="#The-basic-procedure" class="headerlink" title="The basic procedure"></a>The basic procedure</h4><ol>
<li>Partition degraded image into overlapped patches(8*8)</li>
<li>For each patch, solve the nonlinear L1-norm sparse coding problem:<br>$\hat{\alpha} = argmin_\alpha ||HD\alpha-y||_2^2+\lambda||\alpha||_1$</li>
<li>Reconstruct each patch by $\hat{x}=D\hat{\alpha}$</li>
<li>put the reconstructed patch back and average the overlapped pixels</li>
<li>In practice, the 1~4 can be iterated for several rounds</li>
</ol>
<p>why sparse?</p>
<ul>
<li>Neuronscience</li>
<li>Bayersian </li>
<li>Compressive Sensing</li>
</ul>
<h4 id="How-to-solve"><a href="#How-to-solve" class="headerlink" title="How to solve?"></a>How to solve?</h4><p>L0: Greddy search(Matching pursuit, Orthogonal matching pursuit)</p>
<ul>
<li>MP: 贪婪地选取相关性最大的atoms</li>
<li>OMP: 正交地，把曾选的atoms的信息均用上，组合出新的投影向量<br>L1: </li>
<li>Linear programming</li>
<li>Iteratively reweighted least squares：Trickly weighted L2 to L1</li>
<li>Proximal gradient descent: Soft-Thresholding with analytic solution</li>
<li>Augmented Lagrangian methods(Alternating Direction Method of Multipliers, ADMM)</li>
</ul>
<h3 id="ADMM"><a href="#ADMM" class="headerlink" title="ADMM"></a>ADMM</h3><h4 id="拉格朗日变换"><a href="#拉格朗日变换" class="headerlink" title="拉格朗日变换"></a>拉格朗日变换</h4><p>将Constraint结合拉格朗日乘子放在Objective function里面。<br>e.g $min\ f(x) \ s.t. Ax=b$<br>拉格朗日形式：$L(x,\lambda)=f(x)+\lambda (Ax-b)$<br>对于含有不等式约束的情况，结合KKT条件，$h(x)=0, \lambda&gt;=0, \lambda*g(x)=0, g(x)&lt;=0 $, 其中h是等式约束，g是不等式约束，$\lambda$是不等式乘子</p>
<p>KKT条件：对于问题 $L(x,\lambda) = f(x)+\lambda g(x)$<br>满足 </p>
<ul>
<li>$\Delta_x h(x,\lambda)=0 $</li>
<li>$\lambda&gt;=0$</li>
<li>$\lambda *g(x)=0$</li>
<li>$g(x)&lt;=0$</li>
<li>$\Delta_{xx} L(x,\lambda)$ is PSD</li>
</ul>
<h4 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h4><p>对于原问题$L(x,\lambda)=f(x)+\lambda(Ax-b)$<br>对偶形式为：$g(\lambda)= inf_x(L(x,\lambda)) = -f^*(-A^T\lambda)-b^T\lambda)$,其中inf为确认下界（infimum)<br>对偶问题： $max\  g(\lambda)$<br>对偶上升法： $x^{k+1} = argmin_x L(x,\lambda^k)$</p>
<p>变量更新：$\lambda^{k+1}=\lambda^k +\alpha^k(Ax^{k+1}-b)$<br>对偶分解法：将目标函数分解成多个子函数 $f(x)=\Sigma_{i=1}^Nf_i(x_i)$</p>
<p><strong>增广拉格朗日</strong>，为了增加Dual Ascent的鲁棒性，加入松弛函数<br>$$L_p(x,\lambda)=f(x)+\lambda^T(Ax-b)+(\rho/2)||Ax-b||_2^2$$</p>
<h4 id="ADMM-1"><a href="#ADMM-1" class="headerlink" title="ADMM"></a>ADMM</h4><p>ADMM旨在将对偶上升可分解性和乘子法上界收敛属性融合在一起的算法；<br>优化问题：$$ min\ f(x)+g(z) \ \ s.t. \ Ax+Bz=c $$<br>得到增广拉格朗日形式：$ L_\rho(x,z,\lambda)=f(x)+g(z)+y^T(Ax+Bz-c)+(\rho/2)||Ax+Bz-c||_2^2 $</p>
<p>迭代方式：</p>
<ul>
<li>$ x^{k+1} = argmin_x L_p (x,z^k,\lambda^k) $</li>
<li>$ z^{k+1} = argmin_z L_p (x^{k+1},z,\lambda^k) $</li>
<li>$\lambda^{k+1} = \lambda^k + \rho(Ax^{k+1}+Bz^{k+1}-c) $<br>$\rho &gt;0$,停止准则：对偶残差小于某个极小值$\epsilon$<br>收敛速度：对于一个高的精度要求收敛多次，但可以融合其他算法快速产生高精度<br>对于凸优化问题，KKT条件是对偶问题有相同解的保证。非凸的问题会存在Dual Gap.</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/29/CDM-Review/" itemprop="url">
                  CDM_Review
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-29T09:50:05+08:00" content="2017-03-29">
              2017-03-29
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Tech/" itemprop="url" rel="index">
                    <span itemprop="name">Tech</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/03/29/CDM-Review/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/03/29/CDM-Review/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今天来总结一下Color Demosaicking（CDM）里面的重要论文和方法。希望能囊括AP, AHD, SA, LDI-NAT, DLMMSE, LSSC, GBTF, RI等方法</p>
<h4 id="比较旧的：AP-AHD-SA等"><a href="#比较旧的：AP-AHD-SA等" class="headerlink" title="比较旧的：AP, AHD, SA等"></a>比较旧的：AP, AHD, SA等</h4><p>AP给出两个图像规律统计假设：1.自然图像在R,G,B通道间有较大的相关性（inter-color correlations) 2.G通道的采样率比R,B高一倍。则G通道的细节信息更丰富。它的方法包括两步：1.用了高低通滤波，然后构建inter-color恢复像素的公式 2.将结果投影到observed和label constrants sets上，进行fine-tune.（这些后来都有更好的方法）<br>Comment: AP这个方法效果已经不佳，但是它统计出来的inter-color correlation很重要</p>
<p>SA让G和RB通道的像素估计进行一个交替循环地求解，类似于近似逼近的思想。迭代式求解涉及三个问题：1.从何开始（初始化方法） 2.该算法收敛吗（论文用AP的constrains set论证) 3.什么时候结束(更新不再提高，或到一个较少值)<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/SA_1.png" alt=""><br>Comment: SA这个方法主要说明了一个Iterative求解CDM问题的可行性，但iterative问题需要说明清楚上述的三个问题。</p>
<p>AHD这篇文章2005年提出了homogeneity概念，有效结合梯度较小的变化方向进行有效的像素估计，最后结合adaptive中值滤波的方法去除一下artifacts。效果比之前好，而且还快。</p>
<h4 id="接下来说一下速度比较慢，效果比较好的：DLMMSE-LDI-NAT-LSSC-Dict-Learning"><a href="#接下来说一下速度比较慢，效果比较好的：DLMMSE-LDI-NAT-LSSC-Dict-Learning" class="headerlink" title="接下来说一下速度比较慢，效果比较好的：DLMMSE, LDI-NAT, LSSC, Dict Learning"></a>接下来说一下速度比较慢，效果比较好的：DLMMSE, LDI-NAT, LSSC, Dict Learning</h4><p>DLMMSE: 基于G和R/B通道的primal difference signals是low pass的，提出了基于directional minimum mean square-error estimation的方法，这里用到了horizon和vertical两个方向。先恢复G通道，然后用G恢复R/B通道。<br>论文首先给出统计表，说明GR和GB的相关性比RB的强，所以用G-R和G-B作为通道相关性的信号，然后估计真实值与观察值的误差。为了方便求解，而且假设两个信号demosaick noise是i.i.d gaussian，则LMMSE的公式可以简化为<img src="http://7xl4js.com1.z0.glb.clouddn.com/DLMMSE_1.png" alt=""> 其中x是观察值，mu_x是x的均值，sigma为方差，y为估计值。</p>
<p>LDI-NAT的方法在之前的博文说过，这里总结一下，相比DLMMSE，LDI-NAT用LDI做一个初始化方法，然后结合non-local similarity的方法，构建矩阵进行SVD去噪，从而达到去马赛克噪声的效果。具体数学部分挺多的，请看原文或者之前博文。</p>
<p>LSSC是09年提出的nonlocal+dictionary learning的美妙融合，成为了领域的milestone，当时做image restoration是效果最好的。先学字典，然后稀疏编码求解。这个字典的学习是精髓，不同于BM3D直接使用小波字典，这里作者用了L1,2 norm来使得同样的信号尽量获得同样的编码，用group sparsity从而使得字典更紧凑。</p>
<p>Regularization-based: 由于CDM是一个ill-posed problem,所以一般人们习惯于加入正则项来约束退化模型，从而得到原始的估计信号，这就使得正则项对于整个问题的重要性不言而喻了。这里说一篇《cdm using inter-channel correlation and nonlocal self-similarity》的TIP文章，作者提出了两个重要的term来做CDM restoration问题。首先是TV-term和inter-color channel的结合，在difference map上做tv效果会比单独TV更佳。 然后是nonlocal matrix的low rank constraint，由于高频纹理复杂以及噪声影响，这个nonlocal matrix可能不是低秩的，这里用一个低秩矩阵加上Outliers矩阵来近似，意思是总能来nonlocal matrix附近找到一个低秩矩阵满足低秩，从而将假设放宽了一点。最后优化这两个正则项。（当然这是基于MLRI的初始化之后再做的demosaicking denoise),接下来都是凸优化的数学问题求解了。<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/ISM_1.png" alt="最后的优化问题"></p>
<h4 id="最后是又快又好的插值方法：GBTF，-RI-based，-CNN-based"><a href="#最后是又快又好的插值方法：GBTF，-RI-based，-CNN-based" class="headerlink" title="最后是又快又好的插值方法：GBTF， RI-based， CNN-based"></a>最后是又快又好的插值方法：GBTF， RI-based， CNN-based</h4><p>GBTF的论文可以理解为更细致的adaptive插值方法，先做一个LCC1的初始化，然后类似Total Variance的方法，构建一个difference map.在这个difference map上面做四个方法的加权插值，最后将这个estimate difference加回初始化图像，得到最终结果。特别地，对于R,B通道，提出用Laplacian filter加权拟合效果更佳。（这也是后来MLRI的思想）</p>
<p>RI-based methods:<br><img src="http://7xl4js.com1.z0.glb.clouddn.com/RI_1.png" alt="RI流程"><br>RI是最近比较热门的方法，传统流程是在估计G通道之后，用R-G的difference做R图的恢复估计。现在RI是不直接在R-G difference map上面做，而是让G做引导图像，R做被滤波图像，得到tentative R,我们用tentative R - R 的difference(residual map)做插值恢复。最后作者用residual map和difference map对比一下，说明了residual map的像素梯度变化更缓和，有利于梯度插值，减少了插值误差，所以work.</p>
<p>之后延伸了MLRI：bilinear interpolation perform better for minimum laplacian energies. 在G和R通道上分别做sparse laplacian filter的卷积操作，其余跟RI一样。我的理解是，做完这个laplacian filter之后，residual image变得更加smooth,所以效果又提升了。</p>
<p>IRI： 将Iterative和RI结合，交替做G和R/B的恢复<br>ARI: 将MLRI和IRI加权融合，因为有时候MLRI处理不佳，有时候IRI对对于强相关区域处理不佳，所以ADAPTIVELY结合两者，再做加权平均。</p>
<p>Deep JDD: 将CDM和DNS一起做，它的网络没有用初始化方法，而是rearrange CFA,加入一个噪声参数层，end-to-end train,用了大量的数据，并且用目前的criterion来提取Hard-case建立了复杂库，并用这些库对网络进行fine-tune。最后得到较佳的JDD结果。<br>个人理解：由于没有初始化方法，所以需要大量的数据来学习CDM的初始化，网络需要学习的内容复杂（针对自己的实验，如果没有初始化效果会十分不佳），专注于hard-case的CDM可能会导致平滑区域的CDM效果不佳，其实不太有必要（我没有hard case效果还是不错,这也是它的网络在Kodak上面表现不佳的原因). 其实用CNN做JDD是十分好用的，但目前还存在的问题大概是：1.在处理CDM和DNS的流程上应该如何较佳（张老师认为DNS-&gt;CDM会更好，而目前CFA DNS效果不佳，导致其后的CDM也不太好） 2.如何将CNN-JDD做得更快更好，拟合真实噪声的分布</p>
<p>CNN-based的CDM，暂时我自己的网络用20层，64的kernel就已经把CDM效果做爆了，甚至比JDD要好。初始化方法是很有必要的，sequence end-to-end效果已经很好了，但这里面G channel细节信息更多error小，R/B channel细节信息较少，所以error大；如何用G CHANNEL来GUIDANCE成为问题。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="http://7xl4js.com1.z0.glb.clouddn.com/avatar.jpg"
               alt="CsrjTan" />
          <p class="site-author-name" itemprop="name">CsrjTan</p>
          <p class="site-description motion-element" itemprop="description">blog csrjtan tanrunj</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">72</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-block">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://arxiv.org/" title="arXiv" target="_blank">arXiv</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2015 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CsrjTan</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

<div class="busuanzi-count">

  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv"><i class="fa fa-user"></i><span class="busuanzi-value" id="busuanzi_value_site_uv"></span></span>
  

  
    <span class="site-pv"><i class="fa fa-eye"></i><span class="busuanzi-value" id="busuanzi_value_site_pv"></span></span>
  
  
</div>



        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"csrjtan"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  






  
  
  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  

</body>
</html>
